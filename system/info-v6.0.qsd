# -*- mode: qore; indent-tabs-mode: nil -*-
# Qorus System Service Definitions

/*
    Qorus Integration Engine(R) Community Edition

    Copyright (C) 2003 - 2023 Qore Technologies, s.r.o., all rights reserved

    LICENSE: GNU GPLv3

    https://www.gnu.org/licenses/gpl-3.0.en.html

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING
    FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER
    DEALINGS IN THE SOFTWARE.
*/

/** @see @ref ::QorusSystemInfoService for method information

    This service provides many methods for retrieving information about Qorus configuration and data.

    This service is used heavily by the Qorus client programs to provide information about metadata and order data
    status.

    Some methods interface directly with the Qorus server to provide the most up-to-date information possible without
    having to go first to the database.
*/

%new-style
%require-types
%strict-args
%enable-all-warnings

%requires SqlUtil

%try-module oracle
%define NO_ORACLE
%endtry

const defaults = {
    "row-limit" : 100,  # maximum number of rows to return in various places
};

const Grouping = {
    "hourly": \cop_year_hour(),
    "daily": \cop_year_day(),
    "monthly": \cop_year_month(),
    "yearly": \cop_year(),
};

class OptionHelper {
    static auto getOption(string opt) {
        # get service parameters
        return UserApi::propGet("info"){opt}
            ?? defaults{opt}
            ?? OMQ::UserApi::UserApi::getOption(opt);
    }
}

class SQLCommon {
    public {}

    hash processWorkflowMetadata(softint id) {
        return (
            # keynames
            "keylist"  : omqp.select("select keyname from workflow_keys where workflowid = %d", id).keyname,

            # get steps
            "steps"    : omqp.select("select * from steps where stepid in (select stepid from workflow_steps where workflowid = %d)", id),

            # get step dependencies
            "step_deps": omqp.select("select * from workflow_steps where workflowid = %d", id),

            # get segment dependencies
            "seg_deps" : omqp.select("select * from segment_dependencies where workflowid = %d", id),

            # get segment-step definitions
            "seg_steps": omqp.select("select * from segment_steps where workflowid = %d", id),

            # get option info
            "options"  : omqp.select("select * from workflow_options where workflowid = %d", id),

            # get group info from RBAC cache
            "groups"   : Qorus.rbac.getWorkflowGroups(id),
        );
    }

    *list getOrdersFromKey(softstring key, softstring value) {
        *list rv;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = omqp.selectRows("select wi.workflowid, oik.workflow_instanceid from order_instance_keys oik, "
                    "order_instance oi, workflow_instance wi where oi.workflow_instanceid = oik.workflow_instanceid "
                    "and oi.workflow_instanceid = wi.workflow_instanceid and keyname = %v and value = %v", key, value);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return rv;
    }

    *list getWorkflowSummaryOverview(date date, bool useSqlCache = True, bool with_deprecated = True) {
        return map $1, SnapshotsInfoHelper::getReportWfs(date, NOTHING, with_deprecated, True).contextIterator();
    }

    *hash getWorkflowOverview(date date, *softlist wfids, bool useSqlCache = True, bool with_deprecated = True) {
        return SnapshotsInfoHelper::getReportWfs(date, wfids, with_deprecated);
    }

    *hash<auto> getTags(string t, softint id) {
        *hash q;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                q = omqp.select("select tag, value from %s_tags where %sid = %v", t, t, id);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        *hash h;

        foreach hash<auto> row in (q.contextIterator()) {
            if (row.tag =~ /^_/) {
                splice row.tag, 0, 1;
                h.sys.(row.tag) = row.value;
            } else {
                h.(row.tag) = row.value;
            }
        }

        return h;
    }

    *hash<auto> getServiceMetadata(auto args) {
        string sql;
        if (exists args && exists args[0]) {
            sql = sprintf("select * from services where serviceid in (%s)",
                QorusSystemService::compatDeprecatedMakeSelectList(QorusSystemInfoService::qdriver, args));
        } else {
            sql = "select * from services where (name, created) in (select name, max(created) as created from services group by name)";
        }

        *hash<auto> h;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                h = omqp.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return h;
    }

    *hash<auto> getServiceMetadataFromName(string type, string name, *string ver) {
        type = toupper(type);

        string sql;
        if (!strlen(ver)) {
            sql = sprintf("select * from services where service_type = '%s' and (name, created) in (select name, max(created) as created from services where name = '%s' group by name)",
                           type, name);
        } else {
            sql = sprintf("select * from services where serviceid in (select serviceid from services where service_type = '%s' and name = '%s' and version = '%s')", type, name, ver);
        }

        *hash h;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                h = omqp.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return h;
    }

    *hash<auto> getJobOverview(date date, auto jobids, bool useSqlCache = True) {
        return SnapshotsInfoHelper::getReportJobs(date, jobids);
    }
} # class SQLCommon

%ifndef NO_ORACLE
class SQLOracle inherits SQLCommon {
    hash<auto> processWorkflowMetadata(softint workflowid) {
        *hash result;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                result = omqp.select("begin qorus_system_info.process_workflow_metadata(%v, :keyname, :steps, :step_deps, :seg_deps, :seg_steps, :options, :groups); end;",
                                     workflowid, Type::Hash, Type::Hash, Type::Hash, Type::Hash, Type::Hash, Type::Hash, Type::Hash);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex)) {
                    continue;
                }
                rethrow;
            }
            break;
        }

        result.keyname = result.keyname.keyname;
        result.groups = Qorus.rbac.getWorkflowGroups(workflowid);
        return result;
    }

    hash<auto> getServiceMetadata(*softlist args) {
        *hash r;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                on_error omqp.rollback();
                on_success omqp.commit();

                r = omqp.exec("begin qorus_system_info.get_service_metadata(%v, :resultset); end;",
                                exists args && exists args[0] ? bindOracleCollection("sys.odcinumberlist", args) : NOTHING, Type::Hash);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex)) {
                    continue;
                }
                rethrow;
            }
            break;
        }

        return r.resultset;
    }

    hash<auto> getServiceMetadataFromName(string type, string name, *string ver) {
        *hash r;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                on_error omqp.rollback();
                on_success omqp.commit();

                r = omqp.exec("begin qorus_system_info.get_service_metadata_name(%v, %v, %v, :resultset); end;",
                                    type, name, strlen(ver) ? ver : NULL, Type::Hash);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return r.resultset;
    }

} #SQLOracle
%endif

*hash<auto> sub processMetadata(*hash<auto> q, bool compat, string t) {
    *hash h;

    string idc;
    if (t) {
        idc = t + "id";
    }

    # transform query results into a hash
    context (q) {
        h.%name.%version = %%;
        # delete redundant and empty keys
        h.%name.%version -= ("name", "version");

        foreach string k in (keys h.%name.%version) {
            if (h.%name.%version{k} == NULL && k != "description")
                 delete h.%name.%version{k};
        }

        if (compat) {
            h.%name.%version += ("createdby": "omq", "modifiedby": "omq");
        }

        # get tags
        h.%name.%version.tags = sqlHandler.getTags(t, %%{idc});
    }

    return h;
}

hash<auto> sub processJobMetadataRow(hash row) {
    # delete empty keys
    foreach string k in (row.keyIterator())
        if (row{k} === NULL && k != "description")
            delete row{k};

    row += (
        "jobid": int(row.jobid),
        "sessionid": int(row.sessionid),
        "active": boolean(row.active),
        "run_skipped": boolean(row.run_skipped),
        "groups": Qorus.rbac.getJobGroups(row.jobid),
    );

    return row;
}

*hash<auto> sub processJobMetadata(*hash<auto> q) {
    *hash h;
    # transform query results into a hash
    context (q) {
        h.%name = processJobMetadataRow(%%) + (
            # add library info
            "lib": getLibrary("job_lib", "jobid", %jobid),
            "tags": sqlHandler.getTags("job", %jobid),
        );
    }

    return h;
}

hash<auto> sub postProcessJobInstance(hash job) {
    job.job_instanceid = int(job.job_instanceid);
    job.jobid = int(job.jobid);
    job.sessionid = int(job.sessionid);

    if (job.completed === NULL)
        delete job.completed;

    if (job.info === NULL) {
        delete job.info;
    } else {
        job.info = UserApi::deserializeQorusData(job.info);
    }

    job.jobstatus = OMQ::SQLJSMap.(job.jobstatus);

    return job;
}

hash<string, list<hash<auto>>> sub getLibrary(string table, string key, softint id) {
    # prevent possible SQL injections
    if (!inlist(table, ('workflow_lib', 'service_lib', 'job_lib'))) {
        throw "INFO-GET-LIBRARY-ERROR", sprintf("Unallowed table to select from: %s", table);
    }
    if (!inlist(key, ('workflowid', 'serviceid', 'jobid'))) {
        throw "INFO-GET-LIBRARY-ERROR", sprintf("Unallowed column to be used in WHERE clause: %s", key);
    }

    hash<string, list<hash<auto>>> lib = {
        "functions": (),
        "classes": (),
        "constants": (),
    };
    # get library objects
    string sql = sprintf("select * from %s where %s = %v", table, key);

    *hash<auto> h;
    QorusRestartableTransaction trans();
    while (True) {
        try {
            # we can just release the lock because the query is read-only
            on_error omqp.rollback();

            h = omqp.select(sql, id);
        } catch (hash<ExceptionInfo> ex) {
            # restart the transaction if necessary
            if (trans.restartTransaction(ex)) {
                continue;
            }
            rethrow;
        }
        break;
    }

    context (h) {
        if (%type == OMQ::OT_FUNCTION) {
            *hash<auto> fi = Qorus.qmm.rLookupFunc(%name);
            lib.functions += {
                "name"    : %name,
                "version" : fi.lastversion,
                "id"      : fi.(fi.lastversion),
            };
        } else if (%type == OMQ::OT_CLASS) {
            *hash<auto> ci = Qorus.qmm.rLookupClass(%name);
            lib.classes += {
                "name"    : %name,
                "version" : ci.lastversion,
                "id"      : ci.(ci.lastversion),
            };
        } else if (%type == OMQ::OT_CONSTANT) {
            *hash<auto> ci = Qorus.qmm.rLookupConstant(%name);
            lib.constants += {
                "name"    : %name,
                "version" : ci.lastversion,
                "id"      : ci.(ci.lastversion),
            };
        }
    }
    return lib;
}

# change structure to be like old workflow metadata structure with flows
sub makeCompatWorkflow(reference h, string name, string version) {
    h.initflowid = h.workflowid;
    h.createdby = "omq";
    h.modifiedby = "omq";

    foreach hash step in (\h.steps)
        step += ("createdby":"omq","modifiedby":"omq");

    h.flows[0] = (
        "flowid"            : h.workflowid,
        "name"              : name,
        "version"           : version,
        "description"       : h.description,
        "created"           : h.created,
        "createdby"         : "omq",
        "modified"          : h.modified,
        "modifiedby"        : "omq",
        "steps"             : h.steps,
        "step_dependencies" : h.step_dependencies,
        "flow_segments"     : h.workflow_segments,
        "segments"          : h.segments
    );

    if (exists h.patch)
        h.flows[0].patch = h.patch;

    h.flow_dependencies = (
        "flowid": h.workflowid,
        "dependson_flowid": h.workflowid,
        );

    delete h.step_dependencies;
    delete h.workflow_segments;
    delete h.segments;
    delete h.steps;
}

# return old workflow hash structure, with flow information
*hash sub processWorkflowMetadataCompat(*hash inh) {
    *hash h = processWorkflowMetadata(inh);

    foreach string name in (h.keyIterator()) {
        foreach string version in (h{name}.keyIterator()) {
            # fake old structures with flows
            makeCompatWorkflow(\h{name}{version}, name, version);
        }
    }
    return h;
}

*hash sub processWorkflowMetadata(*hash q) {
    #printf("processWorkflowMetadata() q=%y\n", q);

    hash h;
    # transform query results into a hash
    context wq (q) {
        # delete redundant and empty keys
        hash wh = %% - ("name", "version");
        foreach string k in (wh.keyIterator())
            if (wh{k} === NULL && k != "description")
                 delete wh{k};

        wh.deprecated = boolean(wh.deprecated);
        wh.manual_autostart = boolean(wh.manual_autostart);

        *hash result = sqlHandler.processWorkflowMetadata(%workflowid);

        # get workflow keys
        wh.keylist = result.keyname;

        # get steps
        wh.steps = ();
        context (result.steps) { # sq
            hash s = %%;
            # delete empty keys
            foreach string k in (s.keyIterator()) {
                if (s{k} === NULL) {
                    # delete the key if there is no value, unless it's the description
                    if (k != "description")
                        delete s{k};
                    else {
                        # use the primary function's description
                        hash sh = Qorus.qmm.lookupFunc(%stepfunction_instanceid);
                        s.description = sh.description;
                    }
                }
            }
            if (s.workflow_event_typeid) {
                s.event = Qorus.qmm.lookupEvent(s.workflow_event_typeid) + ("typeid": s.workflow_event_typeid);
                delete s.workflow_event_typeid;
            }
            wh.steps += s;
        }

        # get step dependencies
        wh.step_dependencies = ();
        context (result.step_deps)
            wh.step_dependencies +=
            ( "stepid" : %stepid,
              "dependson_stepid" : %dependson_stepid );

        # get segment dependencies
        wh.workflow_segments = ();
        context (result.seg_deps)
            wh.workflow_segments +=
            ( "segmentid"           : %segmentid,
              "dependson_segmentid" : %dependson_segmentid );

        # get segment-step definitions
        context (result.seg_steps) {
            if (!exists wh.segments.%segmentid)
                wh.segments.%segmentid = ();
            wh.segments.%segmentid += (
                "stepid": %stepid,
                "dependson_stepid": %dependson_stepid,
            );
        }

        # get option info
        hash opts = map {$1.name: $1.description}, result.options.contextIterator();

        if (opts)
            wh.options = opts;

        wh += (
            "lib": getLibrary("workflow_lib", "workflowid", %workflowid),
            "tags": sqlHandler.getTags("workflow", %workflowid),
            );

        h.%name.%version = wh;
    }

    return h;
}

*hash sub processServiceMetadata(*hash q, bool compat) {
    hash h;

    SqlUtil::AbstractTable service_methods = QorusSystemService::getSqlTableSystemTrans("omq", "service_methods");

    # transform query results into a hash
    context (q) {
        h.%name.%version = %% + {
            "autostart": boolean(%autostart),
            "manual_autostart": boolean(%manual_autostart),
        };

        if (compat) {
            h.%name.%version += ("createdby": "omq", "modifiedby": "omq");
        }

        # delete redundant and empty keys
        h.%name.%version -= ("name", "version");

        # return class_source as class_based
        h.%name.%version.class_based = exists remove h.%name.%version.class_source;

        foreach string k in (keys h.%name.%version) {
            if (h.%name.%version{k} == NULL && k != "description") {
                 delete h.%name.%version{k};
            }

        }

        # get method information
        list l = ();

        hash<auto> sql = {
            "columns" : (
                "service_methodid", "name", "description", "author", "locktype", "internal",
                cop_as("writeflag", "write"), "created", "modified",
            ),
            "where": {
                "serviceid" : %serviceid,
            },
        };

        *hash h;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();
                h = service_methods.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex)) {
                    continue;
                }
                rethrow;
            }
            break;
        }
        trans.reset();

        context (h) {
            hash m = %%;
            # delete empty keys
            foreach string k in (keys m) {
                if (m{k} == NULL && k != "description") {
                    delete m{k};
                }
            }

            if (compat) {
                m += ( "createdby" : "omq", "modifiedby" : "omq");
            }

            m.tags = sqlHandler.getTags("service_method", %service_methodid);

            l += m;
        }

        h.%name.%version += (
            "methods": l,
            "lib"    : getLibrary("service_lib", "serviceid", %serviceid),
            "groups" : Qorus.rbac.getServiceGroups(%serviceid),
            "tags": sqlHandler.getTags("service", %serviceid),
        );
    }

    return h;
}

# list of allowable functions in SQL conditions
const SQLWhiteList = ("to_date", "in");

sub do_cond(reference wcond, string k, *softlist l) {
    if (l)
        wcond{k} = l.size() > 1 ? op_in(l) : l[0];
}

# issue #2920 if there is a single element list and no '%' character, then a string may be returned instead of a hash
auto sub do_cond_like_string(softlist l) {
    l = map $1.toString(), l;
    return l.size() > 1 ? op_in(l) : ((l[0] =~ /%/) ? op_like(l[0]) : l[0]);
}

sub do_cond_like_string(reference<hash> wcond, string k, *softlist l, *bool force_like) {
    if (l) {
        l = map $1.toString(), l;
        wcond{k} = (l.size() > 1) ? op_in(l) : ((force_like || l[0] =~ /%/) ? op_like(l[0]) : l[0]);
    }
}

sub do_cond_like(reference<hash> wcond, string k, *softlist l, *bool force_like) {
    if (l)
        wcond{k} = (l.size() > 1) ? op_in(l) : ((force_like || l[0] =~ /%/) ? op_like(l[0]) : l[0]);
}

sub do_cond_int(reference<hash> wcond, string k, *softlist l) {
    if (l)
        wcond{k} = l.size() > 1 ? op_in((map $1.toInt(), l)) : l[0].toInt();
}

sub do_cond_bool(reference<hash> wcond, string k, auto v, bool use_null = False) {
    if (exists v)
        wcond{k} = parse_boolean(v) ? 1 : (use_null ? NULL : 0);
}

# parses a string to an int or a list of int and returns a where condition hash
sub do_cond_int_list(reference<hash> wcond, string k, auto v) {
    if (v.val()) {
        v = v =~ /,/ ? (map $1.toInt(), v.split(",")) : v.toInt();
        wcond{k} = v.lsize() > 1 ? op_in(v) : v;
    }
}

# parses a string to a list or a string with an optional like clause and returns a where condition hash
sub do_cond_string_like_list(reference<hash> wcond, string k, auto v) {
    if (v.val()) {
        if (v =~ /,/)
            v = map trim($1), v.split(",");
        if (v.lsize() > 1)
            wcond{k} = op_in(v);
        else
            wcond{k} = (v =~ /%/) ? op_like(v) : v;
    }
}

sub process_workflow_id_and_name(reference wcond, hash h) {
    if (h.workflowid && h.workflowid =~ /,/)
        h.workflowid = h.workflowid.split(",");
    if (h.workflowname) {
        if (h.workflowname =~ /,/)
            h.workflowname = h.workflowname.split(",");
        foreach string wfn in (h.workflowname) {
            *hash<auto> wh = Qorus.qmm.rLookupWorkflow(wfn);
            # ensure h.workflowid is a list
            if (h.workflowid.typeCode() != NT_LIST) {
                softlist l = h.workflowid;
                h.workflowid = l;
            }
            if (wh)
                # add workflowids from name to workflowid list
                map h.workflowid += $1.workflowid, wh.iterator(), $1.workflowid;
            else if (!h.workflowid)
                # otherwise make sure the search fails
                h.workflowid += -1;
        }
    }

    if (h.workflowid) {
        if (h.workflowid.lsize() > 1)
            wcond.workflowid = op_in(map $1.toInt(), h.workflowid);
        else if (h.workflowid.typeCode() == NT_LIST)
            wcond.workflowid = h.workflowid[0].toInt();
        else
            wcond.workflowid = h.workflowid.toInt();
    }
}

list sub get_wfid_list(list l) {
    list wl = ();
    bool err;
    foreach any wfid in (l) {
        if (wfid != int(wfid)) {
            # try to get a name and verion
            *list l1 = (wfid =~ x/([^:]+)?(:(.*)?)?/);
            my (*string name, *string ver) = (l1[0], l1[2]);
            # ignore empty or invalid strings
            if (!name) {
                continue;
            }

            try {
                # lookup workflowid from workflow name
                if (ver) {
                    wl += Qorus.qmm.getWorkflowId(name, ver);
                } else {
                    hash<auto> wh = Qorus.qmm.rLookupWorkflow(name);
                    wl += map $1.workflowid, wh.iterator(), $1.workflowid;
                }
            } catch (hash<ExceptionInfo> ex) {
                err = True;
                ServiceApi::logDebug("ignoring reference to unknown workflow %y: %s: %s", name, ex.err, ex.desc);
            }
        } else {
            wl += wfid.toInt();
        }
    }
    if (err)
        wl += -1;

    #logDebug("get_wfid_list(%y) rv: %y", l, wl);
    return wl;
}

auto sub get_accessible_workflows(*softlist<auto> l) {
    auto rl;
    if (l) {
        l = get_wfid_list(l);
        rl = l.size() > 1 ? op_in(l) : l[0];
    }

    #logDebug("get_accessible_workflows(%y) rv: %y", l, rl);
    return rl;
}

# SQL data operation logger
sub log_data(string sql, *list args) {
    ServiceApi::logDebug("SQL: %s, args: %y", sql, args);
}

const SqlDataOpt = ("sqlarg_callback": \log_data());

# oracle returns durations in a fraction of a day
# mysql returns durations in the number of seconds
# postgresql returns durations as intervals (true durations)
const ProcIntervalCols = (map $1 + "duration", ("min", "avg", "max")) + (map $1 + "processing", ("min", "avg", "max"));

#! the main info service class
class QorusSystemInfoService inherits QorusSystemService {
    public {
        const SessionColumnMap = {
            "id": "sessionid",
            "key": "instancekey",
            "url": "xmlrpc_server",
            "status": "sessionstatus",
        };

        # setup global sqlHandler object
        static SQLCommon sqlHandler;

        static string qdriver;
    }

    #! initializes the info service
    constructor() {
        qdriver = omqp.getDriverName();

        switch (qdriver) {
%ifndef NO_ORACLE
            case "oracle": {
                sqlHandler = new SQLOracle();
                break;
            }
%endif
            default: {
                sqlHandler = new SQLCommon();
                break;
            }
        }
    }

    #! returns workflow instance status from workflow_instanceid: COMPAT VERSION with fake flow and flow_instance information (removed in Qorus v2); use getWorkflowStatus2() instead
    /** @param id the workflow_instanceid
        @deprecated use getWorkflowStatus2() instead
    */
    static deprecated *hash getWorkflowStatus(softint id) {
        *hash h = QorusSystemInfoService::getWorkflowStatus2(id);
        if (!exists h)
            return;

        hash fi = (
            "flowid"           : h.workflowid,
            "flow_instanceid"  : h.workflow_instanceid,
            "name"             : h.name,
            "version"          : h.version,
            "description"      : h.description,
            "patch"            : h.patch,
            "flowstatus"       : h.workflowstatus,
            "started"          : h.started,
            "completed"        : h.completed,
            "segment_instance" : h.segment_instance,
            "step_instance"    : h.step_instance,
            "createdby"        : "omq",
            "modified"         : h.modified,
            "modifiedby"       : "omq"
            );

        delete h.step_instance;
        delete h.segment_instance;

        h += ("createdby":"omq","modifiedby":"omq");

        h.flow_instance = list(fi);

        return h;
    }

    #! returns workflow order data instance status from the workflow_instanceid
    /** This method will retrieve information directly from the internal server cache if possible, otherwise data is retrieved from the database
        @param wfiid the workflow_instanceid
        @return NOTHING if the workflow_instanceid is not valid, otherwise a hash with the following keys:
        - \c name: the name of the workflow (metadata)
        - \c version: the version of the workflow (metadata)
        - \c workflow_instanceid: the instance id of the workflow order data instance
        - \c workflowstatus: the status of the workflow (see @ref StatusDescriptions for possible values)
        - \c workflowid: the id of the workflow (metadata)
        - \c status_sessionid: either 0 (meaning no Qorus application instance 'owns' the data) or the application sessionid that 'owns' the workflow order data instance (see @ref appsessionmodel)
        - \c parent_workflow_instanceid: the parent workflow_instanceid if the workflow order data instance is a subworkflow instance
        - \c started: the date/time the workflow order data instance was originally created
        - \c completed: the date/time the workflow order data instance received status @ref OMQ::StatComplete
        - \c custom_status: the custom status for the workflow order data instance, if any
        - \c custom_status_desc: the description for the custom status for the workflow order data instance, if any
        - \c scheduled: the date/time the order is scheduled for future execution, if any
        - \c priority: the priority of the order
        - \c segment_instance: a list of hashes for each segment with the following keys:
        - \c segmentid: the segment ID
        - \c segmentstatus: the status of the segment (see @ref StatusDescriptions for possible values)
        - \c created: date/time the segment was created
        - \c modified: date/time the segment was last modified
        - \c steps: a list of stepids in the segment
        - \c step_instance: a hash keyed by stepid of steps in the workflow; each step hash value will have the following keys:
        - \c name: name of the step (step metadata)
        - \c version: version of the step (step metadata)
        - \c steptype: type of the step (step metadata, see @ref StepTypes for possible values)
        - \c arraytype: array attribute of the step (step metadata, see @ref StepArrayTypes for possible values)
        - \c stepid: id of the step (step metadata)
        - \c stepstatus: status of the step (see @ref StatusDescriptions for possible values); note that for array steps with more than 1 element, this will be a composite status according to @ref OMQ::StatusOrder)
        - \c started: date/time the step was first created in the DB
        - \c completed: date/time the step got status @ref OMQ::StatComplete
        - \c custom_status: the custom status for the step, if any
        - \c custom_status_desc: the description for the custom status for the step, if any
        - [\c event]: only present for event steps; if present, this will be a hash with the following keys:
            - \c name: the event type name
            - \c desc: the event type description
            - \c typeid: the event type id
            - [\c key]: if not an arraystep, the event key will be present here
        - [\c subworkflow_instanceid]: only present for subworkflow steps: the workflow_instanceid of the subworkflow bound to the step
        - [\c subworkflowstatus]: only present for subworkflow steps: the status of the subworkflow instance bound to the step
        - [\c substeps]: only present for array steps; if present, this will be a list of hashes with the following keys:
            - \c stepid: same as the stepid in the parent data structure
            - \c ind: the step index number
            - \c stepstatus: the status of the step (see @ref StatusDescriptions for possible values)
            - \c started: date/time the step was first created in the DB
            - \c completed: date/time the step got status @ref OMQ::StatComplete
            - \c eventkey: the eventkey bound to the step, if any
            - \c custom_status: the custom status for the step, if any
            - \c custom_status_desc: the description for the custom status for the step, if any
        - \c errors: a list of hashes with the following keys for errors raised while processing the workflow order data instance
        - \c stepid: the stepid of the step that created the error
        - \c ind: the index of the step
        - \c severity: severity of the error: @ref ErrorSeverityCodes
        - \c error: the error code
        - \c description: description of the error
        - \c info: information about the error
        - \c business_error: True if the error is a business error, False if not
        - \c created: the date/time the error was raised
        - \c workflow_instanceid: the same as the workflow_instanceid of the parent data structure
    */
    static *hash getWorkflowStatus2(softstring wfiid) {
        return SM.getWorkflowInstanceStatus(wfiid);
    }

    #! returns order instance info from workflow_instanceid
    static *hash getOrderInfo(softstring wfiid) {
        return SM.getOrderInfoSummary(wfiid);
    }

    #! returns order instance info from external_order_instanceid
    static *list getOrderInfoFromExternalID(softstring id) {
        return SM.getOrderInfoSQL("external_order_instanceid", id);
    }

    #! returns order instance info from user order key (params: workflowname, workflowversion, keyname, value)
    softlist getOrderInfoFromKey(string name, string version, softstring key, softstring value) {
        # get workflowid
        *softint wfid = Qorus.qmm.rLookupWorkflow(name, version).workflowid;

        if (!wfid) {
            throw "UKNOWN-WORKFLOW", sprintf("no workflow exists with name='%s', version='%s'", name, version);
        }

        hash sql = (
            "columns" : ("workflow_instanceid"),
            "where"   : (
                "workflowid" : wfid,
                "keyname"    : key,
                "value"      : value,
            ),
        );
        SqlUtil::AbstractTable order_instance_keys = getSqlTableSystemTrans("omq", "order_instance_keys");
        *list wfiids;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                wfiids = order_instance_keys.select(sql).workflow_instanceid;
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return map SM.getOrderInfoSummary($1), wfiids;
    }

    #! returns order instance info from the key and value
    static softlist getOrdersFromKey(softstring key, softstring value) {
        # get workflow_instanceids
        *list l = sqlHandler.getOrdersFromKey(key, value);
        return map SM.getOrderInfoSummary($1.workflow_instanceid), l;
    }

    #! returns order instance info from the workflow name, key, and value
    /** @return @ref nothing if there is no match or a list of hashes with the following keys:
        - \c workflowid
        - \c workflow_instanceid
    */
    *list getWorkflowListFromWorkflowKey(string workflow, softstring key, softstring value) {
        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = omqp.selectRows("select wi.workflowid, oik.workflow_instanceid from order_instance_keys oik, "
                    "order_instance oi, workflow_instance wi, workflows w where "
                    "oi.workflow_instanceid = oik.workflow_instanceid "
                    "and oi.workflow_instanceid = wi.workflow_instanceid and keyname = %v "
                    "and value = %v and wi.workflowid = w.workflowid and w.name = %v", key, value, workflow);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return l;
    }

    #! returns all information about a workflow from a user order key (params: workflowname, workflowversion, keyname, value)
    hash getAllInfoFromOrderKey(string name, string version, softstring key, softstring value) {
        hash rv.order = getOrderInfoFromKey(name, version, key, value);
        rv.workflows = ();

        # now retrieve workflow information
        foreach hash wf in (rv.order.workflows)
            rv.workflows += getWorkflowStatus(wf.workflow_instanceid);

        return rv;
    }

    #! gets workflow overview, params: [date, [workflowids]]: If no date is given, default = last 24 hours
    /**
        @throw PARAMETER-ERROR the date passed was not valid

        @param date optional, order instance modified threshold. Items modified in last day are used if it's not given.
        @param wfids optional, list of workflow IDs (not order instances) to be used in search criteria
        @param useSqlCache optional, default True. Unused/deprecated.
        @param with_deprecated if False then no workflows with the deprecated flag set are returned

        @return hash or nothing - grouped information about workflow statuses
    */
    static *hash<auto> getWorkflowOverview(softdate date = now() - 1D, *softlist wfids, softbool useSqlCache = True, softbool with_deprecated = True) {
        # check parameters
        if (date < 1000-01-01)
            throw "PARAMETER-ERROR", sprintf("first parameter must be a valid date or NOTHING (given: %y)", date);

        *hash rv;
        *hash<auto> q = sqlHandler.getWorkflowOverview(date, wfids, useSqlCache, with_deprecated);
        context (q) sortBy (%name) {
            rv.%name.%version.workflowid = %workflowid;
            int t = int(%total);
            rv.%name.%version.(OMQ::SQLStatMap.%workflowstatus) = t;
            rv.%name.%version.TOTAL += t;
        }

        ServiceApi::logDebug("getWorkflowOverview() date: %y wfids: %y cache: %y dep: %y", date, wfids,
            useSqlCache, with_deprecated);

        return rv;
    }

    #! gets workflow overview, params: [date, [name, [version]]]: If no date is given, default = last 24 hours
    /**
        @throw PARAMETER-ERROR the date passed was not valid
        @param date optional, order instance modified threshold. Items modified in last day are used if it's not given.
        @param name optional workflow name to be used in search criteria
        @param version optional workflow version to be used in search criteria
        @param useSqlCache optional, default True. Unused/deprecated.
        @param with_deprecated if False then no workflows with the deprecated flag set are returned

        @return hash or nothing - grouped information about workflow statuses
    */
    static *hash getWorkflowOverviewFromName(softdate date = now() - 1D, *string name, *string version, softbool useSqlCache = True, softbool with_deprecated = True) {
        # check parameters
        if (date < 1000-01-01)
            throw "PARAMETER-ERROR", sprintf("first parameter must be a valid date (given: %y)", date);

        auto wfids;
        if (exists name) {
            *hash wi = Qorus.qmm.rLookupWorkflow(name) - ("lvcreated", "lastversion");
            if (exists version) {
                if (!exists wi{version})
                    throw "UNKNOWN-WORKFLOW", sprintf("workflow %s:%s does not exist", name, version);
                wfids = wi{version}.workflowid;
            } else {
                if (!wi)
                    throw "UNKNOWN-WORKFLOW", sprintf("workflow %s does not exist", name);
                wfids = map wi.$1.workflowid, wi.keyIterator();
            }
            wfids = exists version ? wi{version}.workflowid : map wi.$1.workflowid, wi.keyIterator();
        }

        return QorusSystemInfoService::getWorkflowOverview(date, wfids, useSqlCache, with_deprecated);
    }

    #! gets system overview, params: [date]: If no date is given, default = last 24 hours
    /**
        @throw PARAMETER-ERROR the date passed was not valid

        @param date optional, order instance modified threshold. Items modified in last day are used if it's not given.
        @param useSqlCache optional, default True. Unused/deprecated.
        @param with_deprecated if False then no workflows with the deprecated flag set are returned

        @return hash or nothing - summary workflow status information
    */
    static *list getWorkflowSummaryOverview(softdate date = now() - 1D, softbool useSqlCache = True, softbool with_deprecated = True) {
        # check parameters
        if (date < 1000-01-01)
            throw "PARAMETER-ERROR", sprintf("first parameter must be a valid date or NOTHING (given: %y)", date);

        return sqlHandler.getWorkflowSummaryOverview(date, useSqlCache, with_deprecated);
    }

    #! gets workflow metadata (optional params: list of IDs), returns: hash of workflow metadata keyed by name and then version: COMPAT VERSION with fake flow information (removed in Qorus v2); use getWorkflowMetadata2() instead
    /** @deprecated use getWorkflowMetadata2() instead
    */
    deprecated *hash getWorkflowMetadata() {
        hash sql = (
            "where" : (exists argv ? ("workflowid" : op_in(argv)) : {}),
        );
        AbstractTable wfs = getSqlTableSystemTrans("omq", "workflows");
        *hash rv;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = wfs.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processWorkflowMetadataCompat(rv);
    }

    #! gets workflow metadata (optional params: list of IDs), returns: hash of workflow metadata keyed by name and then version
    /** @return NOTHING if the workflowids are not valid, otherwise a hash keyed by workflow name where the values are hases keyed by workflow version with values as hashes of workflow information having the following keys:
        - \c workflowid: the id of the workflow
        - \c patch: the \c "patch" value of the workflow
        - \c description: the description of the workflow
        - \c errorfunction_instanceid: id of the @ref dep_errorfunction
        - \c attach_func_instanceid: id of the @ref dep_attach
        - \c onetimeinit_func_instanceid: id of the @ref dep_onetimeinit
        - \c created: the date/time the workflow was created in the DB
        - \c modified: the date/time the workflow was last modified in the DB
        - \c keylist: either NOTHING or a list of valid @ref wf_keylist "workflow order keys"
        - \c steps: a list of step hashes defining the steps in the workflow; each step hash will have the following keys:
        - \c stepid: the stepid of the step
        - \c steptype: type of the step (see @ref StepTypes for possible values)
        - \c arraytype: array attribute of the step (see @ref StepArrayTypes for possible values)
        - \c name: name of the step
        - \c version: version of the step
        - [\c patch]: the \c "patch" value of the step
        - \c description: description of the step
        - \c stepfunction_instanceid: id of the @ref dep_primarystepfunc
        - [\c validationfunction_instanceid]: id of the @ref dep_validationfunc
        - [\c endfunction_instanceid]: id of the @ref dep_asyncbackendfunc for asynchronous steps
        - [\c arrayfunction_instanceid]: id of the @ref dep_arrayfunc for array steps
        - [\c queueid]: id of the @ref queue_objects "asynchronous queue" for asynchronous steps
        - \c created: the date/time the step was created in the DB
        - \c modified: the date/time the step was last modified in the DB
        - [\c event]: a hash of event information (present if the steptype = @ref OMQ::ExecEvent):
            - \c name: name of the event type
            - \c desc: description of the event type
            - \c typeid: the event type ID
        - \c step_dependencies: a list of hashes of step dependencies with the following keys:
        - \c stepid: the stepid of the step
        - \c dependson_stepid: the stepid of the step that the step depends on (note that if a hash has \c stepid = \c dependson_stepid, then the step has no dependencies)
        - \c workflow_segments: a list of hashes of segment dependencies with the following keys:
        - \c segmentid: the segmentid of the segment
        - \c dependson_segmentid: the segnentid of the segment that the segment depends on (note that if a hash has \c segmentid = \c dependson_segmentid, then the segment has no dependencies)
        - \c segments: a hash of segments where the keys are segmentids and the values are step dependency lists within that segment; the step dependency list elements are hashes with the following keys:
        - \c stepid: the stepid of the step
        - \c dependson_stepid: the stepid of the step that the step depends on (note that if a hash has \c stepid = \c dependson_stepid, then the step has no dependencies within the given segment)
        - \c options: a hash of options where the keys are the option names, and the values are the option descriptions
        - \c lib: a hash keyed by library object type (key values: \c "functions", \c "classes", \c "constants"); the value of each key will be a list of hashes with the following keys (empty lists mean no objects of that type are listed as library objects of the workflow):
        - \c name: the name of the library object
        - \c version: the version of the library object
        - \c id: the ID of the library object (referencing the tables, \c FUNCTION_INSTANCE, \c CLASSES, or \c CONSTANTS)
        - \c groups: a list of RBAC group names that this service is a member of
    */
    *hash getWorkflowMetadata2() {
        hash sql = {
            "where" : (exists argv ? ("workflowid" : op_in(argv)) : {}),
        };
        AbstractTable wfs = getSqlTableSystemTrans("omq", "workflows");
        *hash rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = wfs.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processWorkflowMetadata(rv);
    }

    #! gets workflow metadata from name and version (params: name, optional: version), returns: hash of workflow metadata keyed by name and then version: COMPAT VERSION with fake flow information; use getWorkflowMetadataFromName2() instead
    /** @deprecated use getWorkflowMetadataFromName2() instead
    */
    *hash getWorkflowMetadataFromName(string name, *string ver) {
        hash sql = {
            "where" : (
                "name" : name,
            ) + (strlen(ver) ? ("version" : ver) : {}),
        };
        AbstractTable wfs = getSqlTableSystemTrans("omq", "workflows");
        *hash rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = wfs.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex)) {
                    continue;
                }
                rethrow;
            }
            break;
        }

        return processWorkflowMetadataCompat(rv);
    }

    #! gets workflow metadata from name and version (params: name, optional: version), returns: hash of workflow metadata keyed by name and then version, new version without flows (removed in Qorus v2)
    /** @param name the name of the workflow
        @param ver the optional version of the workflow to return
        @return see getWorkflowMetadata2() for the definition of the hash returned
    */
    *hash getWorkflowMetadataFromName2(string name, *string ver) {
        hash sql = (
            "where" : (
                "name" : name,
            ) + (strlen(ver) ? ("version" : ver) : {}),
        );
        AbstractTable wfs = getSqlTableSystemTrans("omq", "workflows");
        *hash rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = wfs.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processWorkflowMetadata(rv);
    }

    #! retrieves function data from the function_instanceid (params: function_instanceid), returns: hash of function data keyed by name and then version
    *hash getFunctionInstance(softint fiid, *softdate date) {
        if (!fiid)
            throw "PARAMETER-ERROR", "function_instanceid is a required parameter for info.getFunctionInstance()";

        hash sql = (
            "where" : (
                "function_instanceid" : fiid,
            ) + (exists date ? ("modified" : op_gt(date)) : {}),
        );
        SqlUtil::AbstractTable function_instance = getSqlTableSystemTrans("omq", "function_instance");
        *hash result;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                result = function_instance.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processMetadata(result, True, "function_instance");
    }

    #! retrieves function data from the name and optionally the version (params: name, [version]), returns: hash of function data keyed by name and then version
    *hash getFunctionInstanceFromName(string name, *string ver) {
        hash sql = {
            "where" : (
                "name" : name,
            ) + (strlen(ver) ? ("version" : ver) : {}),
        };
        SqlUtil::AbstractTable function_instance = getSqlTableSystemTrans("omq", "function_instance");
        *hash result;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                result = function_instance.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processMetadata(result, True, "function_instance");
    }

    #! retrieves method data from the service_methodid (params: service_methodid), returns: hash of method data
    /** @param mid the method ID
        @param date if this date is present, then information will only be returned if the method has been modified after the given date
        @return NOTHING if no data is available, or a hash with the following info:
        - \c service_methodid: the method ID (corresponding to the mid argument)
        - \c serviceid: the ID of the service
        - \c name: the method name
        - \c description: the method description
        - \c locktype: the lock attribute for the method, see @ref MethodLockAttributes for possible values
        - \c internal: a flag where 0 = not internal, 1 = internal
        - \c body: the method body
        - \c created: the create date/time of the method record
        - \c modified: the modification date/time of the method record
        - \c write: a flag where 0 = not write, 1 = write
        - \c tags: any service method tags; the special tag \c "sys" is a hash with system tags
    */
    *hash getServiceMethod2(softint mid, *softdate date) {
        hash sql = (
            "where" : (
                "service_methodid" : mid,
            ) + (exists date ? ("modified" : op_gt(compatDeprecatedDbDate(qdriver, date))) : {}),
        );
        SqlUtil::AbstractTable wfs = getSqlTableSystemTrans("omq", "service_methods");
        *hash q;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                q = wfs.selectRow(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        if (!q || !q.firstValue()) {
            return;
        }

        # process query results
        # delete empty keys
        foreach string k in (keys q) {
            if (q{k} == NULL && k != "description") {
                delete q{k};
            }
        }

        # rename "writeflag" column to "write" if present
        if (q.writeflag) {
            q.write = remove q.writeflag;
        }

        q.tags = sqlHandler.getTags("service_method", mid);

        return q;
    }

    #! retrieves method data from the service_methodid (params: service_methodid), returns: hash of method data
    /** @deprecated use getServiceMethod2() instead; this method is the same but provides 2 additional hardcoded fields for backwards-compatibility

        @param mid the method ID
        @param date if this date is present, then information will only be returned if the method has been modified after the given date
        @return NOTHING if no data is available, or a hash with the same keys as the return value of getServiceMethod2() with 2 additional hardcoded fields:
        - \c createdby: hardcoded to \c "omq"
        - \c modifiedby: hardcoded to \c "omq"
    */
    *hash getServiceMethod(softint mid, *softdate date) {
        *hash h = getServiceMethod2(mid, date);

        if (h)
            return h + ( "createdby" : "omq", "modifiedby" : "omq" );
    }

    #! retrieves service metadata (optional params: list of service ids), returns: service info keyed by name. NOTE: if no list is given, only the latest version of each service will be returned
    static *hash getServiceMetadata() {
        *hash r = sqlHandler.getServiceMetadata(argv);
        if (r)
            return processServiceMetadata(r, True);
    }

    #! retrieves service metadata from the type, name and optional version (params: type, name, [version]), returns: service info keyed by name. NOTE: if no version is given, only the latest version will be returned
    static *hash getServiceMetadataFromName(string type, string name, *string ver) {
        if (!type)
            throw "PARAMETER-ERROR", "type is a required parameter for info.getServiceMetadataFromName() (try 'system' or 'user')";

        if (!name)
            throw "PARAMETER-ERROR", "name is a required parameter for info.getServiceMetadataFromName()";

        type = type.upr();
        *hash r = sqlHandler.getServiceMetadataFromName(type, name, ver);
        if (r)
            return processServiceMetadata(r, True);
    }

    #! retrieves function library information as a list of hashes with the keys name, function_instanceid
    static list getLibraryMetadata() {
        return omqp.selectRows("select name, function_instanceid from function_instance where function_type = 'GENERIC' order by name");
    }

    #! gets a list of workflow instance ids (not more than 100 by default, can be overridden with the 4th argument), params: workflowid (single value, list, or NOTHING), date, [statuses, num rows]
    *list getWorkflowInstanceList(*softlist workflowid, *softdate date = now() - 1D, auto stati, softint rownum = OptionHelper::getOption("row-limit")) {
        # check parameters

        if (!rownum)
            rownum = OptionHelper::getOption("row-limit");

        if (date < 1000-01-01)
            throw "PARAMETER-ERROR", sprintf("first parameter must be a valid date (given: %y)", date);

        foreach auto status in (stati) {
            if (!OMQ::StatMap{status})
                throw "PARAMETER-ERROR", sprintf("%y is not a valid workflow status (valid statuses: %y)", status, OMQ::StatMap.keys());
        }

        # map workflow statuses to SQL statuses
        stati = map OMQ::StatMap.$1, stati;

        hash sql = (
            "columns" : ("workflow_instanceid"),
            "where"   : (
                "workflowid" : op_in(workflowid),
                "modified"   : op_ge(date),
            ) + (exists stati ? ("workflowstatus" : op_in(stati)) : {}),
            "limit"   : rownum,
        );
        SqlUtil::AbstractTable workflow_instance = getSqlTableSystemTrans("omq", "workflow_instance");

        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = workflow_instance.select(sql).workflow_instanceid;
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex)) {
                    continue;
                }
                rethrow;
            }
            break;
        }

        return l;
    }

    #! gets a list of workflow instance ids; this is the safe and preferred variant of this method
    /** This is the preferred variant of this method, using safe SQL handling; oview uses this variant

        @param wfids a list of WF ids (or names) or NOTHING
        @param statuses a list with requested statuses in expanded form ('ERROR') or NOTHING
        @param modified a limit (>=) for MODIFIED columnn or NOTHING
        @param rownum limit for max rows
        @param offset the starting row
        @param sort the sorting key for SQL \c "order by"
        @param wfiids zero or more workflow_instanceids to use to filter the results
        @param desc sort the results descending
        @param minstarted the minstarted date
        @param maxstarted the maxstarted date
    */
    list getWorkflowInstances(*softlist wfids, *list statuses, *softdate modified, softint rownum = OptionHelper::getOption("row-limit"), *int offset, *softlist sort, *softlist wfiids, *softbool desc, *date minstarted, *date maxstarted) {
        logDebug("getWorkflowInstances: wfids: %y statuses: %y mod: %y rownum: %y sort: %y offset: %y wfiids: %y desc: %y", wfids, statuses, modified, rownum, sort, offset, wfiids, desc);

        AbstractTable workflows = Qorus.dsmanager.getOmqTable("workflows");
        AbstractTable workflow_instance = Qorus.dsmanager.getOmqTable("workflow_instance");

        if (sort) {
            # process sort keys
            bool hwf;
            foreach string k in (\sort) {
                k = k.lwr();
                if (!workflows.describe().hasKey(k) && !workflow_instance.describe().hasKey(k))
                    throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k, (workflows.describe().getHash() + workflow_instance.describe().getHash()).keys());
                if (k == "workflow_instanceid")
                    hwf = True;
            }

            # the sort key must also have a unique column to ensure consistent sort order
            if (!hwf)
                sort += "workflow_instanceid";
        }

        hash wcond;

        if (wfiids)
            wcond.workflow_instanceid = op_in(wfiids);

        if (statuses)
            wcond.workflowstatus = op_in(map OMQ::StatMap.$1, statuses);

        if (exists modified)
            wcond.modified = op_ge(modified);

        if (minstarted)
            wcond.started = op_ge(minstarted);
        if (maxstarted)
            wcond."1:started" = op_lt(maxstarted);

        list wl = ();
        if (wfids)
            wl = wfids;

        if (wl) {
            list wnl = ();
            list wil = ();
            foreach auto e in (wl) {
                if (e =~ /[a-z]/i)
                    wnl += e;
                else
                    wil += e;
            }
            if (wil)
                wcond.workflowid = op_in(wil);
            if (wnl)
                wcond."w.name" = op_in(wnl);
        }

        hash sh = (
            "comment": "qorus.info.getWorkflowInstances",
            "columns": ("w.name", "w.version", "workflow_instanceid", "workflowid", "workflowstatus", "status_sessionid", "started", "completed", "modified", "parent_workflow_instanceid", "synchronous", "business_error", "operator_lock", "note_count", cop_as("warnings", "warning_count"), cop_as("errors", "error_count"), "custom_status", "priority", "scheduled"),
            "where": wcond,
            "join": join_inner(workflows, "w"),
            "limit": rownum,
            "offset": offset,
            "orderby": sort,
            "desc": desc,
        );

        #logDebug("SH: %N opt: %y", sh, SqlDataOpt);

        *list sqlresult;

        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                sqlresult = workflow_instance.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessar
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        if (sqlresult)
            sqlresult = SM.processWorkflowResults(sqlresult);

        return sqlresult;
    }

    #! gets a list of workflow instance ids, params: workflowid, condition, number of rows (100 default)
    /** @param workflowid a WF id or 0
        @param condition a string with any SQL condition used in WHERE clause
        @param rownum limit for max rows

        @deprecated use the variant taking a workflow ID list instead
    */
    deprecated list getWorkflowInstances(softint workflowid, *string condition, int rownum = OptionHelper::getOption("row-limit")) {
        logDebug("getWorkflowInstances: wfid: %y condition: %y rownum: %y", workflowid, condition, rownum);

        # wfiid related condition - all use %v binding from workflowidsqlBind
        string workflowidsql;
        # a value holder to be bound in workflowidsql later
        auto workflowidsqlBind;

        if (!rownum)
            rownum = OptionHelper::getOption("row-limit");

        if (workflowid > 0) {
            workflowidsql = " where wi.workflowid = %v ";
            workflowidsqlBind = int(workflowid);
        }
        else {
            # failsafe - binding failback for no value required.
            workflowidsql = " where %v=1 ";
            workflowidsqlBind = 1;
        }

        hash h;
        if (exists condition) {
            h = processCondition(\condition);
            if (strlen(condition))
                splice condition, 0, 0, " and ";
        }

        string sql = sprintf("select wi.WORKFLOW_INSTANCEID, wi.WORKFLOWID,
    wi.WORKFLOWSTATUS, wi.STATUS_SESSIONID, wi.STARTED, wi.COMPLETED,
    wi.MODIFIED, wi.PARENT_WORKFLOW_INSTANCEID, wi.SYNCHRONOUS, wi.business_error,
    wi.ARCHIVE, wi.WARNINGS as \"warning_count\", wi.ERRORS as \"error_count\", wi.custom_status, priority, scheduled, operator_lock, note_count
    from workflow_instance wi %s %s %s%s%s",
                h.join_oi ? "join order_instance oi on wi.WORKFLOW_INSTANCEID = oi.WORKFLOW_INSTANCEID" : "",
                h.join_oik ? "left join order_instance_keys oik on wi.WORKFLOW_INSTANCEID = oik.WORKFLOW_INSTANCEID" : "",
                workflowidsql,
                condition,
                qdriver == "oracle" ? " and rownum <= %v" : " limit %v"
        );
    #    logInfo("SQL: %s\nARGs: %N %N", sql, workflowidsqlBind, rownum);
        *list sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                sqlresult = omqp.selectRows(sql, workflowidsqlBind, rownum);
                #printf("sql=%s\nresult=%y\n", sql, sqlresult);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                throw "DATABASE_ERROR", sprintf("%s %s: SQL: %y", ex.err, ex.desc, sql);
            }
            break;
        }

        if (sqlresult)
            sqlresult = SM.processWorkflowResults(sqlresult, True);

        return sqlresult;
    }

    #! retrieves workflow instances from a key value and optional key name
    *list getWorkflowInstancesByKeyValue(softlist val, *softstring key, *softlist wfids, *softlist statuses, *date modified, softint rownum = OptionHelper::getOption("row-limit"), *int offset, *softlist sort, *softlist wfiids, *softbool desc, *date minstarted, *date maxstarted) {
        logDebug("getWorkflowInstancesBtKeyValue: val: %y key: %y wfids: %y statuses: %y mod: %y rownum: %y sort: %y offset: %y wfiids: %y desc: %y", val, key, wfids, statuses, modified, rownum, sort, offset, wfiids, desc);

        AbstractTable workflows = Qorus.dsmanager.getOmqTable("workflows");
        AbstractTable workflow_instance = Qorus.dsmanager.getOmqTable("workflow_instance");
        AbstractTable order_instance_keys = Qorus.dsmanager.getOmqTable("order_instance_keys");

        if (sort) {
            # process sort keys
            bool hwf;
            foreach string k in (\sort) {
                k = k.lwr();
                if (!workflows.describe().hasKey(k) && !workflow_instance.describe().hasKey(k))
                    throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k, (workflows.describe().getHash() + workflow_instance.describe().getHash()).keys());
                if (k == "workflow_instanceid")
                    hwf = True;
            }

            # the sort key must also have a unique column to ensure consistent sort order
            if (!hwf)
                sort += "workflow_instanceid";
        }

        hash wcond;

        if (val.size() > 1)
            wcond."oik.value" = op_in(val);
        else {
            auto v = val[0];
            if (v =~ /%/)
                wcond."oik.value" = op_like(v);
            else
                wcond."oik.value" = v;
        }

        if (wfiids)
            wcond.workflow_instanceid = op_in(wfiids);

        if (statuses)
            wcond.workflowstatus = op_in(map OMQ::StatMap.$1, statuses);

        if (exists modified)
            wcond.modified = op_ge(modified);

        if (minstarted)
            wcond.started = op_ge(minstarted);
        if (maxstarted)
            wcond."1:started" = op_lt(maxstarted);

        if (key)
            wcond."oik.keyname" = key;

        if (wfids)
            wcond.workflowid = op_in(wfids);

        hash sh = (
            "comment": "qorus.info.getWorkflowInstancesByKeyValue",
            "columns": ("w.name", "w.version", "workflow_instanceid", "workflowid", "workflowstatus", "status_sessionid", "started", "completed", "modified", "parent_workflow_instanceid", "synchronous", "business_error", "operator_lock", "note_count", cop_as("warnings", "warning_count"), cop_as("errors", "error_count"), "custom_status", "priority", "scheduled"),
            "join": (join_inner(order_instance_keys, "oik") + join_inner(workflows, "w")),
            "where": wcond,
            "limit": rownum,
            "offset": offset,
            "orderby": sort,
            "desc": desc,
        );

        #logDebug("SH: %N\n", sh);

        *list sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                sqlresult = workflow_instance.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        if (sqlresult)
            sqlresult = SM.processWorkflowResults(sqlresult);

        return sqlresult;
    }

    private *list searchWorkflowInstancesPriv(string dsname, hash h) {
        AbstractTable workflows = getSqlTableSystemTrans(dsname, "workflows");
        AbstractTable workflow_instance = getSqlTableSystemTrans(dsname, "workflow_instance");

        if (!h.limit)
            h.limit = OptionHelper::getOption("row-limit");

        if (h.desc)
            h.desc = parse_boolean(h.desc);

        if (h.sort) {
            if (h.sort && h.sort =~ /,/)
                h.sort = h.sort.split(",");

            # process sort keys
            bool hwf;
            foreach string k in (\h.sort) {
                k = k.lwr();
                if (!workflows.describe().hasKey(k) && !workflow_instance.describe().hasKey(k))
                    throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k,
                        (workflows.describe().getHash() + workflow_instance.describe().getHash()).keys());
                if (k == "workflow_instanceid")
                    hwf = True;
            }

            # the sort key must also have a unique column to ensure consistent sort order
            if (!hwf) {
                if (h.sort.typeCode() != NT_LIST)
                    h.sort = list(h.sort);
                h.sort += "workflow_instanceid";
            }
        } else if (h.desc)
            h.sort = "workflow_instanceid";

        hash jh = join_inner(workflows, "w");

        hash wcond;

        if (h.keyvalue) {
            jh += join_inner(getSqlTableSystemTrans(dsname, "order_instance_keys"), "oik");

            if (h.keyvalue && h.keyvalue =~ /,/) {
                h.keyvalue = h.keyvalue.split(",");
            }

            if (h.keyvalue.lsize() > 1) {
                # issue #25.1: ensure that key values are strings for the DB query
                wcond."oik.value" = op_in(map $1.toString(), h.keyvalue);
            } else {
                if (h.keyvalue =~ /%/) {
                    wcond."oik.value" = op_like(h.keyvalue);
                } else {
                    # issue #25.1: ensure that key values are strings for the DB query
                    wcond."oik.value" = h.keyvalue.toString();
                }

                if (h.keyname) {
                    if (h.keyname =~ /%/)
                        wcond."oik.keyname" = op_like(h.keyname);
                    else
                        wcond."oik.keyname" = h.keyname;
                }
            }
        }

        if (h.workflow_instanceid) {
            if (h.workflow_instanceid && h.workflow_instanceid =~ /,/)
                h.workflow_instanceid = h.workflow_instanceid.split(",");

            if (h.workflow_instanceid.lsize() > 1)
                wcond.workflow_instanceid = op_in(map $1.toInt(), h.workflow_instanceid);
            else
                wcond.workflow_instanceid = h.workflow_instanceid.toInt();
        }

        if (h.status) {
            h.status = h.status.upr();
            # make into a list
            if (h.status && h.status =~ /,/) {
                h.status = h.status.split(",");
            }

            wcond.workflowstatus = op_in(map OMQ::StatMap.$1, h.status);
        }

        if (h.modified.val())
            wcond.modified = op_ge(date(h.modified));

        if (h.maxmodified.val())
            wcond."1:modified" = op_lt(date(h.maxmodified));

        if (h.minstarted.val())
            wcond.started = op_ge(date(h.minstarted));
        if (h.maxstarted.val())
            wcond."1:started" = op_lt(date(h.maxstarted));

        process_workflow_id_and_name(\wcond, h);

        hash sh = (
            "comment": "qorus.info.searchWorkflowInstances",
            "columns": ("w.name", "w.version", "workflow_instanceid", "workflowid", "workflowstatus", "status_sessionid", "started", "completed", "modified", "parent_workflow_instanceid", "synchronous", "business_error", "operator_lock", "note_count", cop_as("warnings", "warning_count"), cop_as("errors", "error_count"), "custom_status", "priority", "scheduled"),
            "join": jh,
            "where": wcond,
            "limit": h.limit,
            "offset": h.offset,
            "orderby": h.sort,
            "desc": h.desc,
        );

        #logDebug("SH: %N\n", sh);

        *list sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                sqlresult = workflow_instance.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        if (sqlresult)
            sqlresult = SM.processWorkflowResults(sqlresult);

        return sqlresult;
    }

    #! searches for workflow order instances according to a hash
    /** @param h a hash of search parameters with the following keys (all are optional):
        - \c keyname: the name of a search key to be used with the \a keyvalue value(s)
        - \c keyvalue: the value(s) of workflow order search key(s) to use (optionally used in conjunction with \a keyname)
        - \c workflowname: all versions of the given workflow name
        - \c workflowid: workflowid values(s)
        - \c workflow_instanceid: workflow_instanceid values(s)
        - \c status: status value(s)
        - \c modified: minimum modified date
        - \c maxmodified: maximum modified date
        - \c minstarted: minimum start date
        - \c maxstarted: maximum start date
        - \c limit: max number of rows to return, if not given, then the value of the \a "row-limit" option is used (default: 100)
        - \c offset: row offset
        - \c sort: columns for sorting the results
        - \c desc: return in descending order

        @return @ref nothing if no rows match or a list of hashes with the following keys:
        - \c name: the name of the workflow
        - \c version: the version of the workflow
        - \c workflow_instanceid: the workflow order instance ID
        - \c workflowid: the workflow ID
        - \c workflowstatus: the status of the workflow order instance
        - \c status_sessionid: the application session ID that owns the workflow order instance data or 0 if the data is now owned by any application session
        - \c started: the start date/time of the workflow order instance
        - \c completed: the completed date/time for the workflow order instance
        - \c modified: the last modified date/time of the workflow order instance
        - \c parent_workflow_instanceid: the parent workflow_instanceid if the workflow is a child workflow order
        - \c synchronous: the synchronous flag for the workflow order instance
        - \c business_error: the business error flag for the workflow order instance
        - \c archive: the archive flag for the workflow order instance (presented only if it goes from archive datasource)
        - \c operator_lock: the username of the user owning the lock on the workflow order instance data
        - \c note_count: the number of notes attached to the workflow order instance
        - \c warning_count: the warning count of the workflow order instance
        - \c error_count: the error count of the workflow order instance
        - \c custom_status: any custom status for the workflow order instance
        - \c priority: the priority of the workflow order instance
        - \c scheduled: the scheduled date for the workflow order instance
        - \c archive: if retrieved from the archive datasource

        @since
        - Qorus 3.0.2
        - the \a workflowname option was added in Qorus 3.1
    */
    *list searchWorkflowInstances(*hash h) {
        logDebug("searchWorkflowInstances(): h: %y", h);
        softint expected = h.limit ?? OptionHelper::getOption("row-limit");

        *list ret = searchWorkflowInstancesPriv("omq", h);
        int lsize = ret.lsize();
        if (lsize < expected && (*string dsarch = Qorus.props.get("arch").datasource))
            ret += map $1 + ("archive": True), searchWorkflowInstancesPriv(dsarch, h + ("limit": expected - lsize));
        logDebug("searchWorkflowInstances() returning %d row%s", ret.size(), ret.size() == 1 ? "" : "s");
        return ret;
    }

    #! return the Workflow Instance Overview info, PARAMS: list(hash("ID",[optional: "date"])), RETURN: list(hash(info))
    list getWorkflowInstanceOverview(list wfilist) {
        # inly wfiids
        list wfiIDlist = ();
        # mapping of wfiids to its modified date. (But I still don't get meaning of this selection...)
        hash wfiid2date = {};

        foreach hash obj in (wfilist) {
            push wfiIDlist, obj.ID;

            if (exists obj.ID) {
                wfiid2date{obj.ID} = obj.date;
            }
        } # foreach

        string sql;
        auto args;
        if (qdriver == "oracle") {
%ifndef NO_ORACLE
            sql = sprintf("select wi.*,
                    (select count(STEPID) from step_instance si
                        where wi.WORKFLOW_INSTANCEID = si.WORKFLOW_INSTANCEID) as STEPS,
                    (select count(ERROR_INSTANCEID) from error_instance ei
                        where wi.WORKFLOW_INSTANCEID = ei.WORKFLOW_INSTANCEID) as ERRORS
                    from workflow_instance wi
                    where wi.WORKFLOW_INSTANCEID in (
                                select column_value
                                    from table(%v)
                            )");
            args = bindOracleCollection("sys.odcinumberlist", wfiIDlist);
%else
            throw "ORACLE-ERROR", "Qore 'oracle' module is mandatory but it's missing";
%endif
        } else {
            sql = sprintf("select wi.*,
                    (select count(STEPID) from step_instance si
                        where wi.WORKFLOW_INSTANCEID = si.WORKFLOW_INSTANCEID) as STEPS,
                    (select count(ERROR_INSTANCEID) from error_instance ei
                        where wi.WORKFLOW_INSTANCEID = ei.WORKFLOW_INSTANCEID) as ERRORS
                    from workflow_instance wi
                    where wi.WORKFLOW_INSTANCEID in (%s)");
            args = compatDeprecatedMakeSelectList(qdriver, wfiIDlist);
        }

        list sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                sqlresult = omqp.selectRows(sql, args);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        if (sqlresult) {
            # remove date related info
            sqlresult = select sqlresult, $1.modified != wfiid2date{$1.workflow_instanceid};
            # process it
            sqlresult = SM.processWorkflowResults(sqlresult);
        }

        return sqlresult;
    }

    #! gets a list of step instances, params: wfiid
    list getStepInstanceList(softint wfiId) {
        # setup closure to process step entries
        code proc = hash sub (hash h) {
            if (h.eventkey === NULL)
                h -= ("eventkey", "workflow_event_typeid");

            h += (
                "stepstatus"      : OMQ::SQLStatMap.(h.stepstatus),
                "flow_instanceid" : h.workflow_instanceid,
                "business_error"  : (h.retries == -1 ? True : False),
                "retries"         : (h.retries >= 0 ? h.retries : "0"),
                ) - "workflow_instanceid";

            return h;
        };

        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = omqp.selectRows("select * from step_instance natural left join step_instance_events where workflow_instanceid = %v order by started, ind", wfiId);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        # issue 1777: ensure that array steps are ordered by ind
        return map proc($1), l;
    }

    #! gets a list of error instances, params: wfiid, [stepId, ind]
    list getErrorInstanceList(softint wfiid, *softint stepId, *softint ind) {
        string sql = sprintf("select ei.*
            from error_instance ei
            where ei.workflow_instanceid = %v%s%s order by error_instanceid",
            exists stepId ? " and stepid = %v" : "",
            exists ind ? " and ind = %v" : ""
            );

        list sqlargs = ();
        push sqlargs, wfiid;
        if (exists stepId)
            push sqlargs, stepId;
        if (exists ind)
            push sqlargs, ind;

        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = omqp.vselectRows(sql, sqlargs);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return map $$ + ("business_error":boolean($1.business_error)), l;
    }

    #! gets a list of error instances, params: wfiid, [stepId]
    list getErrorInstanceListByWFIID(softint wfiid, *softint stepId) {
        string sql = sprintf("select ei.*
            from error_instance ei
            where ei.workflow_instanceid = %v%s order by error_instanceid",
            exists stepId ? " and stepid = %v" : ""
            );

        list sqlargs = ();
        push sqlargs, wfiid;
        if (exists stepId)
            push sqlargs, stepId;

        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = omqp.vselectRows(sql, sqlargs);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return map $$ + ("business_error":boolean($1.business_error)), l;
    }

    #! retrieves class data from a classid; returns: hash of class data keyed by name and then version
    *hash<auto> getClass(softint classid, *softdate date) {
        AbstractTable classes = getSqlTableSystemTrans("omq", "classes");

        # do not use hash<auto> here
        hash class_sh = {
            "where": {"classid": classid},
        };
        if (exists date) {
            class_sh."where".modified = op_gt(date);
        }

        *hash<auto> h;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                string sql;
                h = classes.select(class_sh, \sql);

                # get required classes from the cache
                if (!h.classid) {
                    return;
                }
                softlist<softint> required_classid_list = Qorus.qmm.lookupClass(h.classid[0]).requires;
                if (required_classid_list) {
                    hash<string, bool> required_hash;
                    QorusSystemInfoService::getClassesIntern((map {$1: True}, required_classid_list), classes, \required_hash);
                    if (required_hash) {
                        # must wrap this to be a list in query (hash of lists) format
                        h.requires = ((map $1.toInt(), keys required_hash),);
                    }
                }
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processMetadata(h, True, "class");
    }

    static private getClassesIntern(hash<string, bool> classid_hash, AbstractTable classes, reference<hash<string, bool>> req_classes) {
        # make sure we get classes only once
        # remove all classes we already have
        classid_hash -= (keys req_classes);
        if (!classid_hash) {
            return;
        }
        req_classes += classid_hash;

        foreach string classid in (keys classid_hash) {
            # get required classes from the cache
            softlist<softstring> classid_list = Qorus.qmm.lookupClass(classid).requires;
            if (classid_list) {
                QorusSystemInfoService::getClassesIntern((map {$1: True}, classid_list), classes, \req_classes);
            }
        }
    }

    #! retrieves class data from the class name and optional version (params: name, [version]), returns: hash of class data keyed by name and then version
    static *hash getClassFromName(string name, *string ver) {
        if (!strlen(name))
            throw "PARAMETER-ERROR", "name is a required parameter for info.getClassFromName()";

        string sql = "select * from classes where name = %v";
        list sqlargs = ();
        push sqlargs, name;

        if (strlen(ver)) {
            sql += " and version = %v";
            push sqlargs, ver;
        }

        *hash h;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                h = omqp.vselect(sql, sqlargs);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processMetadata(h, True, "class");
    }

    #! retrieves constant data from the constantid (params: constantid), returns: hash of constant data keyed by name and then version
    static *hash getConstant(softint constantid, *softdate date) {
        if (!constantid)
            throw "PARAMETER-ERROR", "constantid is a required parameter for info.getConstant()";

        string sql = "select * from constants where constantid = %v";
        list sqlargs = ();
        push sqlargs, constantid;

        if (exists date) {
            sql += " and modified > %v";
            push sqlargs, date;
        }

        *hash h;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                h = omqp.vselect(sql, sqlargs);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processMetadata(h, True, "constant");
    }

    #! retrieves constant data from the constant name and optional version (params: name, [version]), returns: hash of constant data keyed by name and then version
    static *hash getConstantFromName(string name, *string ver) {
        if (!strlen(name))
            throw "PARAMETER-ERROR", "name is a required parameter for info.getConstantFromName()";

        string sql = "select * from constants where name = %v";
        list sqlargs = ();
        push sqlargs, name;

        if (strlen(ver)) {
            sql += sprintf(" and version = %v", ver);
            push sqlargs, ver;
        }

        *hash h;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                h = omqp.vselect(sql, sqlargs);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processMetadata(h, True, "constant");
    }

    #! gets step metadata (optional params: list of IDs), returns: hash of step metadata information keyed by name and then version
    *hash getStepMetadata() {
        hash sh = {
            "where": {
                "stepid": op_in(argv),
            },
        };

        *hash h;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                AbstractTable t = getSqlTableSystem("omq", "steps");
                h = t.select(sh);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processMetadata(h, True, "step");
    }

    private *hash getTreeWithWorkflowInstancePriv(string dsname, softint wfiid, softbool full = False,
            softbool compat = True) {
        AbstractTable workflows = getSqlTableSystemTrans(dsname, "workflows");
        AbstractTable workflow_instance = getSqlTableSystemTrans(dsname, "workflow_instance");

        # NOTE: any changes here have to be reflected in SegmentManager::getTreeWithWorkflowInstanceIntern()
        # select hash; join on workflows
        hash sh;

        if (!full)
            sh.columns = ("workflowstatus", "workflow_instanceid", "parent_workflow_instanceid", "subworkflow");
        else {
            sh.join = join_inner(workflows, "w");
            sh.columns = ("*", "w.name", "w.version");
        }

        # get the topmost parent
        string sql = "select workflowid, parent_workflow_instanceid as pwid from workflow_instance wi where "
            "workflow_instanceid = %v";
        auto rs;
        int pwid = wfiid;
        AbstractDatasource ds = dsname == "omq" ? omqp : getDatasourcePool(dsname);
        QorusRestartableTransaction trans();
        do {
            *hash rv;

            while (True) {
                try {
                    # we can just release the lock because the query is read-only
                    on_error omqp.rollback();

                    rv = ds.selectRow(sql, pwid);
                } catch (hash<ExceptionInfo> ex) {
                    # restart the transaction if necessary
                    if (trans.restartTransaction(ex))
                        continue;
                    rethrow;
                }
                break;
            }
            trans.reset();

            rs = int(rv.pwid);
            if (rs > 0)
                pwid = rs;
        } while (rs > 0);

        # get the root node
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rs = workflow_instance.selectRows(sh + {
                    "comment" : "qorus.info.getTreeWithWorkflowInstance",
                    "where": ("workflow_instanceid": pwid),
                    "limit": 1,
                }, SqlDataOpt)[0];
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }
        trans.reset();

        if (!rs)
            return;

        remove rs{"workflowid_1", "name_1", "version_1", "modified_1"};
        rs.subworkflow = boolean(rs.subworkflow);

        # fetch & build the tree
        hash wiTree{pwid} = rs;

        if (full) {
            wiTree{pwid} = (
                "name": rs.name,
                "version": rs.version,
                ) + wiTree{pwid} + (
                "workflowstatus":     OMQ::SQLStatMap.(rs.workflowstatus),
                "custom_status_desc": Qorus.qmm.lookupWorkflow(rs.workflowid).custom_statuses{rs.custom_status},
                "business_error":     boolean(rs.business_error),
                "priority":           int(rs.priority),
                "synchronous": rs.synchronous.toBool(),
                "enabled": boolean(rs.enabled),
                "deprecated": boolean(rs.deprecated),
                "autostart": rs.autostart,
                "manual_autostart": boolean(rs.manual_autostart),
                "max_instances": rs.max_instances,
                "open": rs.open.toBool(),
                "remote": rs.remote.toBool(),
                "manual_remote": rs.manual_remote.toBool(),
                "has_detach": rs.has_detach.toBool(),
            ) + (compat ? ("createdby": "omq", "modifiedby": "omq") : NOTHING);
        }

        # now fetch and build a tree
        list toFetch = list(pwid);

        while (toFetch) {
            list l = toFetch;
            toFetch = ();
            while (l) {
                list pl = extract l, 0, 180;
                while (True) {
                    try {
                        # we can just release the lock because the query is read-only
                        on_error omqp.rollback();

                        rs = workflow_instance.select(sh + {
                            "comment": "qorus.info.getTreeWithWorkflowInstance",
                            "where": ("parent_workflow_instanceid": op_in(pl)),
                        }, SqlDataOpt);
                    } catch (hash<ExceptionInfo> ex) {
                        # restart the transaction if necessary
                        if (trans.restartTransaction(ex))
                            continue;
                        rethrow;
                    }
                    break;
                }
                trans.reset();

                remove rs{"workflowid_1", "name_1", "version_1", "modified_1"};

                # fill the values
                context (rs) {
                    hash h = %% + ("subworkflow": boolean(%subworkflow));
                    if (full) {
                        wiTree.%workflow_instanceid = (
                            "name": %name,
                            "version": %version,
                        ) + h + (
                            "workflowstatus": OMQ::SQLStatMap.%workflowstatus,
                            "custom_status_desc":
                                Qorus.qmm.lookupWorkflow(%workflowid).custom_statuses{%custom_status},
                            "business_error": boolean(%business_error),
                            "priority": %priority ?? 500,
                            "synchronous": h.synchronous.toBool(),
                            "enabled": boolean(h.enabled),
                            "deprecated": boolean(h."deprecated"),
                            "autostart": h.autostart,
                            "manual_autostart": boolean(h.manual_autostart),
                            "max_instances": h.max_instances,
                            "open": h.open.toBool(),
                            "remote": h.remote.toBool(),
                            "manual_remote": h.manual_remote.toBool(),
                            "has_detach": h.has_detach.toBool(),
                            ) + (compat ? ("createdby": "omq", "modifiedby": "omq") : NOTHING);
                    } else
                        wiTree.%workflow_instanceid = h;
                } # if elements rs
                # next party to fetch
                toFetch += rs.workflow_instanceid;
            }
        } # while

        # issue 1719 sort hierarchy info in "children-first" order
        return SM.sortHierarchy(wiTree);
    }

    #! retrieves tree view like structure that contains specific instanceid (params: wfiid)
    *hash getTreeWithWorkflowInstance(softint wfiid, softbool full = False, softbool compat = True) {
        *hash ret = getTreeWithWorkflowInstancePriv("omq", wfiid, full, compat);
        if (ret)
            return ret;
        *string dsarch = Qorus.props.get("arch").datasource;
        if (dsarch)
            ret = getTreeWithWorkflowInstancePriv(dsarch, wfiid, full, compat);
        return ret;
    }

    #! Retrieves all workflow instance info (params: wfiid, [last_modified]; output hash keys: InstanceInfo, OrderInfo, StepInstances, ErrorInstances, LastModified
    /** @param wfiid the workflow instance ID of the order
        @param last_modified only retrieve information if changed after this date (if the argument is present); note that this argument is ignored if the workflow order data is cached; in this case, all information are returned and this argument is ignored
        @param compat add keys for backwards-compatibility with very old versions of Qorus
        @param with_sensitive_data also return @ref sensitive_data in the \c OrderInfo key

        @return NOTHING if the workflow instance ID does not exist, otherwise a hash is returned with the following keys:
        - \c InstanceInfo: information about the workflow order; see getWFIInstanceInfo() return value for the value of this key see the \c OrderInfo key also
        - \c OrderInfo: information about the actual order information
        - \c StepInstances: information about steps in the current workflow order
        - \c ErrorInstances: information about errors raised against the workflow order
        - \c HierarchyInfo: information about all parent and/or child workflows related to this workflow order
        - \c AuditEvents: if any audit events were created for the given job instance, they will appear as hashes in a list assigned to this key; the hashes will have the following keys:
        - \c audit_eventid: the audit event ID (unique key in the \c AUDIT_EVENTS table)
        - [\c related_audit_eventid]: related audit event ID
        - \c audit_event_code: the audit event code (see @ref AuditEventCodes for possible values)
        - [\c audit_user_event]: the user audit event code string (present only when \c audit_event_code is @ref OMQ::AE_USER_EVENT)
        - [\c reason]: the reason for the event
        - \c who: the initiator of the event
        - \c source: a string describing the source of the event
        - [\c info1]: an informational string about the event
        - [\c info2]: an informational string about the event
        - \c created: the date/time the audit event was created
        - \c event: the string description corresponding to the \c audit_event_code (see @ref AuditEventStrings for possible values)
        - \c LastModified: the last modified date of the workflow order if the data is retrieved from the DB, otherwise the current date and time if the information was retrieved form the workflow order cache

        @throw SENSITIVE-DATA-ERROR this exception is thrown when \a with_sensitive_data is @ref True "True" and the request is received over an insecure connection

        @since Qorus 3.1.1 this API supports retrieving sensitive data over internal and encrypted connections by authorized users
    */
    *hash<auto> getWFIAllInfo(softint wfiid, *softdate last_modified, softbool compat = True, softbool with_sensitive_data = False) {
        # ensure that sensitive data is only returned over a secure connection and by an authorized user
        if (with_sensitive_data) {
            verifySensitiveDataRequestRo();
        }

        #logDebug("getWFIAllInfo() cx: %N", get_call_context());
        *hash result = SM.getWFIAllInfo(wfiid, last_modified, compat, with_sensitive_data);

        if (result) {
            return result;
        }

        *hash InstanceInfo = QorusSystemInfoService::getWFIInstanceInfo(wfiid, last_modified, compat);
        if (!exists InstanceInfo) {
            return;
        }

        *hash HierarchyInfo   = QorusSystemInfoService::getTreeWithWorkflowInstance(wfiid, True, compat);
        *date LastModified    = InstanceInfo.LastModified;

        *hash OrderInfo       = QorusSystemInfoService::getWFIOrderInfo(wfiid, last_modified, compat,
            with_sensitive_data);
        LastModified          = LastModified > OrderInfo.LastModified ? LastModified : OrderInfo.LastModified;

        *hash StepInstances   = QorusSystemInfoService::getWFIStepInstances(wfiid, last_modified, compat);
        LastModified          = LastModified > StepInstances.LastModified ? LastModified : StepInstances.LastModified;

        *hash ErrorInstances  = QorusSystemInfoService::getWFIErrorInstances(wfiid, last_modified, compat);
        LastModified          = LastModified > ErrorInstances.LastModified ? LastModified : ErrorInstances.LastModified;

        if (InstanceInfo) {
            result.InstanceInfo = InstanceInfo.InstanceInfo;
        }
        if (OrderInfo) {
            result.OrderInfo = OrderInfo.OrderInfo;
        }
        if (StepInstances) {
            result.StepInstances = StepInstances.StepInstances;
        }
        if (ErrorInstances) {
            result.ErrorInstances = ErrorInstances.ErrorInstances;
        }
        if (HierarchyInfo) {
            result.HierarchyInfo = HierarchyInfo;
        }

        result.AuditEvents = SM.getWorkflowAuditEventsSQL(wfiid);

        if (LastModified) {
            result.LastModified = LastModified;
        }

        return result;
    }

    private *hash getWFIInstanceInfoPriv(string dsname, softint wfiid, *softdate last_modified,
            softbool compat = True) {
        if (!wfiid) {
            throw "PARAMETER-ERROR", "Missing workflow instance id";
        }

        hash<auto> wh += {
            "workflow_instanceid": wfiid,
        };
        if (exists last_modified) {
            wh.modified = op_gt(last_modified);
        }

        *hash<auto> InstanceInfo;
        AbstractDatasource ds = dsname == "omq" ? omqp : getDatasourcePool(dsname);
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                AbstractTable workflow_instance = QorusSystemService::getSqlTableSystem(dsname, "workflow_instance");
                InstanceInfo = workflow_instance.selectRow({"where": wh});
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex)) {
                    continue;
                }
                rethrow;
            }
            break;
        }

        #printf("DEBUG getWFIInstanceInfo(wfiid=%d, lmd=%y) sql=%y q=%y\n", wfiid, last_modified, sql, InstanceInfo);

        if (!InstanceInfo) {
            return;
        }

        # add metadata
        {
            *hash<auto> wh = Qorus.qmm.lookupWorkflow(InstanceInfo.workflowid);
            if (!wh) {
                throw "WORKFLOW-ERROR", sprintf("workflowid %d is referenced in the database by "
                    "workflow_instanceid %d, but no such workflow is cached", InstanceInfo.workflowid, wfiid);
            }
            InstanceInfo = wh{
                "name",
                "version",
                "autostart",
                "manual_autostart",
                "deprecated",
                "max_instances",
            } + InstanceInfo;
            if (InstanceInfo.custom_status) {
                InstanceInfo.custom_status_desc = wh.custom_statuses{InstanceInfo.custom_status};
            }
        }

        return (
            "InstanceInfo": InstanceInfo + (
                "workflowstatus": OMQ::SQLStatMap.(InstanceInfo.workflowstatus),
                "business_error": boolean(InstanceInfo.business_error),
                "priority": int(InstanceInfo.priority),
                "synchronous": InstanceInfo.synchronous.toBool(),
            ) + (compat ? ("createdby": "omq", "modifiedby": "omq") : NOTHING),
            "LastModified": InstanceInfo.modified);
    }

    #! Retrieves only workflow instance info (params: wfiid, [last_modified]; output hash keys: InstanceInfo, LastModified
    /** @param wfiid the workflow instance ID of the order
        @param last_modified only retrieve information if changed after this date (if the argument is present)
        @param compat add keys for backwards-compatibility with very old versions of Qorus

        @return NOTHING if the criteria do not match any workflow order, otherwise a hash with the following keys:
        - \c InstanceInfo: a hash with the following keys:
        - \c name: the name of the workflow (metadata)
        - \c version: the version of the workflow (metadata)
        - \c workflow_instanceid: equal to the wfiid argument
        - \c workflowid: the workflowid of the workflow (metadata)
        - \c workflowstatus: the status of the workflow (see @ref StatusDescriptions for possible values)
        - \c status_sessionid: the Qorus application session that the order belongs to or 0 if not owned by any session
        - \c parent_workflow_instanceid: the parent workflow instance ID if this workflow is a subworkflow
        - \c synchronous: 1 for an order currently being executed synchronously
        - \c business_error: \c True if the @ref OMQ::StatError status is due to a business error
        - \c workflowstatus_orig: the original status of the workflow (only if the status is @ref OMQ::StatBlocked or @ref OMQ::StatCanceled; see @ref StatusDescriptions for possible values)
        - \c custom_status: the custom status set for the order (if any)
        - \c scheduled: the scheduled date for the workflow (if any)
        - \c priority: the order priority
        - \c started: the date/time the workflow order was created
        - \c completed: the date/time the workflow order got a @ref OMQ::StatComplete status
        - \c modified: the last modified date/time
        - \c archive: the archive flag for the workflow order instance (presented only if it goes from archive datasource)
        - \c LastModified: the last modified date of the workflow order instance
    */
    *hash getWFIInstanceInfo(softint wfiid, *softdate last_modified, softbool compat = True) {
        *hash ret = getWFIInstanceInfoPriv("omq", wfiid, last_modified, compat);
        if (!ret) {
            *string dsarch = Qorus.props.get("arch").datasource;
            if (!dsarch)
                return ret;
            ret = getWFIInstanceInfoPriv(dsarch, wfiid, last_modified, compat);
            if (ret)
                ret.InstanceInfo.archive = True;
        }
        return ret;
    }

    private *hash getWFIOrderInfoPriv(string dsname, softint wfiid, *softdate last_modified,
            softbool compat = True, softbool with_sensitive_data = False) {
        if (!wfiid)
            throw "PARAMETER-ERROR", "Missing workflow instance id";

        # ensure that sensitive data is only returned over a secure connection and by an authorized user
        if (with_sensitive_data) {
            verifySensitiveDataRequestRo();
        }

        string sql = "select * from order_instance where WORKFLOW_INSTANCEID = %v";
        softlist sqlargs = wfiid;

        if (exists last_modified) {
            # static data will not be returned in case last_modified is present
            sql += " and modified > %v";
            sqlargs += last_modified;
        }

        *hash OrderInfo;
        AbstractDatasource ds = dsname == "omq" ? omqp : getDatasourcePool(dsname);
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                OrderInfo = ds.vselectRow(sql, sqlargs);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                if (Qorus.getDebugSystem())
                    logDebug("SQL: %s", sql);
                rethrow;
            }
            break;
        }
        trans.reset();

        if (!OrderInfo)
            return;

        *date LastModified = OrderInfo.modified;
        OrderInfo += {
            # parse dynamic data
            "dynamicdata": deserializeQorusData(OrderInfo.dynamicdata),

            # parse static data
            "staticdata": deserializeQorusData(OrderInfo.staticdata),
        };

        # issue #2880: get step dynamic data
        {
            AbstractTable t = getSqlTableSystemTrans(dsname, "step_instance_data");
            hash<auto> select_hash = {
                "where": {
                    "workflow_instanceid": wfiid,
                },
                "orderby": ("stepid", "ind"),
            };
            *hash<auto> h;
            while (True) {
                try {
                    on_error omqp.rollback();

                    h = t.select(select_hash);
                } catch (hash<ExceptionInfo> ex) {
                    # restart the transaction if necessary
                    if (trans.restartTransaction(ex))
                        continue;
                    rethrow;
                }
                break;
            }
            trans.reset();

            if (h.stepid.lsize()) {
                # make a hash keyed by stepid
                hash<auto> stepinfo;
                hash<auto> stepdata;
                foreach hash<auto> row in (h.contextIterator()) {
                    if (!stepinfo{row.stepid}) {
                        stepinfo{row.stepid} = Qorus.qmm.lookupStep(row.stepid);
                    }
                    stepdata{row.stepid}[row.ind] = deserializeQorusData(row.data);
                }

                OrderInfo.stepdata = map (stepinfo{$1.key}{"name", "version", "steptype", "arraytype"} + {
                    "stepid": $1.key.toInt(),
                    "data": $1.value,
                }), stepdata.pairIterator();
            }
        }

        # retrieve sensitive data
        {
            AbstractTable t = getSqlTableSystemTrans(dsname, "sensitive_order_data");
            hash wcond = ("workflow_instanceid": wfiid);
            if (with_sensitive_data) {
                hash sd;
                *hash h;
                while (True) {
                    try {
                        on_error omqp.rollback();

                        h = t.select(("where": wcond));
                    } catch (hash<ExceptionInfo> ex) {
                        # restart the transaction if necessary
                        if (trans.restartTransaction(ex))
                            continue;
                        rethrow;
                    }
                    break;
                }
                trans.reset();
                context (h) {
                    string svalue = Qorus.decodeDecryptSensitiveValue(%svalue);
                    string aad = sprintf("%d-%s-%s", wfiid, %skey, svalue);
                    sd{%skey}{svalue}.data = Qorus.deserializeDecryptSensitiveData(%data, %iv, %mac, aad);
                    if (%meta)
                        sd{%skey}{svalue}.meta = Qorus.deserializeDecryptSensitiveData(%meta, %miv, %mmac, aad);
                }
                # get aliases, if any
                if (sd) {
                    t = getSqlTableSystemTrans(dsname, "sensitive_order_data_keys");
                    while (True) {
                        try {
                            on_error omqp.rollback();

                            h = t.select(("where": wcond));
                        } catch (hash<ExceptionInfo> ex) {
                            # restart the transaction if necessary
                            if (trans.restartTransaction(ex))
                                continue;
                            rethrow;
                        }
                        break;
                    }
                    trans.reset();

                    context (h) {
                        string svalue = Qorus.decodeDecryptSensitiveValue(%svalue);
                        reference a = \sd{%skey}{svalue}.aliases;
                        a += a ? %alias : (%alias,);
                    }
                }
                OrderInfo.sensitive_data = sd;
                OrderInfo.has_sensitive_data = boolean(sd);
            } else
                OrderInfo.has_sensitive_data = boolean(t.findSingle(wcond));
        }

        # setup user keys
        if (dsname == "omq") {
            OrderInfo."keys" = SM.getOrderKeysSQL(wfiid);
        } else {
            SqlUtil::AbstractTable t = getSqlTableSystemTrans(dsname, "order_instance_keys");
            hash r;
            while (True) {
                try {
                    # we can just release the lock because the query is read-only
                    on_error omqp.rollback();

                    r = t.select((
                        "columns": ("keyname", "value"),
                        "where": ("workflow_instanceid": wfiid),
                        ));
                } catch (hash<ExceptionInfo> ex) {
                    # restart the transaction if necessary
                    if (trans.restartTransaction(ex))
                        continue;
                    rethrow;
                }
                break;
            }
            trans.reset();

            hash h;
            context (r) {
                if (exists h.%keyname) {
                    if (h.%keyname.typeCode() != NT_LIST)
                        h.%keyname = (h.%keyname, %value);
                    else
                        h.%keyname += %value;
                }
                else
                    h.%keyname = %value;
            }

            OrderInfo."keys" = h;
        }

        if (compat)
            OrderInfo += ("createdby" : "omq", "modifiedby" : "omq");

        return ("OrderInfo" : OrderInfo, "LastModified" : LastModified);
    }

    #! Retrieves workflow instances order info (params: wfiid, [last_modified]; output hash keys: OrderInfo, LastModified
    /**
        @throw SENSITIVE-DATA-ERROR this exception is thrown when \a with_sensitive_data is @ref True "True" and the request is received over an insecure connection

        @since Qorus 3.1.1 this API supports retrieving sensitive data over internal and encrypted connections by authorized users
    */
    *hash getWFIOrderInfo(softint wfiid, *softdate last_modified, softbool compat = True, softbool with_sensitive_data = False) {
        *hash ret = getWFIOrderInfoPriv("omq", wfiid, last_modified, compat, with_sensitive_data);
        if (ret)
            return ret;
        *string dsarch = Qorus.props.get("arch").datasource;
        if (!dsarch)
            return ret;
        return getWFIOrderInfoPriv(dsarch, wfiid, last_modified, compat, with_sensitive_data);
    }

    private *hash getWFIStepInstancesPriv(string dsname, softint wfiid, *softdate last_modified, softbool compat = False) {
        if (!wfiid)
            throw "PARAMETER-ERROR", "Missing workflow instance id";

        string sql = "select si.workflow_instanceid, si.stepid, si.ind, s.name stepname, s.version stepversion, s.steptype,
                                stepstatus, retries, skip, custom_status, started, completed,
                                s.workflow_event_typeid, eventkey, s.stepfunction_instanceid function_instanceid,
                                subworkflow_instanceid, s.user_interaction, s.queueid, q.name as \"queuename\"
                            from step_instance si
                                join steps s on (si.stepid = s.stepid)
                                left join subworkflow_instance swi on (si.workflow_instanceid = swi.workflow_instanceid and si.stepid = swi.stepid and si.ind = swi.ind)
                                left join step_instance_events se on (si.workflow_instanceid = se.workflow_instanceid and si.stepid = se.stepid and si.ind = se.ind)
                                left join queues q on (s.queueid = q.queueid)
                            where si.workflow_instanceid = %v";
        list sqlargs = ();
        push sqlargs, wfiid;

        if (exists last_modified) {
            sql += " and (si.started > %v or si.COMPLETED > %v)";
            push sqlargs, last_modified;
            push sqlargs, last_modified;
        }

        # issue 1777: ensure that array steps are ordered by ind
        sql += " order by si.started, si.ind";

        AbstractDatasource ds = dsname == "omq" ? omqp : getDatasourcePool(dsname);
        *hash sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                on_error omqp.rollback();

                sqlresult = ds.vselect(sql, sqlargs);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                if (Qorus.getDebugSystem())
                    logDebug("SQL: %s", sql);
                rethrow;
            }
            break;
        }

        list StepInstances = ();
        *date LastModified;
        context (sqlresult) {
            hash h = %%;
            if (h.eventkey === NULL)
                h -= ("eventkey", "workflow_event_typeid" );

            h += ("stepstatus" : OMQ::SQLStatMap.%stepstatus);
            if (compat) {
                h.flow_instanceid = h.workflow_instanceid;
                remove h{"workflow_instanceid", "user_interaction", "queueid", "queuename"};
            } else {
                h += {
                    "skip": h.skip.toBool(),
                    "user_interaction": h.user_interaction.toBool(),
                };
                if (!h.queueid) {
                    remove h{"queueid", "queuename"};
                }
            }
            if (h.retries == -1) {
                h.business_error = True;
                h.retries = compat ? "0" : 0;
            } else {
                h.business_error = False;
            }

            StepInstances += h;
            LastModified  = LastModified > %started ? LastModified : %started;
            LastModified  = LastModified > %completed ? LastModified : %completed;
        }

        if (StepInstances)
            return ("StepInstances" : StepInstances, "LastModified" : LastModified);
    }

    #! Retrieves all step info for workflow instance (params: wfiid, [last_modified]; output hash keys: StepInstances, LastModified
    *hash getWFIStepInstances(softint wfiid, *softdate last_modified, softbool compat = False) {
        *hash ret = getWFIStepInstancesPriv("omq", wfiid, last_modified, compat);
        if (!ret) {
            *string dsarch = Qorus.props.get("arch").datasource;
            if (dsarch)
                ret = getWFIStepInstancesPriv(dsarch, wfiid, last_modified, compat);
        }
        return ret;
    }

    private *hash getWFIErrorInstancesPriv(string dsname, softint wfiid, *softdate last_modified, softbool compat = True) {
        if (!wfiid)
            throw "PARAMETER-ERROR", "Missing workflow instance id";

        string sql = "select * from error_instance where WORKFLOW_INSTANCEID = %v";
        list sqlargs = ();
        push sqlargs, wfiid;

        if (exists last_modified) {
            sql += " and created > %v";
            push sqlargs, last_modified;
        }

        sql += " order by error_instanceid";

        AbstractDatasource ds = dsname == "omq" ?  omqp : getDatasourcePool(dsname);
        *hash sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                sqlresult = ds.vselect(sql, sqlargs);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                if (Qorus.getDebugSystem())
                    logDebug("SQL: %s", sql);
                rethrow;
            }
            break;
        }

        list ErrorInstances = ();
        *date LastModified;
        context (sqlresult) {
            # issue #2208: the "info" key must be deserialized from YAML
            ErrorInstances += (%% + ("info": (%info.val() ? deserializeQorusData(%info) : NOTHING), "business_error": boolean(%business_error)) + (compat ? ("createdby": "omq") : NOTHING));
            LastModified  = LastModified > %created ? LastModified : %created;
        }

        if (ErrorInstances)
            return ("ErrorInstances": ErrorInstances, "LastModified": LastModified);
    }

    #! gets workflow instance error info (params: wfiid, [last_modified]; output hash keys: ErrorInstances, LastModified
    *hash getWFIErrorInstances(softint wfiid, *softdate last_modified, softbool compat = True) {
        *hash ret = getWFIErrorInstancesPriv("omq", wfiid, last_modified, compat);
        if (!ret) {
            *string dsarch = Qorus.props.get("arch").datasource;
            if (dsarch)
                ret = getWFIErrorInstancesPriv(dsarch, wfiid, last_modified, compat);
        }
        return ret;
    }

    #! retrieves workflow instances from a workflow name and a key value, returns a list of workflow instance IDs
    *list getWorkflowInstanceListFromWorkflowNameAndKeyValue(string name, softstring val) {
        hash rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = omqp.select("select distinct workflowid, workflow_instanceid from order_instance_keys where workflowid in (select workflowid from workflows where name = %v) and value = %v", name, val);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return rv.workflow_instanceid;
    }

    #! retrieves workflow instances from a workflow name, version, and key value, returns a list of workflow instance IDs
    *list getWorkflowInstanceListFromWorkflowNameVersionAndKeyValue(string name, string version, softstring val) {
        hash rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = omqp.select("select distinct workflowid, workflow_instanceid from order_instance_keys where workflowid in (select workflowid from workflows where name = %v and version = %v) and value = %v", name, version, val);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return rv.workflow_instanceid;
    }

    #! retrieves workflow instances from a key value only, returns a list of workflow instance IDs
    *list getWorkflowInstanceListFromKeyValue(softstring val) {
        hash rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = omqp.select("select distinct workflowid, workflow_instanceid from order_instance_keys where value = %v", val);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return rv.workflow_instanceid;
    }

    #! returns order info from a workflow name and an order key and value (params: workflowname, keyname, value)
    list getOrderInfoList(string name, softstring key, softstring value) {
        if (!Qorus.qmm.rLookupWorkflow(name))
            throw "UKNOWN-WORKFLOW", sprintf("no workflow exists with name %y", name);

        # get workflow_instanceids
        string sql = "select workflow_instanceid
                from order_instance_keys
                where workflowid in (select workflowid from workflows where name = %v)
                    and keyname = %v
                    and value = %v";
        hash q;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                q = omqp.select(sql, name, key, value);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return map SM.getOrderInfoSummary($1.workflow_instanceid), q.contextIterator();
    }

    #! Retrieves only order keys for workflow instance params: wfiid; output: hash
    static *hash getWFIOrderKeysOnly(softint wfiid) {
        return SM.getOrderKeysSQL(wfiid);
    }

    private *list<auto> searchOrderKeysPriv(string dsname, *hash params) {
        AbstractTable workflows = getSqlTableSystemTrans(dsname, "workflows");
        AbstractTable workflow_instance = getSqlTableSystemTrans(dsname, "workflow_instance");
        AbstractTable order_instance_keys = getSqlTableSystemTrans(dsname, "order_instance_keys");

        if (!params.limit)
            params.limit = OptionHelper::getOption("row-limit");

        softlist val = params.orderby;
        if (val) {
            # process sort keys
            hash kh;
            foreach string k in (\val) {
                k = k.lwr();
                kh{k} = True;
                if (workflow_instance.describe().hasKey(k))
                    continue;
                if (workflows.describe().hasKey(k)) {
                    k = "w." + k;
                    continue;
                }
                if (order_instance_keys.describe().hasKey(k)) {
                    k = "oik." + k;
                    continue;
                }

                throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k, (workflows.describe().getHash() + workflow_instance.describe().getHash() + order_instance_keys.describe().getHash()).keys());
            }

            # the sort key must also have a unique column set to ensure consistent sort order
            if (!kh.workflow_instanceid)
                val += "workflow_instanceid";
            if (!kh.keyname)
                val += "oik.keyname";
            if (!kh.value)
                val += "oik.value";

            params.orderby = val;
        }

        if (params.desc) {
            params.desc = parse_boolean(params.desc);
            if (!params.orderby)
                params.orderby = "workflow_instanceid";
        }

        # hash for where condition for SqlUtil
        hash wcond;

        *softdate d = params.mindate.val() ? params.mindate : NOTHING;
        if (d)
            wcond."oik.created" = op_ge(d);
        d = params.maxdate.val() ? params.maxdate : NOTHING;
        if (d)
            wcond."1:oik.created" = op_lt(d);

        val = params.workflowstatus;
        if (val) {
            # convert any long values to short codes
            val = map StatMap.$1 ? StatMap.$1 : $1, val;
            wcond.workflowstatus = val.size() > 1 ? op_in(val) : val[0];
        }

        # process workflow IDs & enforce workflow filter
        process_workflow_id_and_name(\wcond, params);

        if (params.orderkeys) {
            list ol = map ("oik.keyname": $1.key, "oik.value": do_cond_like_string($1.value)), params.orderkeys.pairIterator();
            wcond += call_function_args(\wop_or(), ol);
        } else {
            do_cond_like(\wcond, "oik.keyname", params.keyname);
            do_cond_like_string(\wcond, "oik.value", params.value);
        }

        hash<auto> sh = (
            "comment": "qorus.info.searchOrderKeys",
            "columns": (
                "w.name", "w.version", "workflowid", "workflow_instanceid", "workflowstatus",
                "status_sessionid", "started", "completed", "modified", "parent_workflow_instanceid", "synchronous",
                "business_error", "operator_lock", "note_count", cop_as("warnings", "warning_count"),
                cop_as("errors", "error_count"), "custom_status", "priority", "scheduled", "oik.keyname", "oik.value",
                "oik.created",
            ),
            "join": (join_inner(order_instance_keys, "oik") + join_inner(workflows, "w")),
            "where": wcond,
            "limit": params.limit,
            "offset": params.offset,
            "orderby": params.orderby,
            "desc": params.desc,
        );

        #logDebug("params: %y wcond: %N", params, wcond);

        *list<auto> sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                string sql;
                sqlresult = workflow_instance.selectRows(sh, \sql, SqlDataOpt);
                logInfo("searchOrderKeys() sql: %s", sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        if (sqlresult)
            sqlresult = SM.processWorkflowResults(sqlresult);

        return sqlresult;
    }

    #! returns a list of workflow instance info matching the input criteria
    /** @param params a hash with one or more of the following keys:
        - \c keyname: one or more key names, in case a single value is given and it contains an '%%' character, the SQL like operator is used; this option cannot be used with the \c orderkeys option
        - \c mindate: the minimum creation date for the key (inclusive: ">=")
        - \c maxdate: the maximum creation date for the key (exclusive: "<")
        - \c limit: the maximum number of rows to return
        - \c offset: the offset row number to start returning values
        - \c orderby: one or more column names to order the return values by
        - \c orderkeys: a hash of key names to key values to be combined with \c OR logic; this option cannot be used with the \c keyname or \c value options
        - \c value: the value of the key to find, in case a single value is given and it contains an '%%' character, the SQL like operator is used; this option cannot be used with the \c orderkeys option
        - \c workflowid: one or more workflowids
        - \c workflowname: all versions of the given workflow name
        - \c workflowstatus: one or more workflow order status values

        @return @ref nothing if no rows match or a list of hashes with the following keys:
        - \c workflow_instanceid: the workflow order instance ID
        - \c workflowid: the workflow ID
        - \c name: the name of the workflow
        - \c version: the version of the workflow
        - \c workflowstatus: the status of the workflow order instance
        - \c started: the start date/time of the workflow order instance
        - \c completed: the completed date/time for the workflow order instance
        - \c modified: the last modified date/time of the workflow order instance
        - \c synchronous: the synchronous flag for the workflow order instance
        - \c business_error: the business error flag for the workflow order instance
        - \c archive: the archive flag for the workflow order instance (presented only if it goes from archive datasource)
        - \c operator_lock: the username of the user owning the lock on the workflow order instance data
        - \c note_count: the number of notes attached to the workflow order instance
        - \c warning_count: the warning count of the workflow order instance
        - \c error_count: the error count of the workflow order instance
        - \c custom_status: any custom status for the workflow order instance
        - \c priority: the priority of the workflow order instance
        - \c scheduled: the scheduled date for the workflow order instance
        - \c keyname: the order key name
        - \c value: the order key value
        - \c created: the date/time the order key was created

        @throw SEARCH-ORDER-KEYS-ERROR thrown if the \c orderkeys options and one of both of the \c keyname or \c value options are used in the same call

        @since %Qorus 3.1.1 added support for the \c orderkeys and \c workflowname options
    */
    *list<auto> searchOrderKeys(hash params) {
        if (params.orderkeys) {
            if (params.hasKey("keyname"))
                throw "SEARCH-ORDER-KEYS-ERROR", "info.searchOrderKeys() cannot have both \"orderkeys\" and \"keyname\" options in the same call";
            if (params.hasKey("value"))
                throw "SEARCH-ORDER-KEYS-ERROR", "info.searchOrderKeys() cannot have both \"orderkeys\" and \"value\" options in the same call";
            if (params.orderkeys.typeCode() != NT_HASH)
                throw "SEARCH-ORDER-KEYS-ERROR", sprintf("info.searchOrderKeys() argument \"orderkeys\" passed with type %y; expecting \"hash\"", params.orderkeys.type());
            if (params.orderkeys.size() == 1) {
                params.keyname = params.orderkeys.firstKey();
                params.value = params.orderkeys.firstValue();
                delete params.orderkeys;
            }
        }

        softint expected = params.limit ?? OptionHelper::getOption("row-limit");

        *list ret = searchOrderKeysPriv("omq", params);
        int lsize = ret.lsize();
        if (lsize < expected && (*string dsarch = Qorus.props.get("arch").datasource))
            ret += map $1 + ("archive": True), searchOrderKeysPriv(dsarch, params + ("limit": expected - lsize));
        return ret;
    }

    #! returns a summary of workflow processing for the given time period and optional workflow ID(s)
    /** @param h a hash with the following keys:
        - mindate: (required) the minimum date/time for the processing summary
        - maxdate: (optional) the maximum date/time for the processing summary
        - wfids: (optional) one or more workflowids for the processing summary
        - seconds: (optional) if @ref True "True" then the performance values will be returned in integers representing seconds
        - grouping: (optional) possible values for reporting performance statistics:
        - \c "hourly": hourly grouping
        - \c "daily": daily grouping
        - \c "monthly": monthly grouping
        - \c "yearly": yearly grouping
        - global: (optional) if @ref True "True" then all workflows will be combined into an overall processing report, if @ref False "False" then each workflow gets a separate line in the output
    */
    static *list getWorkflowProcessingSummary(hash h) {
        if (!h.mindate.val())
            throw "ARGUMENT-ERROR", sprintf("missing 'mindate' key in argument hash in the call to info.getWorkflowProcessingSummary(); arg: %y", h);

        # time grouping SqlUtil column operator closure/call ref
        *code tg;
        if (h.grouping) {
            tg = Grouping.(h.grouping);
            if (!tg)
                throw "ARGUMENT-ERROR", sprintf("invalid grouping argument %y; expecting one of: %y", h.grouping, Grouping.keys());
        }

        # hash for where condition for SqlUtil
        hash wcond;

        # process workflow IDs
        h.wfids = get_accessible_workflows(h.wfids);
        if (h.wfids)
            wcond.workflowid = h.wfids;
        #h.wfids.size() > 1 ? op_in(h.wfids) : h.wfids[0].toInt();

        wcond += (
            "started": op_ge(date(h.mindate)),
            "si.segmentid": 0,
            );

        if (h.maxdate.val())
            wcond."1:started" = op_lt(date(h.maxdate));

        bool global = parse_boolean(h.global);

        # column list
        list cols = ();
        # group by list
        list groupby = ();
        # order by list
        list orderby = ();

        if (!global) {
            cols += ("workflowid", "w.name", "w.version");
            groupby += ("workflowid", "w.name", "w.version");
            orderby += "workflowid";
        }

        if (tg) {
            cols += cop_as(tg("started"), "grouping");
            groupby += tg("started");
            orderby += tg("started");
        }

        cols += (
                cop_as(cop_count(), "count"), cop_as(cop_min("started"), "minstarted"),
                cop_as(cop_max("completed"), "maxcompleted"),
                cop_as(cop_min(cop_minus("completed", "started")), "minduration"),
                cop_as(cop_avg(cop_minus("completed", "started")), "avgduration"),
                cop_as(cop_max(cop_minus("completed", "started")), "maxduration"),
                cop_as(cop_min(cop_minus("completed", "si.created")), "minprocessing"),
                cop_as(cop_avg(cop_minus("completed", "si.created")), "avgprocessing"),
                cop_as(cop_max(cop_minus("completed", "si.created")), "maxprocessing"),
            );

        AbstractTable workflows = Qorus.dsmanager.getOmqTable("workflows");
        AbstractTable workflow_instance = Qorus.dsmanager.getOmqTable("workflow_instance");
        AbstractTable segment_instance = Qorus.dsmanager.getOmqTable("segment_instance");

        hash<auto> sh = {
            "comment": "qorus.info.getWorkflowProcessingSummary",
            "columns": cols,
            "join": (join_inner(workflows, "w") + join_inner(segment_instance, "si")),
            "where": wcond,
            "groupby": groupby,
            "orderby": orderby,
        };

        #logDebug("SH: %N\n", sh);

        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = workflow_instance.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return QorusSystemInfoService::processIntervals(l, parse_boolean(h.seconds));
    }

    #! returns a summary of step processing for the given time period and optional step ID(s)
    /** @param h a hash with the following keys:
        - mindate: (required) the minimum date/time for the processing summary
        - maxdate: (optional) the maximum date/time for the processing summary
        - step: (optional) one or more step names
        - stepids: (optional) one or more stepids for the processing summary
        - seconds: (optional) if @ref True "True" then the performance values will be returned in integers representing seconds
        - grouping: (optional) possible values for reporting performance statistics:
        - \c "hourly": hourly grouping
        - \c "daily": daily grouping
        - \c "monthly": monthly grouping
        - \c "yearly": yearly grouping
        - global: (optional) if @ref True "True" then all workflows will be combined into an overall processing report, if @ref False "False" then each workflow gets a separate line in the output
    */
    static *list getStepProcessingSummary(hash h) {
        if (!h.mindate.val())
            throw "ARGUMENT-ERROR", sprintf("missing 'mindate' key in argument hash in the call to info.getWorkflowProcessingSummary(); arg: %y", h);

        # time grouping SqlUtil column operator closure/call ref
        *code tg;
        if (h.grouping) {
            tg = Grouping.(h.grouping);
            if (!tg)
                throw "ARGUMENT-ERROR", sprintf("invalid grouping argument %y; expecting one of: %y", h.grouping, Grouping.keys());
        }

        # hash for where condition for SqlUtil
        hash wcond;

        # process step IDs
        if (h.stepids)
            wcond.stepid = h.stepids;

        if (h.step)
            wcond."s.name" = h.step;

        wcond += (
            "started": op_ge(date(h.mindate)),
            );

        if (h.maxdate.val())
            wcond."1:started" = op_lt(date(h.maxdate));

        bool global = parse_boolean(h.global);

        # column list
        list cols = ();
        # group by list
        list groupby = ();
        # order by list
        list orderby = ();

        if (!global) {
            cols += ("stepid", "s.name", "s.version");
            groupby += ("stepid", "s.name", "s.version");
            orderby += "stepid";
        }

        if (tg) {
            cols += cop_as(tg("started"), "grouping");
            groupby += tg("started");
            orderby += tg("started");
        }

        cols += (
                cop_as(cop_count(), "count"), cop_as(cop_min("started"), "minstarted"),
                cop_as(cop_max("completed"), "maxcompleted"),
                cop_as(cop_min(cop_minus("completed", "started")), "minduration"),
                cop_as(cop_avg(cop_minus("completed", "started")), "avgduration"),
                cop_as(cop_max(cop_minus("completed", "started")), "maxduration"),
            );

        AbstractTable steps = Qorus.dsmanager.getOmqTable("steps");
        AbstractTable step_instance = Qorus.dsmanager.getOmqTable("step_instance");

        hash<auto> sh = {
            "comment": "qorus.info.getStepProcessingSummary",
            "columns": cols,
            "join": (join_inner(steps, "s")),
            "where": wcond,
            "groupby": groupby,
            "orderby": orderby,
        };

        #logDebug("SH: %N\n", sh);

        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = step_instance.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return QorusSystemInfoService::processIntervals(l, parse_boolean(h.seconds));
    }

    private *list searchWorkflowErrorsPriv(string dsname, hash params) {
        logDebug("searchWorkflowErrors(): h: %y", params);

        AbstractTable workflows = getSqlTableSystemTrans(dsname, "workflows");
        AbstractTable workflow_instance = getSqlTableSystemTrans(dsname, "workflow_instance");
        AbstractTable error_instance = getSqlTableSystemTrans(dsname, "error_instance");
        AbstractTable steps = getSqlTableSystemTrans(dsname, "steps");

        softlist val = params.orderby;
        if (val) {
            # process sort keys
            hash kh;
            foreach string k in (\val) {
                k = k.lwr();
                kh{k} = True;
                if (workflow_instance.describe().hasKey(k)) {
                    k = "wi." + k;
                    continue;
                }
                if (workflows.describe().hasKey(k)) {
                    k = "w." + k;
                    continue;
                }
                if (error_instance.describe().hasKey(k))
                    continue;

                throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k, (workflows.describe().getHash() + workflow_instance.describe().getHash() + error_instance.describe().getHash()).keys());
            }

            # the sort key must also have a unique column set to ensure consistent sort order
            if (!kh.error_instanceid)
                val += "error_instanceid";

            params.orderby = val;
        }
        else
            params.orderby = "error_instanceid";

        if (params.desc) {
            params.desc = parse_boolean(params.desc);
            if (!params.orderby)
                params.orderby = "workflow_instanceid";
        }

        # hash for where condition for SqlUtil
        hash wcond;

        do_cond_like(\wcond, "error", params.error);
        do_cond_like(\wcond, "description", params.description);
        # bug 853: info.searchWorkflowErrors() fails on oracle if any value is given to the "info" key
        do_cond_like(\wcond, "info", params.info, qdriver == "oracle");

        do_cond_int(\wcond, "stepid", params.stepid);

        do_cond(\wcond, "severity", params.severity);

        do_cond(\wcond, "s.name", params.stepname);
        do_cond(\wcond, "s.version", params.stepversion);

        do_cond_bool(\wcond, "retry", params.retry);
        do_cond_bool(\wcond, "business_error", params.business_error, True);

        do_cond_int(\wcond, "wi.workflow_instanceid", params.workflow_instanceid);
        do_cond_int(\wcond, "error_instanceid", params.error_instanceid);

        *softdate d = params.mindate.val() ? params.mindate : NOTHING;
        if (d)
            wcond."created" = op_ge(d);
        d = params.maxdate.val() ? params.maxdate : NOTHING;
        if (d)
            wcond."1:created" = op_lt(d);

        val = params.workflowstatus;
        if (val) {
            # convert any long values to short codes
            val = map StatMap.$1 ? StatMap.$1 : $1, val;
            wcond."wi.workflowstatus" = val.size() > 1 ? op_in(val) : val[0];
        }

        # process workflow IDs
        params.workflowid = get_accessible_workflows(params.workflowid);
        if (params.workflowid)
            wcond."wi.workflowid" = params.workflowid;

        if (!params.limit)
            params.limit = OptionHelper::getOption("row-limit");

        hash sh = (
            "comment": "qorus.info.searchWorkflowErrors",
            "columns": ("w.name", "w.version", "wi.workflow_instanceid", "wi.workflowid", "stepid", cop_as("s.name", "stepname"), cop_as("s.version", "stepversion"), "ind", "wi.workflowstatus", "wi.started", "wi.completed", "wi.parent_workflow_instanceid", "wi.custom_status", "wi.priority", "wi.scheduled", "error_instanceid", "error", "description", "info", "severity", "created", "retry", "business_error"),
            "join": (join_inner(workflow_instance, "wi") + join_inner("wi", workflows, "w", ("workflowid": "workflowid")) + join_inner(steps, "s", ("stepid": "stepid"))),
            "where": wcond,
            "limit": params.limit,
            "offset": params.offset,
            "orderby": params.orderby,
            "desc": params.desc,
        );

        #logDebug("SH: %N", sh - "join");

        *list sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                sqlresult = error_instance.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        if (sqlresult) {
            sqlresult = SM.processWorkflowResults(sqlresult);
            sqlresult = map $1 + ("info": deserializeQorusData($1.info)), sqlresult;
        }

        return sqlresult;
    }

    #! returns a list of matching errors for the input criteria
    /** @param h a hash with the following keys:
        - orderby: one or more field names for sorting the output
        - error: the error text to search (can also include '%%' characters for use with the LIKE operator; in this case only 1 value can be given)
        - description: the description text to search (can also include '%%' characters for use with the LIKE operator; in this case only 1 value can be given)
        - info: the info text to search (can also include '%%' characters for use with the LIKE operator; in this case only 1 value can be given
        - stepid: limit the search to one or more stepids
        - severity: limit the search to one or more severity values
        - name: limit the search to one or more step names
        - version: limit the search to one or more step versions
        - retry: limit the search to errors with or without the retry flag
        - business_error: limit the search to errors with or without the business_error flag
        - workflow_instanceid:  limit the search to one or more workflow_instanceids
        - error_instanceid: mit the search to one or more error_instanceids
        - mindate: give the lower date range for the error search
        - maxdate: give the upper date range for the error search
        - workflowid: limit the search to one or more workflowids
        - workflowstatus: limit the search to workflow instances with the given status value(s)
        - limit: the maximum number of errors to return; note that if this parameter is not given then the \c row-limit option is assumed
        - offset: the starting error to return (use when paging for example)

        @return @ref nothing if no rows match or a list of hashes with the following keys:
        - \c name: the workflow name
        - \c version: the workflow version
        - \c workflow_instanceid: the workflow order instance ID
        - \c workflowid: the workflow ID
        - \c stepid: the stepid of the step where the error was raised (could be @ref null if the error was not raised in a workflow step)
        - \c stepname: the step name of the step where the error was raised (could be @ref null if the error was not raised in a workflow step)
        - \c stepversion: the step version of the step where the error was raised (could be @ref null if the error was not raised in a workflow step)
        - \c ind: the step array index (starting from 0) of the step where the error was raised (could be @ref null if the error was not raised in a workflow step)
        - \c workflowstatus: the status of the workflow order instance
        - \c started: the start date/time of the workflow order instance
        - \c completed: the completed date/time for the workflow order instance
        - \c parent_workflow_instanceid: the parent workflow_instanceid if the workflow is a child workflow order
        - \c custom_status: any custom status for the workflow order instance
        - \c priority: the priority of the workflow order instance
        - \c scheduled: the scheduled date for the workflow order instance
        - \c error_instanceid: the error ID
        - \c error: the error name
        - \c description: the error description
        - \c info: the error info string
        - \c severity: the severity of the error
        - \c created: the created date and time of the error
        - \c retry: indicates if the error will get a retry status
        - \c business_error: indicates if the error is a business error
        - \c archive: if retrieved from the archive datasource
    */
    softlist searchWorkflowErrors(hash h) {
        logDebug("searchWorkflowErrors(): h: %y", h);

        softint expected = h.limit ?? OptionHelper::getOption("row-limit");
        softlist ret = searchWorkflowErrorsPriv("omq", h);
        int lsize = ret.lsize();
        if (lsize < expected && (*string dsarch = Qorus.props.get("arch").datasource))
            ret += map $1 + ("archive": True), searchWorkflowErrorsPriv(dsarch, h + ("limit": expected - lsize));
        return ret;
    }

    private *list searchReleasesPriv(string dsname, *hash params) {
        logDebug("searchReleases(): h: %y", params);

        AbstractTable releases = getSqlTableSystemTrans(dsname, "releases");
        AbstractTable release_files = getSqlTableSystemTrans(dsname, "release_files");
        AbstractTable release_file_contents = getSqlTableSystemTrans(dsname, "release_file_contents");

        params.with_files = parse_boolean(params.with_files);
        params.with_components = parse_boolean(params.with_components);

        if (!params.limit)
            params.limit = OptionHelper::getOption("row-limit");

        softlist val = params.orderby;
        if (val) {
            # process sort keys
            hash kh;
            foreach string k in (\val) {
                k = k.lwr();
                kh{k} = True;
                if (releases.describe().hasKey(k))
                    continue;

                if (release_files.describe().hasKey(k)) {
                    params.with_files = True;

                    k = "rf." + k;
                    continue;
                }
                if (release_file_contents.describe().hasKey(k)) {
                    params.with_files = True;
                    params.with_components = True;
                    k = "rfc." + k;
                    continue;
                }

                hash vkh = releases.describe().getHash();
                if (params.with_files) {
                    vkh += release_files.describe().getHash();
                    if (params.with_components)
                        vkh += release_file_contents.describe().getHash();
                }
                throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k, vkh.keys());
            }

            # the sort key must also have a unique column set to ensure consistent sort order
            if (!kh.release_name)
                val += "release_name";

            params.orderby = val;
        }
        else
            params.orderby = "release_name";

        # columns for select
        list cols = ("release_name", "description", "os_user", "os_host", "created", "modified");

        # hash for where condition for SqlUtil
        hash wcond;

        do_cond(\wcond, "release_name", params.name);

        if (params.file_name) {
            params.with_files = True;
            do_cond_like(\wcond, "rf.file_name", '%' + params.file_name + '%');
        }

        {
            *softdate d = params.mindate.val() ? params.mindate : NOTHING;
            if (d)
                wcond.created = op_ge(d);
            d = params.maxdate.val() ? params.maxdate : NOTHING;
            if (d)
                wcond."1:created" = op_lt(d);

            d = params.file_mindate.val() ? params.file_mindate : NOTHING;
            if (d) {
                params.with_files = True;
                wcond."rf.created" = op_ge(d);
            }
            d = params.file_maxdate.val() ? params.file_maxdate : NOTHING;
            if (d) {
                params.with_files = True;
                wcond."1:rf.created" = op_lt(d);
            }

            d = params.content_mindate.val() ? params.content_mindate : NOTHING;
            if (d) {
                params.with_files = True;
                params.with_components = True;
                wcond."rfc.created" = op_ge(d);
            }
            d = params.content_maxdate.val() ? params.content_maxdate : NOTHING;
            if (d) {
                params.with_files = True;
                params.with_components = True;
                wcond."1:rfc.created" = op_lt(d);
            }
        }

        if (params.component) {
            params.with_files = True;
            params.with_components = True;
            do_cond_like(\wcond, "rfc.component", '%' + params.component + '%');
        }

        if (params.with_components)
            params.with_files = True;

        hash jh;
        if (params.with_files) {
            cols += ("rf.file_name", "rf.file_type", "rf.in_db",
                    cop_as("rf.hash_type", "file_hash_type"), cop_as("rf.hash", "file_hash"),
                    cop_as("rf.created", "file_created"), cop_as("rf.modified", "file_modified"),
                );

            jh = join_inner(release_files, "rf");
            if (params.with_components) {
                cols += (cop_as("rfc.id", "content_id"), "rfc.component", "rfc.component_version", "rfc.component_id",
                        cop_as("rfc.hash_type", "component_hash_type"), cop_as("rfc.hash", "component_hash"),
                        cop_as("rfc.created", "component_created"), cop_as("rfc.modified", "component_modified"),
                    );
                do_cond(\wcond, "rfc.component", params.component);
                jh += join_inner("rf", release_file_contents, "rfc");
            }
        }

        QorusRestartableTransaction trans();

        # issue #1931: first get release names to ensure that "limit" and "offset" apply only to the releases table
        {
            list c = ("release_name",);
            list groupby = c;

            c += cop_count();

            hash sh = (
                "comment": "qorus.info.searchReleases-1",
                "columns": c,
                "where": wcond,
                "join": jh,
                "limit": params.limit,
                "offset": params.offset,
                "groupby": groupby,
            );
            string sql;
            hash h;
            while (True) {
                try {
                    # we can just release the lock because the query is read-only
                    on_error omqp.rollback();

                    h = releases.select(sh, \sql);
                } catch (hash<ExceptionInfo> ex) {
                    # restart the transaction if necessary
                    if (trans.restartTransaction(ex))
                        continue;
                    rethrow;
                }
                break;
            }
            trans.reset();
            wcond.release_name = op_in(h.release_name);
            #logDebug("searchReleases SQL 0: %s; releases: %y", sql, wcond.release_name);
        }

        hash sh = (
            "comment": "qorus.info.searchReleases-2",
            "columns": cols,
            "where": wcond,
            "join": jh,
        );

        string sql;
        *list l;
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = releases.selectRows(sh, \sql, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }
        #logDebug("searchReleases sh: %y SQL 1: %s", sh, sql);
        return l[0].hasKey("in_db") ? (map $1 + ("in_db": boolean($1.in_db)), l) : l;
    }

    #! returns release info
    /** @param params search parameters with the following optional keys:
        - \c component: the component name to search for (implies <tt>with_files = True</tt> and <tt>with_components = True</tt>)
        - \c component_maxdate: give the upper date range for the release search for component (implies <tt>with_files = True</tt> and <tt>with_components = True</tt>)
        - \c component_mindate: give the lower date range for the release search for component (implies <tt>with_files = True</tt> and <tt>with_components = True</tt>)
        - \c file_maxdate: give the upper date range for the release search for files (implies <tt>with_files = True</tt>)
        - \c file_mindate: give the lower date range for the release search for files (implies <tt>with_files = True</tt>)
        - \c file_name: the file name to search for; note that this is used with the SQL like operator (implies <tt>with_files = True</tt>)
        - \c limit: the maximum number of releases to return
        - \c maxdate: give the upper date range for the release search
        - \c mindate: give the lower date range for the release search
        - \c offset: the starting release to return (use when paging for example)
        - \c with_components: if @ref True then file components are included (implies <tt>with_files = True</tt>)
        - \c with_files: if @ref True then release files are included
        */
    *list searchReleases(*hash params) {
        softint expected = params.limit ?? OptionHelper::getOption("row-limit");

        *list ret = searchReleasesPriv("omq", params);
        int lsize = ret.lsize();
        if (lsize < expected && (*string dsarch = Qorus.props.get("arch").datasource))
            ret += map $1 + ("archive": True), searchReleasesPriv(dsarch, params + ("limit": expected - lsize));
        return ret;
    }

    private *list searchSessionsPriv(string dsname, *hash params) {
        logDebug("searchSessions(): h: %y", params);

        AbstractTable sessions = getSqlTableSystemTrans(dsname, "sessions");

        if (!params.limit)
            params.limit = OptionHelper::getOption("row-limit");

        softlist val = params.orderby;
        if (val) {
            Columns c = sessions.describe();
            # process sort keys
            hash kh;
            foreach string k in (\val) {
                k = k.lwr();
                bool desc;
                if (k[0] == "-") {
                    k = k.substr(1);
                    desc = True;
                }
                string key = SessionColumnMap{k} ?? k;
                if (desc)
                    kh{"-" + key} = True;
                else
                    kh{key} = True;
                if (c.hasKey(key))
                    continue;

                throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k, c.keys());
            }

            # the sort key must also have a unique column set to ensure consistent sort order
            if (!kh.sessionid)
                kh.sessionid = True;

            params.orderby = kh.keys();
        }
        else
            params.orderby = "sessionid";

        # columns for select
        list cols = (cop_as("sessionid", "id"), cop_as("instancekey", "key"), cop_as("sessionstatus", "status"),
            "hostname", cop_as("xmlrpc_server", "url"), "version", "started", "ended");

        # hash for where condition for SqlUtil
        hash wcond;

        if (params.hasKey("id"))
            do_cond(\wcond, "sessionid", params.id.toInt());
        do_cond(\wcond, "instancekey", params.key);
        do_cond(\wcond, "version", params.version);
        do_cond(\wcond, "hostname", params.hostname);
        do_cond(\wcond, "status", params.sessionstatus);
        do_cond(\wcond, "xmlrpc_server", params.url);

        {
            *softdate d = params.started_mindate.val() ? params.started_mindate : NOTHING;
            if (d)
                wcond."started" = op_ge(d);
            d = params.started_maxdate.val() ? params.started_maxdate : NOTHING;
            if (d)
                wcond."1:started" = op_lt(d);
            d = params.ended_mindate.val() ? params.ended_mindate : NOTHING;
            if (d)
                wcond."ended" = op_ge(d);
            d = params.ended_maxdate.val() ? params.ended_maxdate : NOTHING;
            if (d)
                wcond."1:ended" = op_lt(d);
        }

        hash sh = (
            "comment": "qorus.info.searchSessions",
            "columns": cols,
            "where": wcond,
            "limit": params.limit,
            "offset": params.offset,
            "orderby": params.orderby,
            "desc": params.desc,
        );

        #logDebug("sh: %N", sh);
        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = sessions.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return l;
    }

    #! returns information about application sessions
    /** @param params search parameters with the following optional keys:
        - \c ended_maxdate: give the upper date range for the session end date
        - \c ended_mindate: give the lower date range for the session end date
        - \c hostname: the hostname to search for
        - \c id: the session ID
        - \c key: the instance key name
        - \c limit: the maximum number of releases to return
        - \c started_maxdate: give the upper date range for the session start date
        - \c started_mindate: give the lower date range for the session start date
        - \c offset: the starting release to return (use when paging for example)
        - \c status: one or more session status values
        - \c url: the HTTP URL for the instance
        - \c version: the Qorus version string
        */
    *list searchSessions(*hash params) {
        softint expected = params.limit ?? OptionHelper::getOption("row-limit");

        *list ret = searchSessionsPriv("omq", params);
        int lsize = ret.lsize();
        if (lsize < expected && (*string dsarch = Qorus.props.get("arch").datasource))
            ret += map $1 + ("archive": True), searchSessionsPriv(dsarch, params + ("limit": expected - lsize));
        return ret;
    }

    #! returns a hash of event type names with lists of unposted events for each, params: event ID(s), [last modified date]
    /** @param ids NOTHING or one or more event type IDs to check
        @param lastmod an optional last modified date; if present, then only records modified after the given date will be returned
        @param rownum maximum rowz returned
        @param offset row offset for return values
        @return NOTHING if no events are available, or a hash keyed by the event type name where each value is a list of event keys
    */
    *hash getUnpostedEvents(*softlist ids, *softdate lastmod = now() - 6M, softint rownum = OptionHelper::getOption("row-limit"), *int offset) {
        AbstractTable workflow_events = getSqlTableSystemTrans("omq", "workflow_events");
        AbstractTable workflow_event_types = getSqlTableSystemTrans("omq", "workflow_event_types");

        hash wcond = (
            "modified": op_gt(lastmod),
            "event_posted": 0,
        );

        if (ids)
            wcond.workflow_event_typeid = op_in(ids);

        hash sh = (
            "comment": "qorus.info.getUnpostedEvents",
            "columns": ("t.name", "eventkey"),
            "where": wcond,
            "join": join_inner(workflow_event_types, "t"),
            "limit": rownum,
            "offset": offset,
        );

        hash q;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                q = workflow_events.select(sh);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        hash h;
        context (q) {
            if (!exists h.%name)
                h.%name = ();
            h.%name += %eventkey;
        }

        return h;
    }

    #! returns a hash of event type names with lists of unposted events for each, params: event type name, [last modified date]
    /** @param eventname the event type name to query
        @param lastmod an optional last modified date; if present, then only records modified after the given date will be returned
        @return NOTHING if no events are available, or a hash keyed by the event type name where each value is a list of event keys

        @throw UNKNOWN-EVENT the event name passed is invalid
    */
    *hash getUnpostedEventsFromName(string eventname, *softdate lastmod) {
        # get event type id

        *softint id = Qorus.qmm.rLookupEvent(eventname).workflow_event_typeid;
        if (!id)
            throw "UNKNOWN-EVENT", sprintf("event %y cannot be mapped to an event type ID", eventname);

        return getUnpostedEvents(id, lastmod);
    }

    private list searchEventsPriv(string dsname, *hash h) {
        AbstractTable workflow_events = getSqlTableSystemTrans(dsname, "workflow_events");
        AbstractTable workflow_event_types = getSqlTableSystemTrans(dsname, "workflow_event_types");

        if (!h.limit)
            h.limit = OptionHelper::getOption("row-limit");

        if (h.desc)
            h.desc = parse_boolean(h.desc);

        if (h.sort) {
            if (h.sort && h.sort =~ /,/)
                h.sort = h.sort.split(",");

            # process sort keys
            bool he;
            foreach string k in (\h.sort) {
                k = k.lwr();
                if (!workflow_event_types.describe().hasKey(k) && !workflow_events.describe().hasKey(k))
                    throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k, (workflow_event_types.describe().getHash() + workflow_events.describe().getHash()).keys());
                if (k == "eventkey")
                    he = True;
            }

            # the sort key must also have a unique column to ensure consistent sort order
            if (!he) {
                if (h.sort.typeCode() != NT_LIST)
                    h.sort = (h.sort,);
                h.sort += "eventkey";
            }
        } else if (h.desc)
            h.sort = "eventkey";

        hash wcond;

        if (h.posted.val())
            wcond.event_posted = h.posted.toInt();

        if (h.modified.val())
            wcond.modified = op_ge(date(h.modified));
        if (h.maxmodified.val())
            wcond."1:modified" = op_lt(date(h.maxmodified));

        if (h.eventkey)
            wcond.eventkey = h.eventkey;
        if (h.eventname)
            wcond."t.name" = h.eventname;

        if (h.id && h.id =~ /,/)
            h.id = h.id.split(",");

        if (h.id) {
            if (h.id.lsize() > 1)
                wcond.workflow_event_typeid = op_in(map $1.toInt(), h.id);
            else if (h.id.typeCode() == NT_LIST)
                wcond.workflow_event_typeid = h.id[0].toInt();
            else
                wcond.workflow_event_typeid = h.id.toInt();
        }

        # do not return the default system event
        wcond."1:workflow_event_typeid" = op_ne(0);

        hash sh = {
            "comment": "qorus.info.getEvents",
            "columns": (cop_as("workflow_event_typeid", "id"), cop_as("t.name", "eventname"), "eventkey", cop_as("event_posted", "posted"), "created", "modified"),
            "where": wcond,
            "join": join_inner(workflow_event_types, "t"),
            "limit": h.limit,
            "offset": h.offset,
        };

        string sql;
        *list l;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                l = map ($1 + ("posted": $1.posted.toBool())), workflow_events.selectRows(sh, \sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        #logDebug("searchEvents: sql: %s", sql);
        return l;
    }

    #! returns workflow synchronization event information
    /** @param h a hash with the following optional keys:
        - \c "desc": return in descending order
        - \c "eventkey": the event key name
        - \c "eventname": the event type name
        - \c "id": one or more event type IDs
        - \c "limit": max number of rows to return, if not given, then the value of the \a "row-limit" option is used (default: 100)
        - \c "maxmodified": maximum modified date
        - \c "modified": minimum modified date
        - \c "offset": row offset
        - \c "posted": the event posted status
        - \c "sort": columns for sorting the results

        @since Qorus 3.1.0
    */
    list searchEvents(*hash h) {
        #logDebug("searchEvents(): h: %y", h);
        softint expected = h.limit ?? OptionHelper::getOption("row-limit");

        *list ret = searchEventsPriv("omq", h);
        int lsize = ret.lsize();
        if (lsize < expected && (*string dsarch = Qorus.props.get("arch").datasource))
            ret += map $1 + ("archive": True), searchEventsPriv(dsarch, h + ("limit": expected - lsize));
        return ret;
    }

    #! gets job overview, params: [date, [jobids]]: If no date is given, default = last 24 hours
    /** @param date the minimum date to check for changes; job_instance rows with a modified date before this date will not be reported; the default value is 24 hours from the current date and time
        @param jobids the jobs IDs to query
        @param useSqlCache if the sql cache should be used

        @return NOTHING if no information is available, otherwise a hash where the keys are job names and the values are hashes with the following keys:
        - \c jobid: the jobid of the job
        - \c version: the version of the job
        - [\c COMPLETE]: the number of job instances with status @ref OMQ::JS_Complete in the given time frame
        - [\c ERROR]: the number of job instances with status @ref OMQ::JS_Complete in the given time frame
        - [\c IN-PROGRESS]: the number of job instances with status @ref OMQ::JS_InProgress in the given time frame (should never be > 1 for a given job)
        - [\c CRASH]: the number of job instances with status @ref OMQ::JS_Crash in the given time frame

        @throw PARAMETER-ERROR the date passed was not valid
    */
    static *hash getJobOverview(softdate date = now() - 1D, auto jobids, bool useSqlCache = True) {
        # check parameters
        if (date < 1000-01-01)
            throw "PARAMETER-ERROR", sprintf("first parameter must be a valid date or NOTHING (given: %y)", date);

        hash rv;
        context (sqlHandler.getJobOverview(date, jobids, useSqlCache)) sortBy (%name) {
            rv.%name.(OMQ::SQLJSMap.%jobstatus) = int(%total);
            rv.%name += (
                "jobid": int(%jobid),
                "version": %version,
            );
        }

        return rv;
    }

    #! gets job overview, params: [date, [name]]: If no date is given, default = last 24 hours
    /** @param date the minimum date to check for changes; job_instance rows with a modified date before this date will not be reported; the default value is 24 hours from the current date and time
        @param name the optional name of the job to check; if no name is passed, then all jobs will be reported
        @param useSqlCache if the sql cache should be used

        @return see getJobOverview() for the return value

        @throw UNKNOWN-JOB the job name given does not exist
        @throw PARAMETER-ERROR the date passed was not valid
    */
    static *hash getJobOverviewFromName(softdate date = now() - 1D, *string name, bool useSqlCache = True) {
        *int jobid;
        if (exists name) {
            jobid = Qorus.qmm.rLookupJob(name).jobid;
            if (!exists jobid)
                throw "UNKNOWN-JOB", sprintf("job %y does not exist", name);
        }

        return QorusSystemInfoService::getJobOverview(date, jobid, useSqlCache);
    }

    #! retrieves job metadata (optional params: list of job ids), returns: job info keyed by name
    /** @return NOTHING if no job can be matched to any of the given ids (or no jobs are in the system if no id is passed), or a hash keyed by job name where the value is a hash of job information with the following keys:
        - \c name: the unique name of the job
        - \c jobid: the unique job ID
        - \c description: job description
        - \c version: version number of the job
        - \c sessionid: session where the job is running
        - \c active: \c True if active, \c False if not
        - \c run_skipped: \c True if the job should be executed immediately if a trigger time was missed due to down time, \c False if not
        - \c code: the source code of the job
        - [\c recurring]: if this field is present, this gives the number of seconds between job executions, and the cron fields will not be present
        - [\c minute]: cron field: minutes when the job can be executed
        - [\c hour]: cron field: hours when the job can be executed
        - [\c day]: cron field: days when the job can be executed
        - [\c month]: cron field: months when the job can be executed
        - [\c wday]: cron field: week days (0 = Sunday) when the job can be executed
        - [\c last_executed]: the date/time the job was last executed (if not present, the job has not yet been executed)
        - [\c last_executed_job_instanceid]: the last executed instance id of the job
        - [\c expiry_date]: the date/time the job will expire; if this date is present, the job will not run automatically after this date
        - \c created: the date/time the job was loaded into the database
        - \c modified: the date/time the job was modified in the database
        - \c lib: a hash keyed by library object type (key values: \c "functions", \c "classes", \c "constants"); the
          value of each key will be a list of hashes with the following keys (empty lists mean no objects of that type
          are listed as library objects of the workflow):
          - \c name: the name of the library object
          - \c version: the version of the library object
          - \c id: the ID of the library object (referencing the tables, \c FUNCTION_INSTANCE, \c CLASSES, or \c CONSTANTS)
        - \c groups: a list of RBAC group names that this job is a member of
    */
    *hash getJobMetadata() {
        hash sql = (
            "orderby" : "name",
        );

        if (exists argv && exists argv[0]) {
            sql.where = {"jobid": op_in(argv)};
        }

        SqlUtil::AbstractTable jobs = getSqlTableSystemTrans("omq", "jobs");
        hash job_metadata;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                job_metadata = jobs.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processJobMetadata(job_metadata);
    }

    #! retrieves job metadata from the name, returns: job info keyed by name
    /** @param name the name of the job to query
        @return see getJobMetadata() for information about the return value
    */
    *hash getJobMetadataFromName(string name) {
        if (!strlen(name))
            throw "PARAMETER-ERROR", "name is a required parameter for info.getJobMetadataFromName()";

        hash sql = (
            "where"   : (
                "name" : name,
            ),
        );
        SqlUtil::AbstractTable jobs = getSqlTableSystemTrans("omq", "jobs");
        hash rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = jobs.select(sql);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return processJobMetadata(rv);
    }

    #! retrieves a list of all jobs without the code field
    /** @return a list of hashes with the following keys for all jobs in the database:
        - \c name: the unique name of the job
        - \c jobid: the unique job ID
        - \c description: job description
        - \c version: version number of the job
        - \c sessionid: session where the job is running
        - \c active: \c True if active, \c False if not
        - \c run_skipped: \c True if the job should be executed immediately if a trigger time was missed due to down
          time, \c False if not
        - [\c recurring]: if this field is present, this gives the number of seconds between job executions, and the
          cron fields will not be present
        - [\c minute]: cron field: minutes when the job can be executed
        - [\c hour]: cron field: hours when the job can be executed
        - [\c day]: cron field: days when the job can be executed
        - [\c month]: cron field: months when the job can be executed
        - [\c wday]: cron field: week days (0 = Sunday) when the job can be executed
        - [\c last_executed]: the date/time the job was last executed (if not present, the job has not yet been
          executed)
        - [\c last_executed_job_instanceid]: the last executed instance id of the job
        - [\c expiry_date]: the date/time the job will expire; if this date is present, the job will not run
          automatically after this date
        - \c created: the date/time the job was loaded into the database
        - \c modified: the date/time the job was modified in the database
        - \c groups: a list of RBAC group names that this job is a member of
    */
    list getJobList() {
        hash sh = {
            "columns" : ("name", "jobid", "description", "version",
                        "sessionid", "active", "run_skipped",
                        "recurring", "minute", "hour",
                        "day", "month", "wday", "last_executed", "last_executed_job_instanceid",
                        "created", "modified",),
        };

        # get metadata for all jobs
        hash q;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                AbstractTable t = getSqlTableSystem("omq", "jobs");
                q = t.select(sh);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return map processJobMetadataRow($1), q.contextIterator();
    }

    #! returns NOTHING if the job instance ID is not valid or a hash giving job instance status corresponding to the job instance ID passed as an argument
    /** @param jiid the job instance ID to query
        @return NOTHING if the job instance ID is not valid or a hash giving job instance status corresponding to the job instance ID passed as an argument with the following keys:
        - \c job_instanceid: the job instance ID being queried
        - \c jobid: the jobid (metadata ID)
        - \c sessionid: the application session currently running the job, otherwise 0
        - \c jobstatus: the current status of the job (see @ref JobStatusDescriptions for possible values)
        - [\c info]: the information saved against the job (if any)
        - \c started: the time the job instance was started
        - \c completed: the time the job instance completed (with any status)
        - \c modified: the time the job instance was last modified
        - \c errors: if any errors were raised against the job instance, they will appear as hashes in a list assigned to this key; the hashes will have the following keys:
        - \c job_errorid: the unique ID of the error in the \c job_errors table
        - \c severity: the severity of the error (see @ref ErrorSeverityCodes for possible values)
        - \c error: the error code
        - \c description: description of the error
        - [\c info]: any additional data saved against the error
        - \c business_error: True if the error is a business error, False if not
        - \c created: the date/time the error was created
        - \c audit: if any audit events were created for the given job instance, they will appear as hashes in a list assigned to this key; the hashes will have the following keys:
        - \c audit_eventid: the audit event ID (unique key in the \c AUDIT_EVENTS table)
        - [\c related_audit_eventid]: related audit event ID
        - \c audit_event_code: the audit event code (see @ref AuditEventCodes for possible values)
        - [\c audit_user_event]: the user audit event code string (present only when \c audit_event_code is @ref OMQ::AE_USER_EVENT)
        - [\c reason]: the reason for the event
        - \c who: the initiator of the event
        - \c source: a string describing the source of the event
        - [\c info1]: an informational string about the event
        - [\c info2]: an informational string about the event
        - \c created: the date/time the audit event was created
        - \c event: the string description corresponding to the \c audit_event_code (see @ref AuditEventStrings for possible values)
    */
    *hash getJobStatus(softint jiid) {
        *hash ji = omqp.selectRow("select name, version, ji.jobid, job_instanceid, ji.sessionid, jobstatus, info, started, completed, ji.modified from job_instance ji, jobs j where ji.jobid = j.jobid and job_instanceid = %v", jiid);
        if (!exists ji)
            return;

        ji = postProcessJobInstance(ji);

        # add job instance errors
        ji.errors = ();

        *hash q;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                q = omqp.select("select job_errorid, severity, error, description, info, business_error, created from job_errors where job_instanceid = %v", jiid);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }
        trans.reset();

        context (q) {
            hash h = %%;
            # delete NULL values
            map delete h.$1, keys h, h.$1 === NULL;

            # deserialize info, if any
            if (exists h.info)
                h.info = deserializeQorusData(h.info);

            h.business_error = boolean(h.business_error);

            ji.errors += h;
        }

        # add job instance audit events
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                q = omqp.select("select audit_eventid, related_audit_eventid, audit_event_code, audit_user_event, "
                    "reason, who, source, info1, info2, created from audit_events where job_instanceid = %v "
                    "order by created", jiid);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        ji.audit = processAuditEvents(q);

        return ji;
    }

    #! gets a list of job instance ids (not more than 100 by default, can be overridden with the 4th argument), params: jobid (single value or list), date, [statuses, num rows]
    /** @param jobid a single jobid or a list of jobids to query
        @param date an optional cutoff date, if the date parameter is not passed, then the cutoff date is set to 24 hours in the past; the cutoff date is used with the \c job_instance.modified column; only rows with a \c modified date greater than or equal to the date passed will be returned
        @param stati a single job status or a list of job statuses to check; see @ref JobStatusDescriptions for possible values
        @param rownum the maximum number of rows to return
        @return a list of integer job instance IDs
        @note if more than one jobid is given, there is no way to differentiate the jobid from the list returned because only a flat list of job_instanceid values is returned
        @throw PARAMETER-ERROR missing jobid parameter, invalid date passed, or invalid job status passed
    */
    *list getJobInstanceList(auto jobid, *softdate date = now() - 1D, auto stati, softint rownum = OptionHelper::getOption("row-limit")) {
        # check parameters
        if (!jobid && type(jobid) != Type::List)
            throw "PARAMETER-ERROR", "missing jobid parameter";

        if (!exists date)
            date = now() - 1D;

        if (!rownum)
            rownum = OptionHelper::getOption("row-limit");

        if (date < 1000-01-01)
            throw "PARAMETER-ERROR", sprintf("the second parameter must be a valid date (given: %y)", date);

        foreach auto status in (stati) {
            if (!OMQ::JSMap{status})
                throw "PARAMETER-ERROR", sprintf("%y is not a valid job status (valid statuses: %y)", status, OMQ::JSMap.keys());
        }

        # map job statuses to SQL statuses
        stati = map OMQ::StatMap.$1, stati;

        hash sh = {
            "columns": "job_instanceid",
            "where": {
                "jobid": op_in(jobid),
                "modified": op_ge(date),
            },
            "limit": rownum,
        };

        if (exists stati) {
            sh.where.jobstatus = op_in(stati);
        }

        hash q;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                AbstractTable t = getSqlTableSystem("omq", "job_instance");
                q = t.select(sh);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return map int($1), q.job_instanceid;
    }

    #! gets a list of job instance ids, params: jobid, condition, number of rows (100 default)
    /** @param jobids one or more jobids to query
        @param statuses a list with requested statuses in expanded form ('ERROR') or @ref nothing
        @param modified a limit (>=) for the \c modified column or @ref nothing
        @param rownum the maximum number of rows to return
        @param offset the row offset (for paging results)
        @param sort a list of column names for sorting
        @param jiids an optional list of job_instanceids for the search
        @param desc if @ref True "True", then a descending sort is used
        @param full if @ref True "True", then errors and audit events are also returned

        @return NOTHING if no rows match the criteria, or a list of hashes with the following keys:
        - \c job_instanceid: the job instance ID being queried
        - \c jobid: the jobid (metadata ID)
        - \c jobstatus: the current status of the job (see @ref JobStatusDescriptions for possible values)
        - \c sessionid: the application session currently running the job, otherwise 0
        - \c started: the time the job instance was started
        - \c completed: the time the job instance completed (with any status)
        - \c modified: the time the job instance was last modified
        - \c errors: a list of error hashes (included only if \c full = @ref True "True")
        - \c audit: a list of audit event hashes (included only if \c full = @ref True "True")
    */
    *list getJobInstances(*softlist jobids, *softlist statuses, *softdate modified, softint rownum = OptionHelper::getOption("row-limit"), *softint offset, *softlist sort, *softlist jiids, *softbool desc, *softbool full) {
        logDebug("getJobInstances: jobids: %y statuses: %y mod: %y rownum: %y sort: %y offset: %y jiids: %y desc: %y full: %y", jobids, statuses, modified, rownum, sort, offset, jiids, desc, full);

        AbstractTable jobs = Qorus.dsmanager.getOmqTable("jobs");
        AbstractTable job_instance = Qorus.dsmanager.getOmqTable("job_instance");

        if (sort) {
            # process sort keys
            bool hk;
            foreach string k in (\sort) {
                k = k.lwr();
                if (!jobs.describe().hasKey(k) && !job_instance.describe().hasKey(k))
                    throw "JOB-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k, (hash(jobs.describe()) + hash(job_instance.describe())).keys());
                if (k == "job_instanceid")
                    hk = True;
            }

            # the sort key must also have a unique column to ensure consistent sort order
            if (!hk)
                sort += "job_instanceid";
        }

        if (desc && !sort)
            sort = "job_instanceid";

        hash wcond;

        if (jiids)
            wcond.job_instanceid = op_in(jiids);

        if (statuses)
            wcond.jobstatus = op_in(map OMQ::JSMap.$1, statuses);

        if (exists modified)
            wcond.modified = op_ge(modified);

        list jl = ();
        if (jobids)
            jl = jobids;

        if (jl) {
            list jnl = ();
            list jil = ();
            foreach auto e in (jl) {
                if (e =~ /[a-z]/i)
                    jnl += e;
                else
                    jil += e;
            }
            if (jil)
                wcond.jobid = op_in(jil);
            if (jnl)
                wcond."j.name" = op_in(jnl);
        }

        hash sh = (
            "comment": "qorus.info.getJobInstances",
            "columns": ("j.name", "j.version", "job_instanceid", "jobid", "jobstatus", "info", "sessionid", "started", "completed", "modified"),
            "where": wcond,
            "join": join_inner(jobs, "j"),
            "limit": rownum,
            "offset": offset,
            "orderby": sort,
            "desc": desc,
        );

        #logDebug("SH: %N", sh);

        *list sqlresult;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                sqlresult = job_instance.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }
        trans.reset();
        #string sql;
        #*list sqlresult = ji.selectRows(sh, \sql);
        #logDebug("sql: %s", sql);

        # post-process results
        foreach hash row in (\sqlresult)
            row = postProcessJobInstance(row);

        if (sqlresult && full) {
            AbstractTable job_errors = Qorus.dsmanager.getOmqTable("job_errors");
            AbstractTable audit_events = Qorus.dsmanager.getOmqTable("audit_events");

            # get job instance ID list
            if (!jiids)
                jiids = map $1.job_instanceid, sqlresult;

            *list el;
            while (True) {
                try {
                    # we can just release the lock because the query is read-only
                    on_error omqp.rollback();

                    el = job_errors.selectRows((
                        "comment": "qorus.info.getJobInstances",
                        "columns": ("job_instanceid", "job_errorid", "severity", "error", "description", "info",
                            "business_error", "created"),
                        "where": ("job_instanceid": op_in(jiids)),
                    ), SqlDataOpt);
                } catch (hash<ExceptionInfo> ex) {
                    # restart the transaction if necessary
                    if (trans.restartTransaction(ex))
                        continue;
                    rethrow;
                }
                break;
            }
            trans.reset();

            # make into a hash
            hash eh;
            map eh.($1.job_instanceid) += list($1), el;

            logInfo("eh: %y\n", eh);

            *list al;
            while (True) {
                try {
                    # we can just release the lock because the query is read-only
                    on_error omqp.rollback();

                    al = audit_events.selectRows({
                        "comment": "qorus.info.getJobInstances",
                        "columns": ("job_instanceid", "audit_eventid", "related_audit_eventid", "audit_event_code",
                            "audit_user_event", "reason", "who", "source", "info1", "info2", "created"),
                        "where": ("job_instanceid": op_in(jiids)),
                }, SqlDataOpt);
                } catch (hash<ExceptionInfo> ex) {
                    # restart the transaction if necessary
                    if (trans.restartTransaction(ex))
                        continue;
                    rethrow;
                }
                break;
            }

            # make into a hash
            hash ah;
            map ah.($1.job_instanceid) += list($1), al;

            foreach hash row in (\sqlresult) {
                row.errors = (map ($1 + (
                    "business_error": boolean($1.business_error),
                    "info": deserializeQorusData($1.info),
                )) - "job_instanceid", eh.(row.job_instanceid));
                row.audit = (map $1 - "job_instanceid", ah.(row.job_instanceid));
            }
        }

        return sqlresult;
    }

    #! gets a list of order instance notes
    /** @param wfiid the wfiid to query
        @param count an optional "limit count
    */
    softlist getOrderInstanceNotes(softint wfiid, *int count) {
        try {
            return SM.getOrderInstanceNotes(wfiid, count);
        } catch (hash<ExceptionInfo> ex) {
            if (ex.err != "INVALID-WORKFLOW-ORDER-DATA-INSTANCE")
                rethrow;
        }

        *string dsarch = Qorus.props.get("arch").datasource;
        if (dsarch) {
            SqlUtil::AbstractTable t = getSqlTableSystemTrans(dsarch, "order_instance_notes");
            QorusRestartableTransaction trans();
            while (True) {
                try {
                    # we can just release the lock because the query is read-only
                    on_error omqp.rollback();

                    return t.selectRows(("where": ("workflow_instanceid": wfiid ), "orderby": "created"));
                } catch (hash<ExceptionInfo> ex) {
                    # restart the transaction if necessary
                    if (trans.restartTransaction(ex))
                        continue;
                    rethrow;
                }
                break;
            }
        }

        return ();
    }

    private softlist<hash<SlaEventInfo>> searchSlaEventsPriv(string dsname, *hash h) {
        AbstractTable sla = getSqlTableSystemTrans(dsname, "sla");
        AbstractTable sla_events = getSqlTableSystemTrans(dsname, "sla_events");

        if (!h.limit)
            h.limit = OptionHelper::getOption("row-limit");

        if (h.desc)
            h.desc = parse_boolean(h.desc);

        if (h.sort) {
            if (h.sort && h.sort =~ /,/)
                h.sort = h.sort.split(",");

            # process sort keys
            bool has_pk;
            foreach string k in (\h.sort) {
                k = k.lwr();
                if (!sla.describe().hasKey(k) && !sla_events.describe().hasKey(k))
                    throw "ORDER-SORT-ERROR", sprintf("sort key %y is not valid; valid keys: %y", k,
                        (sla.describe().getHash() + sla_events.describe().getHash()).keys());
                if (k == "sla_eventid")
                    has_pk = True;
            }

            # the sort key must also have a unique column to ensure consistent sort order
            if (!has_pk) {
                if (h.sort.typeCode() != NT_LIST)
                    h.sort = list(h.sort);
                h.sort += "sla_eventid";
            }
        } else if (h.desc)
            h.sort = "sla_eventid";

        hash wcond;

        do_cond_string_like_list(\wcond, "s.name", h.name);
        do_cond_int_list(\wcond, "s.slaid", h.slaid);
        do_cond_string_like_list(\wcond, "producer", h.producer);
        do_cond_string_like_list(\wcond, "err", h.err);
        do_cond_string_like_list(\wcond, "errdesc", h.errdesc);

        if (h.mindate.val())
            wcond.created = op_ge(date(h.mindate));

        if (h.maxdate.val())
            wcond."1:created" = op_lt(date(h.maxdate));

        if (h.success.val())
            wcond.success = h.success ? 1 : 0;

        hash sh = (
            "comment": "qorus.info.searchSlaEvents",
            "columns": ("s.name", "s.slaid", "sla_eventid", "value", "producer", "success", "err", "errdesc",
                 "created"),
            "join": join_inner(sla, "s"),
            "where": wcond,
            "limit": h.limit,
            "offset": h.offset,
            "orderby": h.sort,
            "desc": h.desc,
        );

        *list rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = sla_events.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return map cast<hash<SlaEventInfo>>($1), rv;
    }

    #! searches for SLA events according to the given criteria and returns a list of results
    /** @param h a hash of search criteria with the following optional keys:
        - \c desc: return the results in descending order
        - \c err: the error string of unsucessful SLA events; can be a list of strings or a string with \c "%" characters for SQL like matching
        - \c errdesc: the error description string of unsucessful SLA events; can be a list of strings or a string with \c "%" characters for SQL like matching
        - \c name: the name of the SLA; can be a list of names or a string with \c "%" characters for SQL like matching
        - \c limit: max number of rows to return, if not given, then the value of the \a "row-limit" option is used (default: 100)
        - \c mindate: minimum SLA event timestamp (inclusive, meaning \c ">=" comparisons used)
        - \c maxdate: maximum SLA event timestamp (exclusive, meaning \c "<" comparisons used)
        - \c offset: row offset
        - \c producer: the producer string of SLA events; can be a list of strings or a string with \c "%" characters for SQL like matching
        - \c slaid: the SLA ID, can be a list of IDs
        - \c sort: columns for sorting the results
        - \c success: filter for sucessful calls (1) or errored calls (0)

        @return an empty list if no events are matched, otherwise a list of @ref OMQ::SlaEventInfo hashes

        @since Qorus 3.1.1
    */
    list<hash<SlaEventInfo>> searchSlaEvents(*hash h) {
        logDebug("searchSlaEvents(): h: %y", h);
        softint expected = h.limit ?? OptionHelper::getOption("row-limit");

        list<hash<SlaEventInfo>> ret = searchSlaEventsPriv("omq", h);
        int lsize = ret.lsize();
        if (lsize < expected && (*string dsarch = Qorus.props.get("arch").datasource))
            ret += map $1 + ("archive": True), searchSlaEventsPriv(dsarch, h + ("limit": expected - lsize));
        return ret;
    }

    #! searches for SLA events according to the given criteria and returns a list of results
    /** @param h a hash of search criteria with the following optional keys:
        - \c err: the error string of unsucessful SLA events; can be a list of strings or a string with \c "%" characters for SQL like matching
        - \c errdesc: the error description string of unsucessful SLA events; can be a list of strings or a string with \c "%" characters for SQL like matching
        - \c grouping: (optional) possible values for reporting performance statistics:
        - \c "hourly": hourly grouping
        - \c "daily": daily grouping
        - \c "monthly": monthly grouping
        - \c "yearly": yearly grouping
        - \c name: the name of the SLA; can be a list of names or a string with \c "%" characters for SQL like matching
        - \c maxdate: maximum SLA event timestamp (exclusive, meaning \c "<" comparisons used)
        - \c mindate: minimum SLA event timestamp (inclusive, meaning \c ">=" comparisons used)
        - \c producer: the producer string of SLA events; can be a list of strings or a string with \c "%" characters for SQL like matching
        - \c slaid: the SLA ID, can be a list of IDs
        - \c success: filter for sucessful calls (1) or errored calls (0)

        @return an empty list if no events are matched, otherwise a list of @ref OMQ::SlaPerformanceInfo hashes

        @since Qorus 3.1.1
    */
    softlist<hash<SlaPerformanceInfo>> getSlaPerformance(*hash h) {
        logDebug("getSlaPerformance(): h: %y", h);

        # time grouping SqlUtil column operator closure/call ref
        *code tg;
        if (h.grouping) {
            tg = Grouping.(h.grouping);
            if (!tg)
                throw "ARGUMENT-ERROR", sprintf("invalid grouping argument %y; expecting one of: %y", h.grouping, Grouping.keys());
        }

        AbstractTable sla = Qorus.dsmanager.getOmqTable("sla");
        AbstractTable sla_events = Qorus.dsmanager.getOmqTable("sla_events");

        hash wcond;

        do_cond_string_like_list(\wcond, "s.name", h.name);
        do_cond_int_list(\wcond, "s.slaid", h.slaid);
        do_cond_string_like_list(\wcond, "producer", h.producer);

        if (h.mindate.val())
            wcond.created = op_ge(date(h.mindate));

        if (h.maxdate.val())
            wcond."1:created" = op_lt(date(h.maxdate));

        if (h.success.val())
            wcond.success = h.success ? 1 : 0;

        # column list
        list cols = ();
        # group by list
        list groupby = ();
        # order by list
        list orderby = ();

        if (tg) {
            cols += cop_as(tg("created"), "grouping");
            groupby += tg("created");
            orderby += tg("created");
        }

        cols += (
            cop_as(cop_count(), "count"),
            cop_as(cop_min("created"), "mindate"),
            cop_as(cop_max("created"), "maxdate"),
            cop_as(cop_min("value"), "minprocessing"),
            cop_as(cop_avg("value"), "avgprocessing"),
            cop_as(cop_max("value"), "maxprocessing"),
            cop_as(cop_avg("success"), "successratio"),
        );

        hash sh = (
            "comment": "qorus.info.getSlaPerformance",
            "columns": cols,
            "join": join_inner(sla, "s"),
            "where": wcond,
            "groupby": groupby,
            "orderby": orderby,
        );

        *list rv;
        QorusRestartableTransaction trans();
        while (True) {
            try {
                # we can just release the lock because the query is read-only
                on_error omqp.rollback();

                rv = sla_events.selectRows(sh, SqlDataOpt);
            } catch (hash<ExceptionInfo> ex) {
                # restart the transaction if necessary
                if (trans.restartTransaction(ex))
                    continue;
                rethrow;
            }
            break;
        }

        return map cast<hash<SlaPerformanceInfo>>($1), rv;
    }

    static private *list processIntervals(*list l, bool return_seconds) {
        if (return_seconds) {
            switch (qdriver) {
                case "oracle": {
                    foreach hash row in (\l)
                        map row.$1 = row.$1 * 86400n, ProcIntervalCols, exists row.$1;
                    break;
                }
                case "pgsql": {
                    foreach hash row in (\l)
                        map row.$1 = row.$1 ? (row.$1.durationMicroseconds() / 1000000n) : 0, ProcIntervalCols, exists row.$1;
                    break;
                }
            }
        } else {
            switch (qdriver) {
                case "oracle": {
                    foreach hash row in (\l)
                        map row.$1 = seconds(row.$1 * 86400n), ProcIntervalCols, exists row.$1;
                    break;
                }
                case "mysql": {
                    foreach hash row in (\l)
                        map row.$1 = seconds(row.$1), ProcIntervalCols, exists row.$1;
                    break;
                }
            }
        }

        return l;
    }

    private hash processCondition(reference condition) {
        # check for illegal values (first attempt at detecting sql-injections)
        if (condition =~ /(\bwhere\b|\bselect\b|\bupdate\b|\binsert\b|\bcreate\b|\bdrop\b|\bbegin\b|\bfrom\b|\binto\b)/i)
            throw "CONDITION-ERROR", sprintf("condition %y is invalid", condition);

        # check for function calls; copy string for destructive tests
        *string c = condition;
        c = tolower(c);
        while (True) {
            *string c1 = (c =~ x/(\w+)\s*\(.*\)/)[0];
            if (!exists c1)
                break;
            if (!inlist(c1, SQLWhiteList))
                throw "CONDITION-ERROR", sprintf("condition %y is invalid", condition);
            # remove call from string to test again
            int i = index(c, c1);
            # get closing parenthesis
            int t = index(c, ")", i + strlen(c1));
            #printf("i=%d cond: %y\nc=%y\nc1=%y\n", i, condition, c, c1);
            splice c, i, t - i + 1;
            #printf("c=%y\n", c);
        }

        # substitute SQL status values
        condition =~ s/'READY'/'Y'/g;
        condition =~ s/'SCHEDULED'/'S'/g;
        condition =~ s/'COMPLETE'/'C'/g;
        condition =~ s/'INCOMPLETE'/'N'/g;
        condition =~ s/'ERROR'/'E'/g;
        condition =~ s/'CANCELED'/'X'/g;
        condition =~ s/'RETRY'/'R'/g;
        condition =~ s/'WAITING'/'W'/g;
        condition =~ s/'ASYNC-WAITING'/'A'/g;
        condition =~ s/'EVENT-WAITING'/'V'/g;
        condition =~ s/'IN-PROGRESS'/'I'/g;
        condition =~ s/'BLOCKED'/'B'/g;
        condition =~ s/'CRASH'/'Z'/g;

        condition =~ s/\$\{WORKFLOW_ID\}/wi.workflowid/g;
        condition =~ s/\$\{WORKFLOW_INSTANCEID\}/wi.workflow_instanceid/g;
        condition =~ s/\$\{JOB_ID\}/wi.jobid/g;
        condition =~ s/\$\{JOB_INSTANCEID\}/wi.job_instanceid/g;
        condition =~ s/\$\{STARTED\}/wi.started/g;
        condition =~ s/\$\{MODIFIED\}/wi.modified/g;
        condition =~ s/\$\{COMPLETED\}/wi.completed/g;
        condition =~ s/\$\{PARENT_WORKFLOW_INSTANCEID\}/wi.parent_workflow_instanceid/g;
        condition =~ s/\$\{WORKFLOW_STATUS\}/wi.workflowstatus/g;
        condition =~ s/\$\{JOB_STATUS\}/wi.jobstatus/g;
        bool join_oik = condition =~ /\$\{KEYVALUE\}/;
        condition = replace(condition, "${KEYVALUE}", "oik.VALUE");
        bool join_oi = (condition =~ /\$\{STATICDATA\}/) || (condition =~ /\$\{DYNAMICDATA\}/);
        condition =~ s/\$\{STATICDATA\}/oi.staticdata/g;
        condition =~ s/\$\{DYNAMICDATA\}/oi.dynamicdata/g;

        # process and substitute dates
        *string date;
        while (exists (date = (condition =~ x/\$\{DATE\}\(([^\)]+)\)/)[0])) {
            date = compatDeprecatedDbDate(qdriver, Qore::date(date));
            condition = regex_subst(condition, "\\${DATE}\\([^)]+\\)", date);
        }

        return ("join_oik" : join_oik, "join_oi" : join_oi);
    }
}
