/** @page systemref System Reference Manual

    @section systemrefcontents Overview of Content of the Qorus System Reference

    - @subpage sysrefintro
      - @ref qorusfeatures
    - @subpage sysarch
      - @ref sysarchintro
      - @ref sysarchoverview
      - @ref dirlayout
      - @ref configfiles
      - @ref systemstartup
      - @ref systemshutdown
      - @ref RBAC
      - @ref auditing
      - @ref systemevents
      - @ref transmodel
      - @ref httpserver
    - @subpage appsessionmodel
      - @ref appsessionoverview
      - @ref appsessioninit
      - @ref appsessionrecovery
    - @subpage connmon
      - @ref conn_intro
      - @ref remoteconn
      - @ref userconn
      - @ref dsconn
      - @ref monitoring
    - @subpage mappers
      - @ref mapper-intro
      - @ref mapper-types
      - @ref mapper-modules-ref
    - @subpage value-maps
      - @ref value-map-intro
      - @ref value-map-datatypes
      - @ref value-map-enabled
    - @subpage sla_tracking
    - @subpage sql-cache
    - @subpage alerts
      - @ref ongoingalerts
      - @ref transientalerts
    - @subpage services
      - @ref serviceoverview
      - @ref servicemeth
      - @ref serviceload
      - @ref servicecalls
    - @subpage workflowmodel
      - @ref workflowoverview
      - @ref workflows
      - @ref steps
      - @ref segments
      - @ref wfmetadatacache
      - @ref orderdata
      - @ref workflowexecution
      - @ref workflowdatacache
    - @subpage jobs
      - @ref joboverview
      - @ref jobmetadata
      - @ref jobdata
    - @subpage sysprops
      - @ref sysprops_intro
      - @ref sysprops_apis
      - @ref sysprops_examples
    - @subpage logging
      - @ref logfilelocations
      - @ref logmessageformat
      - @ref logrotation
    - @subpage datamodel
    - @subpage systemoptions
      - @ref optionoverview
      - @ref readonlyoptions
      - @ref perfoptions
      - @ref optiondetails

    @image html qorus-small-white-on-transparent-200x77.png "Qorus Integration Engine&reg;"
*/

/** @page sysrefintro Introduction to the Qorus Integration Engine&reg;

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    Qorus Integration Engine&reg; is an IT integration and automation platform designed for reliable automation
    of business-critical processes, for complex data integration challenges, API management, and much more,
    targeting enterprise deployments leverging AI and data science in modern IT automation scenarios, built on a
    "no-code platform for coders" which delivers fast/inexpensive/low-risk results through its configuration-based
    approach while staying flexible enough to handle the most challenging IT requirements.  The result is a very low
    TCO, from low-overhead system operations supporting automatic error recovery to fast component-based deliveries
    and configuration-based change management.

    An example deployment might have the following layout:

    @htmlonly
    <div class="image">
      <img src="Qorus Example Deployment-2.svg" alt="Example Qorus Deployment" style="width:75%;">
      <div class="caption">Example Qorus Deployment</div>
    </div>
    @endhtmlonly

    @section qorusfeatures Features of Qorus Integration Engine&reg;

    The following are some specific features of Qorus Integration Engine&reg; that allow the system to realize the
    reliability and process quality goals described above:
    - A @ref devintro_no_code_for_coders "no-code platform architecture for coders" - allowing full customization with
      code for expert users and a high-level, configuration-only approach for repetitive challenges provides the best
      of both worlds, no-code for productivity and complete flexibility to solve any IT challenge or requirement
    - Dynamic loading and unloading of versioned workflow metadata, workflow implementations, user and system
      services and jobs resulting in the ability to support live upgrades of user logic, minimizing downtime
    - Simple, powerful, and consistent system framework and API making complex tasks such as asynchronous messaging,
      multithreaded workflow definition, database transaction management, etc, easy to implement for even less-
      experienced programmers
    - Automatic creation of statefulsets in <a href="https://kubernetes.io/">Kubernetes</a> for Qorus system and user
      services including @ref service_stateless "microservices"
    - Full traceability for all workflows using natural checkpointing of each step in the logic in the database,
      meaning that in case of errors every properly-designed workflow is restartable and recoverable by design
      (see the @ref develguide and @ref wf_recoverability)
    - Automatic error detection and recovery built in to the system framework
    - Sensitive data segregation and encryption to protect sensitive data and to facilitate the processing of
      sensitive data
    - Efficient use and sharing of system resources by a highly-threaded integration engine
    - Advanced database transaction management model provides a consistent view of data at all times and ensures
      system recovery in the case of catastrophic failures as long as the database remains consistent.

    This document provides a reference to Qorus's system architecture and implementation supporting the features
    listed above.

    @see develintro
*/

/**
    @page sysarch System Architecture

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section sysarchintro Introduction

    Qorus Integration Engine&reg; provides a framework for the reliable operation of business-critical interfaces.
    From a high level, the Qorus Integration Engine&reg; server is made up of a set of processes backed by metadata
    and status information stored in a database schema, communicating with other systems and clients through the
    network or the enterprise message bus as follows:

    @htmlonly
    <div class="image">
      <img src="Qorus External Architecture Overview-2.svg" alt="Qorus High Level External Architecture" style="width:30%;">
      <div class="caption">Qorus High Level External Architecture</div>
    </div>
    @endhtmlonly

    @section sysarchoverview System Architecture Overview

    The following figure gives a high-level overview of the internal system architecture:

    @htmlonly
    <div class="image">
      <img src="qorus-system-architecture-8-white-text.svg" alt="Qorus Integration Engine&reg; System Architecture Overview" style="width:80%;">
      <div class="caption">Qorus Integration Engine&reg; System Architecture Overview</div>
    </div>
    @endhtmlonly

    The Qorus system provides a workflow logic cache, a @ref workflowapi "workflow API", and a workflow execution
    engine, a service loader, a @ref serviceapi "service API", a job engine and @ref jobapi "API", many other APIs,
    and a multithreaded @ref httpserver "HTTP server" servicing @ref restapi "REST", @ref YAMLRPC "YAML-RPC", XML-RPC,
    JSON-RPC, WebSocket, and HTTP requests, among others.  Because the @ref restapi "REST", @ref YAMLRPC "YAML-RPC",
    XML-RPC, and JSON-RPC handlers export all service methods automatically as well as built-in system API methods,
    user services can be considered run-time extensible and run-time upgradeable API providers as well (and can
    explicitly serve APIs using the @ref service_api_manager "API manager" configuration of a service, for example).

    The APIs made available by the Qorus system are listed in the following table.

    <b>Qorus APIs</b>
    |!API|!Type|!Description
    |@ref workflowapi "Workflow API"|Internal|Set of functionality exported for use by workflow code
    |@ref serviceapi "Service API"|Internal|Set of functionality exported for use by services
    |@ref jobapi "Job API"|Internal|Set of functionality for use by job code
    |@ref mapperapi "Mapper API"|Internal|Set of functionality for use by mapper code
    |@ref systemservices "System Service API"|Internal and External|Set of services delivered with the system \
        providing additional functionality to Qorus
    |@ref restapi "REST API"|External|Qorus system network API

    @note
    - Qorus APIs are primarily written in %Qore and are automatically made available through on-demand dynamic imports
      in %Python and Java code as well
    - Service methods are exported through the system API by default (see @ref service_method_internal).  Because
      these methods are available both internally and externally, they can be verified and tested separately from
      dependent interface components.  Exported service methods can also be called from the network or from the command
      line (using the @ref qrest "qrest" program) or other programs using @ref restapi "REST" or other protocols.

    Qorus relies on its system schema to store most of its configuration information, some system logic (in system
    services), and all user configuration.

    The following table outlines some of the data that is stored in the system database.

    <b>Qorus Database Configuration</b>
    |!Data|!Description
    |@ref workflows "Workflow Metadata"|The description of a workflow (name, version, steps, dependencies, etc) and \
        all workflow logic written in Python, Java, or %Qore using the @ref workflowapi "workflow API"
    |@ref services "Service Metadata"|The description of a system or user service (method names, version, etc) and \
        service method logic written in Python, Java, or %Qore and using the @ref serviceapi "service API"
    |@ref jobs "Job Metadata"|The descripion of time-based jobs and job logic using the @ref jobapi "job API"
    |@ref workflow_instance_desc "Workflow Order Data"|Workflow order data instances, the data and processing status

    Qorus is a highly multithreaded integration platform.  Due to the fact that much of the system code is stored in a
    database, and can be "refreshed" (i.e. old version deleted from the cache, new version read in from the database
    and started) while the system is running, not only can use logic be upgraded without shutting the system down,
    parts of the workflow system itself (system services) can also be upgraded without shutting the system down.

    The majority of the additional programs included with Qorus are client programs to the integration engine.  They
    communicate with the Qorus server either via the @ref httpserver "HTTP server" using @ref restapi "REST",
    @ref YAMLRPC "YAML-RPC", XML-RPC, or JSON-RPC protocols or via <a href="http://zeromq.org">ZeroMQ</a> for clients
    using the high-performance encrypted network cluster API.

    Qorus features a built-in multithreaded @ref httpserver "HTTP server" which functions as the system's primary
    interface to the outside world and serves various protocols as well as HTTP/S.

    All system activities happen in a set of processes that manage many concurrent threads to get their work done.

    @section dirlayout Qorus Directory Layout
    For self-contained application installations; the Qorus Integration Engine&reg; application directory has a
    structure as given in the following table.

    @anchor tar

    <b>Qorus Integration Engine&reg; Self-Contained Application Directory Layout</b>
    |!Directory|!Description
    |\c $OMQ_DIR/bin|System binaries are located here
    |\c $OMQ_DIR/etc|System configuration files
    |\c $OMQ_DIR/jar|Qorus Java files
    |\c $OMQ_DIR/lib|System and included third-party library files
    |\c $OMQ_DIR/qlib|%Qore-language include file directory
    |\c $OMQ_DIR/python|Qorus %Python modules
    |\c $OMQ_DIR/releases|System load files
    |\c $OMQ_DIR/system|System service definitions
    |\c $OMQ_DIR/templates|Miscellaneous template files
    |\c $OMQ_DIR/user|Qorus user definition files, code objects, interface descriptions, release source
    |\c $OMQ_DIR/webapp|Qorus web UI files

    @section configfiles Configuration Files

    Contents of this section:
    - @ref options

    @subsection options System Options File
    The \c options file contains system and client options.  The location of the file is
    <tt>$OMQ_DIR/etc/options</tt>.  This file is also mounted on the host system in Docker installations and is
    located on a shared filesystem in <a href="https://kubernetes.io/">Kubernetes</a> installations.

    Qorus System options have the format:
    - <tt>qorus.</tt><i>option</i><tt>:</tt> \em value

    Example:
    @verbatim qorus.http-server: 8002 @endverbatim

    Also an equals sign (\c =) may be used instead of a colon as in:
    @verbatim qorus.http-server = 8002 @endverbatim

    Any text after a \c # character is assumed to be a comment.

    One of the most important option that should be set before the system will start is
    @ref instance-key "instance-key".  This must be a unique identifier for the instance that will enable the system
    to avoid accidentally starting the same instance more than once and will also allow the system to recover the
    application session gracefully errors should the system ever terminate abnormally.  The default value for this key
    is \c "qorus-test-instance".

    Example @ref instance-key option setting:
    @verbatim
qorus.instance-key: bss-uat-1 @endverbatim

    Additionally, if the log files for Qorus should be written to a directory other than the default (the default for
    @ref tar installations is \c $OMQ_DIR/log), the @ref logdir option must be set to the directory where Qorus log
    files will be written.  This directory must be writable by the user running the Qorus server:

    Example @ref logdir option setting:
    @verbatim
qorus.logdir: /var/log/qorus
    @endverbatim

    Another key of interest in the initial installation is @ref http-secure-server "http-secure-server":

    Example @ref http-secure-server option setting:
    @verbatim
qorus.http-secure-server: 192.168.20.77:8085{cert=$OMQ_DIR/etc/cert1.pem;key=$OMQ_DIR/etc/key1.pem},8086{cert=$OMQ_DIR/etc/cert2.pem;key=$OMQ_DIR/etc/key2.pem}
qorus.http-secure-server: 8087{cert=$OMQ_DIR/etc/cert3.pem;key=$OMQ_DIR/etc/key3.pem}
    @endverbatim

    If no @ref http-secure-server or @ref http-server options are set, the default for the HTTP server value is 8001,
    meaning that Qorus will listen on all interfaces on port 8001 for unencrypted requests, and any APIs requiring
    encrypted client connections will be unavailable.

    @see
    - @ref ops_sensitive_data_https
    - @ref systemoptions for a complete reference to all system options.

    Qorus client options have the format:
    - <tt>qorus-client.</tt><i>option</i><tt>:</tt> \em value

    Example:
    @verbatim qorus-client.proxy-url: http://user:pass@192.168.25.7:8080 @endverbatim

    @see @ref qorusclientoptionoverview for information on client options.

    @subsection obsolete-system-files Obsolete System Files Migrated to the Database

    @subsubsection dbparams Upgrade Migration Info: System Datasource (dbparams) File

    As of Qorus 4.0 the \c dbparams file is no longer used by Qorus; all system datasources are handled as
    @ref dsconn "datasource connection objects" instead.

    When upgrading a per-4.0 version of Qorus, datasources defined in any existing \c dbparams file are automatically
    migrated to the system database and created as @ref dsconn "datasource connection objects".

    @see @ref dsconn

    @subsubsection remoteconnections Upgrade Migration Info: Remote Qorus Instance Configuration File

    As of Qorus 4.0 the \c remoteconnections file is no longer used by Qorus; all Qorus remote connections are handled
    as @ref remoteconn "Qorus remote connection objects" instead.

    When upgrading a per-4.0 version of Qorus, Qorus remote connections defined in any existing \c remoteconnections
    file are automatically migrated to the system database and created as
    @ref remoteconn "Qorus remote connection objects".

    @see @ref remoteconn

    @section systemstartup System Startup

    Once launched, the system initializes itself with the following steps:

    <hr>
    <b>Step 1: Parse Options File</b>

    Parse @ref options; if any syntax errors are found, information is displayed and the program exits.

    @see @ref systemoptions for detailed descriptions of all system options.

    <hr>
    <b>Step 2: Open System Datasources</b>

    Open System Datasource \c "omq".
    If the system \c "omq" @ref dsconn "datasource" cannot be opened, then error information is displayed and the program
    exits.

    <hr>
    <b>Step 3: Open Log Files</b>

    If the log files cannot be opened, an error message is displayed and the program exits.

    <hr>
    <b>Step 4: Initialize @ref RBAC "RBAC Framework"</b>

    @ref rbacgroups "interface groups" are read in from the database.

    <hr>
    <b>Step 5: Open Application Instance Session</b>

    If any errors are encountered, information is logged, and the program exits.  The application DB session is
    recovered here if needed.

    @see @ref appsessionmodel for more information about opening an application session and session recovery.

    <hr>
    <b>Step 6: Initialize Services</b>

    Services with the autostart flag set are started automatically.  Any errors auto-starting services are logged, but
    do not otherwise affect system startup.

    <hr>
    <b>Step 7: Start @ref httpserver "HTTP Server"</b>

    If any errors are encountered, information is logged, any loaded services are deleted, and the program exits.
    <hr>

    When the @ref httpserver "HTTP server" is started, listeners for each entry in the @ref options (or as overridden
    on the command-line) will listen for requests on their respective interfaces and ports.  To start and stop
    workflows and services, to shut down the system, to change options, etc, the appropriate system API calls must be
    made, normally as properly formatted @ref restapi "REST", @ref YAMLRPC "YAML-RPC", XML-RPC, or JSON-RPC commands
    sent to Qorus' @ref httpserver "HTTP server".  For more details, please see @ref httpserver.

    System startup raises the following @ref systemevents "system event": @ref SYSTEM_STARTUP "SYSTEM_STARTUP"

    @section systemshutdown System Shutdown

    If the shutdown message is received, the system performs the following steps:

    <hr>
    <b>Step 1: Stop All Workflows</b>

    All running workflow execution instances are stopped.  While system shutdown is in progress, it is not possible to
    start new workflow execution instances.

    <hr>
    <b>Step 2: Stop all Jobs</b>

    All jobs are stopped.

    <hr>
    <b>Step 3: Stop and Unload All Services</b>

    All system and user services are stopped and unloaded from the service cache.

    <hr>
    <b>Step 4: Stop @ref httpserver "HTTP Server"</b>

    Any requests in progress must complete before the server can be stopped.  After this point, no external
    communication is possible with the Qorus system.

    <hr>
    <b>Step 5: Close Application Session</b>

    The application session is marked as closed in the system database.

    <hr>
    <b>Step 6: Close System Log Files</b>

    System log files are closed.
    <hr>

    System shutdown is the last @ref systemevents "system event" raised by the system; the event raised is
    @ref SYSTEM_SHUTDOWN "SYSTEM_SHUTDOWN".

    @section RBAC Role Based Access Control

    The Community Edition of Qorus does not support users, roles, and permissions; these are only supported in the
    Enterprise Edition.

    <b>RBAC Concepts</b>
    |!RBAC Concept|!Description
    |@ref rbacgroups "interface group"|An interface group contains lists of @ref workflowmodel "workflows", \
        @ref services "services", @ref jobs "jobs", \
        @ref finite_state_machines "finite state machines", @ref data_pipelines "pipelines", @ref mappers "mappers", \
        @ref value-maps "value maps"; associated interfaces can be enabled or disabled \
        for operational reasons by enabling or disabling the interface group, and the group can be applied to roles \
        to limit access to those objects through the system API.

    @subsection rbacgroups Interface Groups

    An interface group is contains a list of workflows, user services, jobs, @ref mappers "mappers",
    @ref value-maps "value maps", @ref finite_state_machines "finite state machines", and
    @ref data_pipelines "data pipelines"; groups can be enabled and disabled.

    Interface groups service the following functions:
    - they allow larger Qorus installations the flexibility to restrict access only to data and services needed by
      particular operations or business personnel (ie permit a multi-tenant configuration of Qorus)
    - they allow interfaces to be grouped logically
    - they allow interfaces to be temporarily enabled or disabled as a group for operational reasons

    If a group is disabled, then no workflows, services, or jobs in the group can be started; if a group is disabled
    while member workflow execution instances, services are running or loaded, or jobs are active, then they will be
    immediately stopped when the group is disabled.

    When an interface group is enabled, then all workflows with a non-zero autostart value are started, all services
    with their autostart flag set are loaded, and all active jobs in the group are reactivated (assuming they are not
    also members of another disabled group or they do not have connection dependencies that prohib them to be
    started).

    @note
    - The \c "DEFAULT" group cannot be disabled or deleted

    @subsubsection defaultgroup DEFAULT Interface Group

    The \c "DEFAULT" group (@ref OMQ::DefaultGroupName) with ID 0 (@ref OMQ::DefaultGroupID) is a special system group
    that automatically contains all system objects.

    @section auditing System Auditing

    Qorus supports writing out database records for system and user events; this solution is called system auditing;
    records are written to the \c AUDIT_EVENTS table.

    System auditing is enabled by setting the @ref audit system option.  Audit events can be used to keep a security
    record of actions taken in the system, or to explicitly track KPIs (Key Process Indicators) for SLA tracking, for
    example (see the audit_user_event() function, for example).

    The @ref audit system option accepts the codes in the following table (corresponding to @ref AuditOptions).

    <b>Audit Option Codes</b>
    |!Code|!Description
    |\c alerts|Setting this option will cause alert events to be written to the \c AUDIT_EVENTS table
    |\c api|Setting this option will cause every api call that makes changes to be audited in the \c AUDIT_EVENTS \
        table
    |\c groups|Setting this option will cause group status change events to be written to the \c AUDIT_EVENTS table
    |\c jobs|Setting this option will cause job start and stop events to be audited
    |\c job-data|Setting this option will cause job instance start and stop events to be audited (each time a job is \
        executed an event will be written to \c AUDIT_EVENTS when the job starts and then when it stops)
    |\c oload|Setting this option will cause @ref oload "oload" to write audit events when source code is loaded \
        into the system schema
    |\c services|Setting this option will audit service start and stop events
    |\c system|Setting this option will audit system startup, shutdown, and recovery events
    |\c user-events|Setting this option will cause every call to audit_user_event() to be written to the \
        \c AUDIT_EVENTS table; if this audit option is not set, then calls to audit_user_event() will be discarded
    |\c workflow-data|Setting this option will audit workflow status changes; note that this will have a performance \
        impact as each change to a workflow order's status will cause a row to be written in the \c AUDIT_EVENTS table
    |\c workflows|Setting this option will audit workflow start and stop events

    @note If an event is not audited, then it is neither written to the database nor logged in the audit log file.

    @subsection auditevents Audit Events

    Audit events are written to the \c AUDIT_EVENTS table; each audit event has attributes as in the following table:

    <b>Audit Event Attributes</b>
    |!Column|!Type|!Description
    |\c audit_eventid|number|a unique number assigned to the event (created from a database sequence)
    |[\c related_audit_eventid]|number|an optional event id that this event is related to
    |[\c workflowid]|number|if the event is related to a workflow, the workflowid
    |[\c workflow_instanceid]|number|if the event is related to a workflow instance, the workflow instance id
    |[\c stepid]|number|if the event is related to a workflow step, the stepid
    |[\c ind]|number|if the event is related to a step, the step index number (always 0 for non array steps)
    |[\c jobid]|number|if the event is related to a job, the jobid
    |[\c job_instanceid]|number|if the event is related to a job instance, the job instance id
    |[\c serviceid]|number|if the event is related to a service, the serviceid
    |\c audit_event_code|number|a code giving the audit event type; see @ref AuditEventCodes for possible values
    |[\c audit_user_event]|string|for user events, the user event code
    |[\c reason]|string|a reason for the event (ex: if due to an API call, then the API name, ex \
        \c "REST PUT api/latest/services/my-example-service/method?action=call", if due to normal system processing, \
        then the string \c "internal call")
    |\c who|string|the @ref RBAC "RBAC" user who initiated the action that led to the event, or \c "Qorus" if due to \
        normal system processing or no username is available
    |\c source|string|the source of the call that led to the event (ex: \
        \c "source: ipv6[::1]:50653 listener: ipv6[::]:8001") or \c "system" if due to normal system processing
    |[\c info1]|string|an informational string related to the event
    |[\c info2]|string|an informational string related to the event
    |\c created|date/time|the date and time the event was created in the database

    @section systemevents System Events

    Qorus includes an event sink that maintains a list of system events.  System events can be read internally and
    externally through the system API.

    The system option @ref max-events controls the maximum number of system events the system will store.

    System events are identified by an @link EventClasses event class@endlink and an
    @link EventCodes event code@endlink, and each event also contains addtional information describing details of the
    event.  Note that there is a special system event, @ref USER_EVENT "USER_EVENT", that is used for all user events;
    user events are differentiated by their custom content as supplied by the user code when the event is raised.

    The following give some links to additional information about events:
    - see @ref EventClasses for a list of possible event classes
    - see @ref EventCodes for a list of possible event codes
    - For a list of event functions in the service API, see @ref service_event_functions "Service Event Handling Methods"
    - For a list of system APIs related to event processing, see @ref eventmethods "Event API Methods".
    - For a description of event data structures and a list of all system events, see @ref events "Event Descriptions"

    @section transmodel Database Transaction Model

    @subsection statemachine State Machine

    Basically the Qorus Integration Engine&reg; system can be considered a workflow state machine that uses the Oracle
    database to store the workflow state data.

    After every atomic transaction any changes to the database are immediately committed.  By design there are no
    cases where state information relevant to state recovery after a crash is internally queued in the system and
    committed later.  While this can have a negative performance impact, it reduces the impact of system crashes and
    makes complete system/workflow recovery possible (as long as the database remains intact).

    @note Never update the Qorus system schema directly using SQL; always system APIs.  Any inconsistencies in the
    system schema can lead to data corruption, deadlocks, or other errors.  Additionally any row, table, or other
    locks created manually when Qorus is running can lead to deadlocks; never lock any database object using SQL in
    the system schema while the system is running.

    Access to the system schema where transaction management is required is made through a connection pool, where
    connections are automatically assigned to threads as needed.  Connections are acquired when the first statements
    that make changes to the database are executed and released to the pool when each thread does a commit or rollback
    on the connection.

    @subsection recoverymodel Recovery Model

    Due to the system's design, the worst-case scenario for a system crash is that workflow order data instances (i.e.
    also segment and step instances) will incorrectly have an @ref OMQ::StatInProgress status in the database after
    the crash.  That means that the information loss is well defined and limited to the bottom level of the workflow
    order data instance; the steps with an @ref OMQ::StatInProgress status may have been subject to information loss.

    When a crashed session is recovered, all workflow order data instances, segment instances, and step instances with
    an @ref OMQ::StatInProgress are modified to @ref OMQ::StatRetry and the workflow order data instance rows (the
    parent object) are cleared of the crashed session's ID.

    A well-defined workflow will have recovery logic where necessary that will verify the status of any errored step
    before repeating the step's actions (by defining @ref validationcode "validation logic" in the step).  In this
    case, the workflow developer can ensure the automatic recovery of the step with no data loss after a system crash.

    @section httpserver HTTP Server

    Qorus includes a built-in HTTP server providing a gateway to internal protocol handlers.  To better support
    compression with large messages, the HTTP server understands and can generate \c "deflate"
    (<a href="http://www.ietf.org/rfc/rfc1951.txt">RFC1951</a>), \c "gzip"
    (<a href="http://www.ietf.org/rfc/rfc1952.txt">RFC1952</a>), and \c "bzip" content-encodings and will respect
    client preferences as transmitted in the \c "Accept-Encodings" HTTP header.

    A new thread is launched to handle each incoming request so the system can handle many requests simultaneously.

    Qorus supports the following top-level paths by default (note that requests are also matched by \c Content-Type if
    applicable):

    <b>Qorus HTTP Server Protocol Handlers</b>
    |!Path|!Content-Type|!Handler|!Description
    |\c /YAML|\c application/x-yaml|\c YamlRpcHandler|Handles @ref YAMLRPC "YAML-RPC" requests; acts as a \
        @ref YAMLRPC "YAML-RPC" gateway to the system API
    |\c /RPC2|\c text/xml|\c XmlRpcHandler|Handles XML-RPC requests; acts as an XML-RPC gateway to the system API
    |\c /JSON|\c application/json|\c JsonRpcHandler|Handles JSON-RPC requests; acts as a JSON-RPC gateway to the system API
    |\c /SOAP|\c text/xml or \c application/soap+xml|\c SoapHandler|Handles SOAP requests for user services exported \
        with @ref OMQ::UserApi::Service::ServiceApi::registerSoapHandler() "ServiceApi::registerSoapHandler()"
    |\c /api|\c application/x-yaml, \c text/xml, \c application/json|<tt>@ref restapi "REST"</tt>|Implements the \
        system @ref restapi "REST API"
    |\c /apievents|n/a|\c WebSocketHandler|Handles requests for system events over the \
        <a href="http://tools.ietf.org/html/rfc6455">RFC-6455</a> \
        <a href="http://en.wikipedia.org/wiki/Websocket">WebSocket</a> protocol
    |\c /creator|n/a|\c WebSocketHandler|Handles requests for the creator API with the \
        <a href="http://tools.ietf.org/html/rfc6455">RFC-6455</a> \
        <a href="http://en.wikipedia.org/wiki/Websocket">WebSocket</a> protocol
    |\c /log|n/a|\c WebSocketHandler|Handles requests for log file events over the \
        <a href="http://tools.ietf.org/html/rfc6455">RFC-6455</a> \
        <a href="http://en.wikipedia.org/wiki/Websocket">WebSocket</a> protocol
    |\c /remote-command|n/a|\c WebSocketHandler|Handles requests for remote commands over the \
        <a href="http://tools.ietf.org/html/rfc6455">RFC-6455</a> \
        <a href="http://en.wikipedia.org/wiki/Websocket">WebSocket</a> protocol
    |\c /webdav|n/a|\c FsWebDavHandler|Handles requests for \
        <a href="https://en.wikipedia.org/wiki/WebDAV">WebDAV clients</a>

    Any requests not matched with a protocol handler are handled by the default handler, which serves the system
    web UI.

    @subsesion http_rest_handler REST Handler

    The Qorus REST API handler handles requests on the \c /api URI path.

    The following header can be given by clients to specify the client's
    <a href="https://en.wikipedia.org/wiki/List_of_tz_database_time_zones">time zone region</a>:
    - \c Qorus-Client-Time-Zone

    For example:
    @verbatim
Qorus-Client-Time-Zone: America/New_York
    @endverbatim

    This allows the REST server to handle date/time values in the client's time zone.

    @subsection webdav_server WebDAV Server

    Remote clients can access the <tt>$OMQ_DIR/user</tt> filesystem using the
    <a href="https://en.wikipedia.org/wiki/WebDAV">WebDAV</a> protocol.

    Directories with the same name as @ref rbacgroups "interface groups" that the user has associated with their
    account are also accessible.
  */

/** @page appsessionmodel Application Session Model

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section appsessionoverview Application Session Overview

    Qorus Integration Engine&reg; application sessions should not to be confused with database sessions.
    Conceptually, an application session corresponds to an instance of Qorus Integration Engine&reg; that is (or was)
    running on an Qorus database schema, and directly corresponds to a row in the \c SESSIONS table in the Qorus
    system schema.  The Qorus instance is identified by its instance key, normally set in the @ref options.

    @section appsessioninit Session Initiation

    When Qorus starts, it checks the \c SESSIONS table for a row with an \c ACTIVE status.  If such a session is
    found, and the Qorus instance is running, then an error message is displayed, and the system will not start, as it
    is illegal for the same instance to have more than one active session in the same Qorus database.

    This rule is designed to allow for session recovery in the case of system failures, while still allowing for
    concurrent Qorus instances to access the same database.

    Otherwise, if no \c ACTIVE row in the \c SESSIONS table for the current instance is found, a new row is created
    with the current session ID and the status is set to \c ACTIVE.

    @section appsessionrecovery Session Recovery

    In the case of a system failure, such as a system crash, a session will normally be left open (status still set to
    \c ACTIVE) even though the Qorus process is no longer running.

    In this case, @ref qorus-core "qorus-core" will try to contact the instance using the URL given in the
    \c SESSIONS.XMLRPC_SERVER field.  If the server can be contacted, then the process assumes that the Qorus server
    is still running, and refuses to start again, exiting with an error message.  Otherwise system recovery takes
    place with the following recovery actions.

    The session recovery procedures (SQL select/update statements) are split into batches due the performance reasons.
    It means that all steps described below are performend 1..N times depending on amount of data in the system
    database schema.

    Size of these batches can be set by options:
    - @ref sql-default-blocksize

    <hr>
    <b>Step 1: Set IN-PROGRESS Step Instance Statuses to RETRY</b>

    Any step instances with status @ref OMQ::StatInProgress that belong to a workflow instance marked with the failed
    session's session ID will have the step instance status set to @ref OMQ::StatRetry.

    <hr>
    <b>Step 2: Set IN-PROGRESS Segment Instance Status to RETRY</b>

    Any segment instances with status @ref OMQ::StatInProgress that belong to a workflow instance marked with the
    failed session's session ID will have the segment instance status set to @ref OMQ::StatRetry.

    <hr>
    <b>Step 3: Set IN-PROGRESS Workflow Instance Status to RETRY</b>

    Any workflow instances with status @ref OMQ::StatInProgress that are also tagged with the failed session's session
    ID will have the workflow instance status set to @ref OMQ::StatRetry.

    <hr>
    <b>Step 4: Clear Old Session ID From Workflow Instances</b>

    Any remaining workflows marked with the old session's ID will have the session ID column cleared.
    <hr>

    All of the above actions are logged.

    @note
    - @ref qwf "qwf" and @ref qjob "qjob" processes recover their own application sessions if they abort and are
      restarted
*/

/** @page connmon Connections and Connection Monitoring

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section conn_intro Introduction to Connections

    Qorus supports automatic connection monitoring and dependent interface management based on connection status.  The
    following connection types are monitored:
    - @ref remoteconn
    - @ref userconn
    - @ref dsconn

    @note Automatic interface management can be disabled by setting system option @ref manage-interfaces to
    @ref False; in this case interfaces are not started and stopped automatically based on their connection status

    All connections are defined in the database (in the \c CONNECTIONS table) and are usually created as a part of a
    user release, but can also be created via REST API calls (ex: @ref rest_api_POST_latest_remote_user).

    @section remoteconn Qorus to Qorus Connections

    These connection definitions can be used in user code (@ref workflowmodel "workflow", @ref services "service", and
    @ref jobs "job" code) by using one of the following APIs:
    - @ref OMQ::UserApi::UserApi::getRemoteRpcConnection() "UserApi::getRemoteRpcConnection()": returns a
      @ref OMQ::QorusSystemAPIHelper "QorusSystemAPIHelper" object for communicating with the remote Qorus instance's
      @ref rpcapi "RPC API"
    - @ref OMQ::UserApi::UserApi::getRemoteRestConnection() "UserApi::getRemoteRestConnection()": returns a
      @ref OMQ::QorusSystemRestHelperBase "QorusSystemRestHelper" object for communicating with the remote Qorus
      instance's @ref restapi "REST API"

    @note Each of the APIs above includes a \a register_dependency argument that can be used to supress the creation
    of any dependency between the interface and the connection; see the API method documentation for more information.

    @see @ref rest_api_GET_latest_remote_qorus for information about manipulating remote Qorus to Qorus connections
    via the REST API

    @note
    - The \c "qorus" connection name is provided by default by the
      @ref qorusconnectionproviderintro "QorusConnectionProvider" module as a connnection to the local Qorus instance,
      therefore it's recommended not to use \c "qorus" for a @ref userconn "user" or @ref remoteconn "remote"
      connection name
    - Loopback connections should always use one of \c "::" \c "127.0.0.1", or \c "localhost" as the target host name
      in the URL in order to be recognized as loopback connections

    <b>Remote Connection Types</b>
    |!Scheme|!Object|!Description
    |\c "qorus"|@ref OMQ::QorusSystemRestHelper|unencrypted Qorus HTTP connections
    |\c "qoruss"|@ref OMQ::QorusSystemRestHelper|encrypted Qorus HTTPS connections

    <b>Remote Connection Keys</b>
    |!Key|!Mandatory?|!Description|!Example
    |\c url|Y|full URL to remote instance|\c http://user:pass@localhost:8001
    |\c desc|N|public description of the connection|production server 2
    |\c proxy|N|full URL to proxy used for remote instance|\c http://proxy.mydomain.com
    |\c connect_timeout|N|Initial connection timeout in seconds|\c 10
    |\c timeout|N|Timeout for regular user calls in seconds|\c 30
    |\c api_version|N|The REST API version for REST connections; default: \c "latest"|\c v2
    |\c ignore_socket_warnings|N|If \c true then socket I/O warnings will not be issued for the given remote \
        connection|\c true

    <b>Deployment (qconn) File Example</b>
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-qorus-1
desc: My Remote Qorus Instance
url: qorus://example.com:8001
options:
    timeout:
        type: int
        value: 30
    @endverbatim

    @see
    - @ref definingconnections

    @section userconn User Connections

    User connections are acquired in user code by the following API:
    - @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()": returns the connection object
      described by the user connection

    User connections can be disabled and enabled by an operator (or authenticated user). The functionality is covered
    by @ref rest_api_remote_user

    User connection objects are of the type defined by the connection; the connection URLs and connection objects in
    the following table are supported by Qorus (see @ref connection-modules for an option allowing for user-defined
    connection types).

    @anchor userconntypes
    <b>User Connection Types</b>
    |!Scheme|!Object|!Documentation
    |\c awsrests|@ref AwsRestClient::AwsRestClient "AwsRestClient"|@ref userconn_awsrest
    |\c billwerkrest, \c billwerkrests|@ref BillwerkRestClient::BillwerkRestClient "BillwerkRestClient"|\
        @ref userconn_billwerkrest
    |\c cdsrests|@ref CdsRestClient::CdsRestClient "CdsRestClient"|@ref userconn_cdsrest
    |\c file, \c dir|@ref Qore::Dir "Dir"|@ref userconn_file
    |\c ftp, \c ftps|@ref Qore::FtpClient "FtpClient"|@ref userconn_ftp
    |\c http, \c https|@ref Qore::HTTPClient "HTTPClient"|@ref userconn_http
    |\c jsonrpc, \c jsonrpcs|@ref Qore::Json::JsonRpcClient "JsonRpcClient"|@ref userconn_jsonrpc
    |\c pop3, \c pop3s|@ref Pop3Client::Pop3Client "Pop3Client"|@ref userconn_pop3
    |\c rest, \c rests|@ref RestClient::RestClient "RestClient"|@ref userconn_rest
    |\c sap4hanarests|@ref Sap4HanaRestClient::Sap4HanaRestClient "Sap4HanaRestClient"|@ref userconn_sap4hanarest
    |\c sewiorest, \c sewiorests|@ref SewioRestClient::SewioRestClient "SewioRestClient"|@ref userconn_sewiorest
    |\c sewiows, \c sewiowss|@ref SewioWebSocketClient::SewioWebSocketConnection "SewioWebSocketConnection"|\
        @ref userconn_sewiowebsocket
    |\c sftp|@ref Qore::SSH2::SFTPClient "SFTPClient"|@ref userconn_sftp
    |\c sfrests|@ref SalesforceRestClient::SalesforceRestClient "SalesforceRestClient"|@ref userconn_sfrest
    |\c smtp, \c smtps, \c smtptls,\n \c esmtp, \c esmtptls|@ref SmtpClient::SmtpClient "SmtpClient"|\
        @ref userconn_smtp
    |\c snrests|@ref ServiceNowRestClient::ServiceNowRestClient "ServiceNowRestClient"|@ref userconn_snrest
    |\c soap, \c soaps|@ref SoapClient::SoapClient "SoapClient"|@ref userconn_soap
    |\c telnet|@ref TelnetClient::TelnetClient "TelnetClient"|@ref userconn_telnet
    |\c ws, \c wss|@ref WebSocketClient::WebSocketClient "WebSocketClient"|@ref userconn_websocket
    |\c xmlrpc, \c xmlrpcs|@ref Qore::Xml::XmlRpcClient "XmlRpcClient"|@ref userconn_xmlrpc
    |\c yamlrpc, \c yamlrpcs|@ref YamlRpcClient::YamlRpcClient "YamlRpcClient"|@ref userconn_yamlrpc
    |\c zeyosrest, \c zeyosrests|@ref ZeyosRestClient::ZeyosRestClient "ZeyosRestClient"|@ref userconn_zeyosrest

    @see
    - @ref definingconnections
    - @ref connection-modules
    - @ref ConnectionProvider::AbstractConnection "AbstractConnection"
    - @ref SalesforceSoapConnection

    @note The \c "qorus" connection name is provided by default by the
    @ref qorusconnectionproviderintro "QorusConnectionProvider" module as a connnection to the local Qorus instance,
    therefore it's recommended not to use \c "qorus" for a @ref userconn "user" or @ref remoteconn "remote" connection
    name

    @subsection userconn_awsrest AWS REST User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref AwsRestClient::AwsRestClient "AwsRestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: awsrest-connection
desc: My AWS REST HTTP connection
url: awsrests://iotevents.eu-central-1.amazonaws.com
options:
    client_id:
        type: string
        value: V9HjEFLihcwfAbxAJUvxzifnE7uwuNFoEYjNoK5kxI1GubH1Cc9khkXNHBIQ6ljbJGRw1PRxIe2CI9K3rBZQF
    client_secret:
        type: string
        value: JrL7TeubWmQwxUb5Ry5
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "sfrests"|encrypted Salesforce.com REST HTTP connections

    @par Connection Options
    |!Option|!Description
    |\c "api"|the Salesforce.com API to use; use \c "auto" (the default) to use the latest API version
    |\c "aws_keyid"|(required) the AWS key ID
    |\c "aws_region"|the AWS region to use (ex: \c "us-east-1"); if it cannot be derived from the URL then it is a \
        required option
    |\c "aws_service"|the AWS service to use (ex: \c "iam"); if it cannot be derived from the URL then it is a \
        required option
    |\c "aws_secret"|(required) the AWS secret access key value
    |\c "aws_token"|a temporary session token from AWS Security Token Service for this HTTP session
    |\c "aws_s3"|set to True to flag this object for use with AWS aws_s3, which requires special message encoding
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); ex: \
        <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref AwsRestClient::AwsRestConnection
    - @ref AwsRestClient::AwsRestClient "AwsRestClient::constructor()" for more information on the above options

    @subsection userconn_billwerkrest billwerk.com REST API User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref BillwerkRestClient::BillwerkRestClient "BillwerkRestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: billwerkrests-connection
desc: My billwerk.com REST HTTP connection
url: billwerkrests://api.billwerk.com
options:
    client_id:
        type: string
        value: _id_
    client_secret:
        type: string
        value: _secret_
    swagger:
        type: string
        value: "https://developer.billwerk.io/swagger.json"
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "billwerkrest"|unencrypted billwerk.com REST HTTP connections
    |\c "billwerkrests"|encrypted billwerk.com REST HTTPS connections

    @par Connection Options
    |!Option|!Description
    |\c "name" (optional*)|the <a href="https://billwerk.com">billwerk.com</a> username; required if \
        \c client_secret is not provided
    |\c "password" (optional*)|the <a href="https://billwerk.com">billwerk.com</a> user password; required if \
        \c client_secret is not provided
    |\c "client_id" (mandatory)|the <a href="https://billwerk.com">billwerk.com</a> client ID
    |\c "client_secret" (optional*)|the <a href="https://billwerk.com">billwerk.com</a> client secret; required if \
        \c username and \c password are not provided
    |\c "token"|the <a href="https://billwerk.com">billwerk.com</a> token, if provided then name, password, \
        client_id and client_secret are not needed and will be ignored
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "data"|see @ref RestClient::RestClient::DataSerializationOptions for possible values when used with the null \
        REST schema validator; the default is \c "json"
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); \
        ex: <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref BillwerkRestClient::BillwerkRestConnection
    - @ref BillwerkRestClient::BillwerkRestClient "BillwerkRestClient::constructor()" for more information on the
      above options

    @since %Qorus 4.1.2

    @subsection userconn_cdsrest Microsoft Dynamics 365 / Common Data Service REST User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref CdsRestClient::CdsRestClient "CdsRestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: My Dynamics 365 Connection
desc: test
url: cdsrests://qt-dev.crm4.dynamics.com
options:
    client_id:
        type: string
        value: fba80400-68e9-43dd-8cf2-fe163b730365
    client_secret:
        type: string
        value: "DkIMz?!NW(aHOkb'5>GF328-no*')xbU"
    tenant:
        type: string
        value: d630b231-ae5a-411a-b9d5-0f70af81f034
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "cdsrests"|encrypted Microsoft Dynamics 365 / Common Data Service REST HTTP connections

    @par Connection Options
    |!Option|!Description
    |\c "api"|the CDS API level to use; if not present, the default API level for the \
        @ref CdsRestClient::CdsRestClient "CdsRestClient" object is used
    |\c "client_id"|(required) the CDS client ID
    |\c "client_secret"|(required) the CDS client secret
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "data"|see @ref RestClient::RestClient::DataSerializationOptions "DataSerializationOptions" for possible \
        values; the default is \c "json"
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "scope"|the scope to use when logging in; the default is to use the URL + \c "/.default"
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); \
        ex: <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "tenant"|(required) the tenant ID to use
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref CdsRestClient::CdsRestClient
    - @ref CdsRestClient::CdsRestClient "CdsRestClient::constructor()" for more information on the above options

    @since Qorus 5.0

    @subsection userconn_file Filesystem/Directory User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a @ref Qore::Dir "Dir"
    object giving a location on the local system's filesystem; monitoring monitors for free space.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: file-connection
desc: filesystem connection
url: "file://$SOME_DIRECTORY/input"
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "dir"|filesystem connection
    |\c "file"|filesystem connection

    @see @ref ConnectionProvider::FilesystemConnection

    @subsection userconn_ftp FTP User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns an
    @ref Qore::FtpClient "FtpClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: ftp-connection
desc: My FTP connection
url: ftp://user:pass@example.com:8080/path
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "ftp"|FTP connections; default control port 21 if not present in the URL
    |\c "ftps"|<a href="https://en.wikipedia.org/wiki/FTPS">FTPS</a> connections; secure FTP (not SFTP); default \
        control port 21 if not present in the URL

    @see
    - @ref ConnectionProvider::FtpConnection
    - @ref userconn_sftp

    @subsection userconn_http HTTP User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns an
    @ref Qore::HTTPClient "HTTPClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: http-connection
desc: My HTTP connection
url: https://user:pass@example.com:8080/path
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "http"|non-encrypted HTTP connections; default port 80 if not present in the URL
    |\c "https"|encrypted HTTPS connections; default port 443 if not present in the URL

    @par Connection Options
    |!Option|!Description
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref ConnectionProvider::HttpConnection
    - @ref Qore::HTTPClient::constructor(hash<auto>) "HTTPClient::constructor(hash opts)" for more information on the
      above options

    @subsection userconn_jsonrpc JSON-RPC User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref Qore::Json::JsonRpcClient "JsonRpcClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: jsonrpc-connection
desc: My JSON-RPC connection
url: jsonrpcs://user:pass@example.com:8080/path
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "jsonrpc"|non-encrypted JSON-RPC HTTP connections; default port 80 if not present in the URL
    |\c "jsonrpcs"|encrypted JSON-RPC HTTPS connections; default port 443 if not present in the URL

    @par Options
    |!Option|!Description
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "timeout"|transfer timeout to use in milliseconds
    |\c "connect_timeout"|connection timeout to use in milliseconds

    @see
    - @ref JsonRpcConnection::JsonRpcConnection
    - @ref Qore::Json::JsonRpcClient::constructor() "JsonRpcClient::constructor()" for more information on the above
      options

    @subsection userconn_pop3 POP3 User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref Pop3Client::Pop3Client "Pop3Client" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: pop3-connection
desc: My POP3 connection
url: pop3s://username@example.com:password@pop.gmail.com
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "pop3"|non-encrypted POP3 connections; default port 110 if not present in the URL
    |\c "pop3s"|encrypted POP3 connections; default port 995 if not present in the URL

    @par Runtime Connection Options
    |!Option|!Description
    |\c "log"|a closure accepting a single string for logging
    |\c "dbglog"|a closure taking a single string for detailed technical connection logging

    @see @ref Pop3Client::Pop3Connection

    @subsection userconn_rest REST User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref RestClient::RestClient "RestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: rest-connection
desc: My REST HTTP connection
url: rests://user:pass@example.com:8080/path
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "rest"|non-encrypted REST HTTP connections; default port 80 if not present in the URL
    |\c "rests"|encrypted REST HTTPS connections; default port 443 if not present in the URL

    @par Connection Options
    |!Option|!Description
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "data"|see @ref RestClient::RestClient::DataSerializationOptions "DataSerializationOptions" for possible \
        values; the default is \c "auto"; note that it's recommended to use \c "yaml" when talking to Qorus
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); ex: \
        <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref RestClient::RestConnection
    - @ref RestClient::RestClient "RestClient::constructor()" for more information on the above options

    @subsection userconn_sap4hanarest SAP S/4Hana REST API User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref Sap4HanaRestClient::Sap4HanaRestClient "Sap4HanaRestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-sap-connection
desc: My SAP S/4Hana REST HTTPS connection
url: sap4hanarests://https://sandbox.api.sap.com/s4hanacloud/sap/opu/odata/sap
options:
    apikey:
        type: string
        value: V3EC5RWfWTTn9Gl5xWTVwevWHCT1vusdG
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "sap4hanarests"|encrypted SAP S/4Hana REST HTTPS connections

    @par Connection Options
    |!Option|!Description
    |\c "apikey"|(required) the SAP S/4Hana API key
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "data"|see @ref RestClient::RestClient::DataSerializationOptions "DataSerializationOptions" for possible \
        values; the default is \c "json"
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); \
        ex: <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref Sap4HanaRestClient::Sap4HanaRestClient
    - @ref Sap4HanaRestClient::Sap4HanaRestClient "Sap4HanaRestClient::constructor()" for more information on the
      above options

    @since %Qorus 4.0.3.p2

    @subsection userconn_sewiorest Sewio.net RTLS Studio REST API User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a @ref SewioRestClient::SewioRestClient "SewioRestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-sewiorest-connection
desc: My Sewio.net RTLS Studio REST HTTPS connection
url: sewiorest://rtlsstudio.com/sensmapserver
options:
    apikey:
        type: string
        value: JrL7TeubWmQwxUb5Ry5
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "sewiorest"|unencrypted Sewio.net RTLS Studio REST HTTP connections
    |\c "sewiorests"|encrypted Sewio.net RTLS Studio REST HTTPS connections

    @par Connection Options
    |!Option|!Description
    |\c "apikey"|(required) the Sewio.net API key
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "data"|see @ref RestClient::RestClient::DataSerializationOptions "DataSerializationOptions" for possible \
        values; the default is \c "json"
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); \
        ex: <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref SewioRestClient::SewioRestConnection
    - @ref SewioRestClient::SewioRestClient "SewioRestClient::constructor()" for more information on the above options

    @since %Qorus 3.1.1

    @subsection userconn_sewiowebsocket Sewio WebSocket User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref SewioWebSocketClient::SewioWebSocketClient "SewioWebSocketClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-sewiows-connection
desc: My Sewio.net RTLS Studio WebSocket connection
url: sewiows://rtlsstudio.com:8080
options:
    apikey:
        type: string
        value: JrL7TeubWmQwxUb5Ry5
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "sewiows"|non-encrypted Sewio WebSocket connections; default port 80 if not present in the URL
    |\c "sewiowss"|TLS/SSL encrypted Sewio WebSocket connections; default port 443 if not present in the URL

    @par Options
    |!Option|!Description
    |\c "apikey"|(required) Sewio API key
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "timeout"|transfer timeout to use in milliseconds

    @par Runtime Connection Options
    |!Option|!Description
    |\c "callback"|(required) a callback for websocket events
    |\c "dbglog"|a closure taking a single string for detailed technical connection logging
    |\c "errlog"|a closure taking a single string for error logging
    |\c "log"|a closure accepting a single string for logging

    @see
    - @ref SewioWebSocketClient::SewioWebSocketConnection
    - @ref SewioWebSocketClient::SewioWebSocketClient::constructor() "SewioWebSocketClient::constructor()" for more
      information on the above options

    @since %Qorus 3.1.1

    @subsection userconn_sfrest Salesforce.com REST User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref SalesforceRestClient::SalesforceRestClient "SalesforceRestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-sfrest-connection
desc: My Salesforce.com REST HTTP connection
url: sfrests://user:password@login.salesforce.com/services/oauth2/token
options:
    client_id:
        type: string
        value: V9HjEFLihcwfAbxAJUvxzifnE7uwuNFoEYjNoK5kxI1GubH1Cc9khkXNHBIQ6ljbJGRw1PRxIe2CI9K3rBZQF
    client_secret:
        type: string
        value: JrL7TeubWmQwxUb5Ry5
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "sfrests"|encrypted Salesforce.com REST HTTP connections

    @par Connection Options
    |!Option|!Description
    |\c "api"|the Salesforce.com API to use; use \c "auto" (the default) to use the latest API version
    |\c "client_id"|(required) the Salesforce.com "consumer key" for the Connected App
    |\c "client_secret"|(required) the Salesforce.com "consumer secret" for the Connected App
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "data"|see @ref RestClient::RestClient::DataSerializationOptions "DataSerializationOptions" for possible \
        values; the default is \c "json"
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); \
        ex: <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref SalesforceRestClient::SalesforceRestConnection
    - @ref SalesforceRestClient::SalesforceRestClient "SalesforceRestClient::constructor()" for more information on the
      above options

    @subsection userconn_sftp SFTP Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref Qore::SSH2::SFTPClient "SFTPClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-sftp-connection
desc: My SFTP connection
url: sftp://username:password@sftp.example.com
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "sftp"|SFTP connections; default port 22 if not present in the URL

    @par Options
    |!Option|!Description
    |\c "keyfile"|a path to the private key file for key-based authentication

    @par Runtime Connection Options
    |!Option|!Description
    |\c "path"|overrides the path component in the URL at runtime
    |\c "path_add"|appends the given string to the path component of the URL at runtime

    @see @ref Ssh2Connections::SftpConnection

    @subsection userconn_smtp SMTP Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref SmtpClient::SmtpClient "SmtpClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-smtp-connection
desc: My SMTP connection
url: esmtptls://username:password@smtp.example.com
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "smtp"|standard SMTP port (25) without encryption; ESMPT and \c "STARTTLS" detection is supported \
        automatically
    |\c "smtps"|SMTP on port 465 without encryption; ESMPT and \c "STARTTLS" detection is supported automatically
    |\c "smtptls"|standard SMTP port (25); a \c "STARTTLS" command is executed unconditionally after the connection
    |\c "esmtp"|SMTP on port 587 without encryption; ESMPT and \c "STARTTLS" detection is supported automatically
    |\c "esmtptls"|SMTP on port 587; a \c "STARTTLS" command is executed unconditionally after the connection

    @par Runtime Connection Options
    |!Option|!Description
    |\c "log"|a closure accepting a single string for logging
    |\c "dbglog"|a closure taking a single string for detailed technical connection logging

    @see @ref SmtpClient::SmtpConnection

    @subsection userconn_snrest ServiceNow REST User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref ServiceNowRestClient::ServiceNowRestClient "ServiceNowRestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: My ServiceNow Connection
desc: test
url: snrests://dev493922.service-now.com
options:
    client_id:
        type: string
        value: b73a867187eb18f62d89820395417684
    client_secret:
        type: string
        value: "M09tfOc&NoEP(XCEKkT:T&V<lKR%+=h9hw"
    username:
        type: string
        value: admin
    password:
        type: string
        value: mypassword
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "snrests"|encrypted ServiceNow REST HTTP connections

    @par Connection Options
    |!Option|!Description
    |\c "api"|the API level to use; if not present, the default API level for the \
        @ref ServiceNowRestClient::ServiceNowRestClient "ServiceNowRestClient" object is used
    |\c "client_id"|(required) the OAuth2 client ID
    |\c "client_secret"|(required) the OAuth2 client secret
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "data"|see @ref RestClient::RestClient::DataSerializationOptions "DataSerializationOptions" for possible \
        values; the default is \c "json"
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "password"|(required) the ServiceNow password to use
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); \
        ex: <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "timeout"|transfer timeout to use in milliseconds
    |\c "username"|(required) the ServiceNow username to use

    @see
    - @ref ServiceNowRestClient::ServiceNowRestClient
    - @ref ServiceNowRestClient::ServiceNowRestClient "ServiceNowRestClient::constructor()" for more information on the above options

    @since Qorus 5.0.5

    @subsection userconn_soap SOAP Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref SoapClient::SoapClient "SoapClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-soap-connection
desc: My SOAP connection
url: soaps://example.com/service1?wsdl
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "soap"|SOAP connections; the URL here will be used to retrieve the WSDL using HTTP; use the \c "wsdl" option \
        to override (for example, to retrieve the WSDL from a file)
    |\c "soaps"|SOAP connections; the URL here will be used to retrieve the WSDL using HTTPS; use the \c "wsdl" \
        option to override (for example, to retrieve the WSDL from a file)

    @par Options
    |!Option|!Description
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref SoapClient::SoapClient::EncodingSupport "EncodingSupport"
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "port"|in case multiple port entries are found in the WSDL, give the one to be used here
    |\c "portType"|in case multiple portType entries are found in the WSDL, give the one to be used here
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref SoapClient::SoapClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "target_url"|overrides the URL in the WSDL (mapped to \c "url" in the \
        @ref SoapClient::SoapClient::constructor(hash<auto>) "SoapClient constructor" argument)
    |\c "timeout"|transfer timeout to use in milliseconds
    |\c "wsdl"|the @ref filelocationhandlerintro "location" of the WSDL for the connection; overrides the URL; \
        ex: <tt>resource://service-name:my-wsdl.xml</tt>

    @see
    - @ref SoapClient::SoapConnection
    - @ref SoapClient::SoapClient::constructor(hash<auto>) "SoapClient::constructor(hash opts)" for more information
      on the above options

    @subsection userconn_telnet TELNET User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref TelnetClient::TelnetClient "TelnetClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-telnet-connection
desc: My TELNET connection
url: telnet://username@example.com:password@example.com
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "telnet"|standard TELNET connections; default port 23 if not present in the URL

    @par Runtime Connection Options
    |!Option|!Description
    |\c "log"|a closure accepting a single string for logging
    |\c "dbglog"|a closure taking a single string for detailed technical connection logging

    @see @ref TelnetClient::TelnetConnection

    @subsection userconn_websocket WebSocket User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref WebSocketClient::WebSocketClient "WebSocketClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-ws-connection
desc: My WebSocket connection
url: wss://username:example.com:password@example.com
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "ws"|non-encrypted WebSocket connections; default port 80 if not present in the URL
    |\c "wss"|encrypted WebSocket connections; default port 443 if not present in the URL

    @par Options
    |!Option|!Description
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "timeout"|transfer timeout to use in milliseconds

    @par Runtime Connection Options
    |!Option|!Description
    |\c "callback"|(required) a callback for websocket events
    |\c "dbglog"|a closure taking a single string for detailed technical connection logging
    |\c "errlog"|a closure taking a single string for error logging
    |\c "log"|a closure accepting a single string for logging

    @see
    - @ref WebSocketClient::WebSocketConnectionObject
    - @ref WebSocketClient::WebSocketClient::constructor() "WebSocketClient::constructor()" for more information on
      the above options

    @subsection userconn_xmlrpc XML-RPC User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref Qore::Xml::XmlRpcClient "XmlRpcClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: xmlrpc-connection
desc: My XML-RPC connection
url: xmlrpcs://user:pass@example.com:8080/path
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "xmlrpc"|non-encrypted XML-RPC HTTP connections; default port 80 if not present in the URL
    |\c "xmlrpcs"|encrypted XML-RPC HTTPS connections; default port 443 if not present in the URL

    @par Options
    |!Option|!Description
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "timeout"|transfer timeout to use in milliseconds
    |\c "connect_timeout"|connection timeout to use in milliseconds

    @see
    - @ref XmlRpcConnection::XmlRpcConnection
    - @ref Qore::Xml::XmlRpcClient::constructor() "XmlRpcClient::constructor()" for more information on the above
      options

    @subsection userconn_yamlrpc YAML-RPC User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref YamlRpcClient::YamlRpcClient "YamlRpcClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: yamlrpc-connection
desc: My YAML-RPC connection
url: yamlrpcs://user:pass@example.com:8080/path
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "yamlrpc"|non-encrypted YAML-RPC HTTP connections; default port 80 if not present in the URL
    |\c "yamlrpcs"|encrypted YAML-RPC HTTPS connections; default port 443 if not present in the URL

    @par Options
    |!Option|!Description
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "timeout"|transfer timeout to use in milliseconds
    |\c "connect_timeout"|connection timeout to use in milliseconds

    @see
    - @ref YamlRpcClient::YamlRpcConnection
    - @ref YamlRpcClient::YamlRpcClient::constructor() "YamlRpcClient::constructor()" for more information on the
      above options

    @subsection userconn_zeyosrest Zeyos.com REST API User Connections

    @par Description
    @ref OMQ::UserApi::UserApi::getUserConnection() "UserApi::getUserConnection()" returns a
    @ref ZeyosRestClient::ZeyosRestClient "ZeyosRestClient" object; socket performance is monitored.

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-zeyosrest-connection
desc: My Zeyos.com REST HTTP connection
url: zeyosrest://cloud.zeyos.com/test
options:
    token:
        type: string
        value: 66f258ca62439adad2bf593f908032e255e125ed
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "zeyosrest"|unencrypted Zeyos.com REST HTTP connections
    |\c "zeyosrests"|encrypted Zeyos.com REST HTTPS connections

    @par Connection Options
    |!Option|!Description
    |\c "name" (mandatory)|the <a href="http://www.zeyos.com">zeyos.com</a> name
    |\c "password" (mandatory)|the <a href="http://www.zeyos.com">zeyos.com</a> password
    |\c "identifier" (mandatory)|the <a href="http://www.zeyos.com">zeyos.com</a> identifier
    |\c "appsecret" (mandatory)|the <a href="http://www.zeyos.com">zeyos.com</a> appsecret
    |\c "token"|the <a href="http://www.zeyos.com">zeyos.com</a> token, if provided then name, password, identifier \
        and appsecret are not needed and will be ignored.
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref RestClient::RestClient::EncodingSupport "EncodingSupport"
    |\c "data"|see @ref RestClient::RestClient::DataSerializationOptions "DataSerializationOptions" for possible \
        values; the default is \c "json"
    |\c "error_passthru"|if @ref True "True" then HTTP status codes indicating errors will not cause an \
        \c REST-RESPONSE-ERROR exception to be raised, rather such responses will be passed through to the caller \
        like any other response
    |\c "headers"|an optional hash of headers to send with every request, these can also be overridden in request \
        method calls; also a string giving headers can be given in the format: \
        <tt>header1=value, header2=value</tt>; the value will be parsed with \
        @ref Util::parse_to_qore_value() "parse_to_qore_value()"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref RestClient::RestClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "swagger"|the @ref filelocationhandlerintro "location" of a <a href="https://swagger.io/">Swagger 2.0</a> \
        REST schema file for runtime API validation (see the @ref swaggerintro "Swagger" module); \
        ex: <tt>resource://service-name:swagger-resource.yaml</tt>
    |\c "timeout"|transfer timeout to use in milliseconds

    @see
    - @ref ZeyosRestClient::ZeyosRestConnection
    - @ref ZeyosRestClient::ZeyosRestClient "ZeyosRestClient::constructor()" for more information on the above
      options

    @since %Qorus 4.0.1

    @subsection SalesforceSoapConnection SalesforceSoapConnection User Connection Module

    @par Description
    The SalesforceSoapConnection module can be used to provide access to Salesforce.com
    @ref userconn "user connections" in Qorus by returning
    @ref SalesforceSoapClient::SalesforceSoapClient "SalesforceSoapClient" objects to Qorus user code on demand.\n\n
    To use this module; add \c "SalesforceSoapConnection" to the @ref connection-modules system option in the
    @ref options "options file" as follows:
    @verbatim
qorus.connection-modules: SalesforceSoapConnection
    @endverbatim

    @par Example
    @verbatim
# This is a generated file, don't edit!
type: connection
name: my-sfsoap-connection
desc: My Salesforce.com CRM SOAP connection
url: sfsoap://ignored-see-wsdl-option
options:
    wsdl:
        type: string
        value: "file:///$OMQ_DIR/user/wsdl/enterprise.wsdl"
    username:
        type: string
        value: username@example.com
    password:
        type: string
        value: my_password
    token:
        type: string
        value: aJCabsJnXVtVxjWnjyyLNY1L
    @endverbatim

    @par Schemes
    |!URI Scheme|!Description
    |\c "sfsoap"|Salesforce.com SOAP HTTP connections; the URL here is used to retrieve the WSDL using HTTP; use the \
        \c "wsdl" option to override (for example, to retrieve the WSDL from a file)
    |\c "sfsoaps"|Salesforce.com SOAP HTTP connections; the URL here is used to retrieve the WSDL using HTTPS; use \
        the \c "wsdl" option to override (for example, to retrieve the WSDL from a file)

    @par Connection Options
    |!Option|!Description
    |\c "connect_timeout"|connection timeout to use in milliseconds
    |\c "content_encoding"|this sets the send encoding (if the \c "send_encoding" option is not set) and the \
        requested response encoding; for possible values, see \
        @ref SoapClient::SoapClient::EncodingSupport "EncodingSupport"
    |\c "http_version"|HTTP version to use (\c "1.0" or \c "1.1", defaults to \c "1.1")
    |\c "max_redirects"|maximum redirects to support
    |\c "password"|(required) the Salesforce.com password to use for the connection; can be specified using system \
        properties instead (see below)
    |\c "port"|in case multiple port entries are found in the WSDL, give the one to be used here
    |\c "portType"|in case multiple portType entries are found in the WSDL, give the one to be used here
    |\c "proxy"|proxy URL to use
    |\c "send_encoding"|a @ref SoapClient::SoapClient::EncodingSupport "send data encoding option" or the value \
        \c "auto" which means to use automatic encoding; if not present defaults to no content-encoding on sent \
        message bodies
    |\c "target_url"|overrides the URL in the WSDL (mapped to \c "url" in the \
        @ref SalesforceSoapClient::SalesforceSoapClient::constructor() "SalesforceSoapClient constructor" argument)
    |\c "timeout"|transfer timeout to use in milliseconds
    |\c "token"|(required) the Salesforce.com user API token to use for the connection; can be specified using \
        system properties instead (see below)
    |\c "username"|(required) the Salesforce.com username to use for the connection; can be specified using system \
        properties instead (see below)
    |\c "wsdl"|overrides the WSDL to use for the connection

    @par Runtime Connection Options
    |!Option|!Description
    |\c "log"|a closure accepting a single string for logging
    |\c "dbglog"|a closure taking a single string for detailed technical connection logging

    @note that the following options can be specified with system properties by providing a value for each of the
    following keys in the \c "salesforce.com" system property domain:
    - \c "password"
    - \c "token"
    - \c "username"
    .
    In this case, the above authentication options do not have to be present in the connection file itself

    @see @ref SalesforceSoapClient::SalesforceSoapClient::constructor() "SalesforceSoapClient::constructor()" for more
    information on the above options

    @section dsconn Datasource Connections

    Datasources are system-wide named connections to external databases.  Qorus datasources are defined in the Qorus
    system DB schema; from these definitions datasource connections can be acquired in the following ways:
    - \b Python / \b Java / \b %Qore:
      @ref OMQ::UserApi::UserApi::getDatasourceDedicated() "UserApi::getDatasourceDedicated()" gets a dedicated
      @ref Qore::SQL::Datasource "Datasource" object with a transient connection to the DB server (normally
      @ref OMQ::UserApi::UserApi::getDatasourcePool() "UserApi::getDatasourcePool()" should be used instead)
    - \b Python / \b Java / \b %Qore: @ref OMQ::UserApi::UserApi::getDatasourcePool() "UserApi::getDatasourcePool()":
      gets a @ref Qore::SQL::DatasourcePool "DatasourcePool" object for the given datasource; this is the recommended
      way to get a database connection

    Database connections are using special URI with a form
    <i>db://driver:user/pass@@database[(encoding)][%host][:port][{min=#,max=#,coord-mode}]</i>

    Note that <tt>db://</tt> prefix, \em driver, and \em database are always required. \em driver must be a valid
    %Qore database driver name.  \em min and \em max give the minimum and maximum connections for
    @ref Qore::SQL::DatasourcePool "DatasourcePool" objects based on that connection string, respectively.   See
    @ref dsconn_pools for a description of the \em coord_mode option

    The encoding specification describes the character set encoding to be used when communicating with the database server and must be made in the format required by the database driver (i.e. \c "AL32UTF8" for UTF-8 with an Oracle driver).

    For example:
    @verbatim
db://oracle:qorususer/qorususer@qorusdb
    @endverbatim

    <b>Remote Connection Types</b>
    |!Scheme|!Object|!Description
    |\c db|@ref Qore::SQL::Datasource "Datasource" or @ref Qore::SQL::DatasourcePool "DatasourcePool"; or referenced by the common parent class @ref Qore::SQL::AbstractDatasource "AbstractDatasource"|a DB/SQL access object

    @see
    - @ref definingconnections

    @section dsconn_pools Datasource Connection Pools and the qdsp Mode

    When a connection pool object is aqcuired, an object is returned that is an injected client for @ref qdsp "qdsp"
    processes; how this object acquires a connection and executes SQL depends on the @ref qdsp_mode "qdsp mode" option
    for the given datasource.

    To enable @ref qdsp_mode "coordinated mode" for a given datasource, the \c "coord-mode" option can be set in the
    datasource URL as in the following example:

    @verbatim
db://driver:user/password@dbname{coord-mode}
    @endverbatim

    which is equivalent to:

    @verbatim
db://driver:user/password@dbname{coord-mode=true}
    @endverbatim

    @ref qdsp_mode "Coordinated mode" can also be disabled for a given datasource (in case it has been enabled by
    default with the @ref default-datasource-coordinated "default-datasource-coordinated option") by setting the
    \c coord-mode option to \c false as in the following example:

    @verbatim
db://driver:user/password@dbname{coord-mode=false}
    @endverbatim

    @note
    - Any value provided to the \em coord-mode option is parsed with @ref parse_boolean() "parse_boolean()"
    - Setting the \em coord-mode option in the datasource URL overrides any
      @ref default-datasource-coordinated "default-datasource-coordinated option" and therefore can be used to ensure
      that the desired \em coord-mode value is used for the datasource in all cases.
    - The \em coord-mode option is only used by Qorus; it is not passed to the database driver

    @see @ref qdsp_reset

    @section monitoring Connection Monitoring

    @subsection monoverview Monitoring Overview

    Connections are monitored regularly by executing their "ping" methods, which make a small round trip call to the
    remote endpoint.  If there is are at least two consecutive ping errors establishing the connection or receiving
    the response, then the connection is marked as down.

    When a connection is marked as down, an ongoing alert is raised, and any dependent interfaces are also stopped
    (see @ref conndeps).  The associated ongoing alert is raised again when the connection is monitored to be up
    again.

    @note Manually called ping methods will also affect monitored connection status (a successfull ping will mark a
    "down" interface as up and vice versa, if the consecutive error limit is reached).

    @subsection conndeps Connection Dependencies

    Once any workflow, service, or job requests a connection (assuming that any \a register_dependency argument is
    @ref True "True"), the connection is then automatically registered as a dependency of the interface object, so
    that if the connection is monitored to go down, the dependent interface object will be stopped.  When connection
    monitoring determines that the connection is back up, the dependent interfaces are restarted (for workflows and
    services this also depends on their autostart setting).
*/

/** @page sla_tracking SLA Tracking in Qorus

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    SLA and performance tracking can be managed in Qorus with service calls and job execution through configuration (i.e. without requiring any development)
    and arbitrarily with any part of the system by using the @ref sla_api "SLA API".

    SLA events can be tracked once an SLA has been created; SLA events are flushed to the system database asynchronously in
    another thread of execution from the associated action in order to avoid causing a performance penalty in the action itself.

    The following system options affect the SLA event cache:
    - @ref sla-max-events "sla-max-events": the maximum number of SLA events to store before flushing to the database
    - @ref sla-max-sync-secs "sla-max-sync-secs": the maximum number of seconds to hold SLA events before flushing to ORDER_INSTANCE_KEYS

    Qorus will flush SLA events to disk when either the maximum time or the maximum cache size is reached, whichever comes first.

    This means that the @ref sla-max-sync-secs "sla-max-sync-secs" option determines the maximum delay an SLA event can remain
    in the cache.

    The following REST API URI paths can be used to manage and report SLAs:
    - @ref rest_api_v2_slas system SLA information
    - @ref rest_api_v2_slas__sla_ actions on an existing SLA
*/

/** @page sql-cache Qorus SQL Object Cache

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    Qorus implements a cache for @ref sqlutilintro "SqlUtil"-based @ref SqlUtil::AbstractTable "AbstractTable"
    objects for use with DML in Qorus interfacing code.  This is because the acquisition cost of an
    @ref SqlUtil::AbstractTable "AbstractTable" object is relatively high, due to the necessity of reading the
    dataserver's data dictionary for the table and all associated properties (indexes, constraints, etc).

    Objects in the cache are referenced according to their @ref dsconn "datasource"; if a datasource is
    @ref qdsp_reset "reset", then all associated objects in the cache are automatically purged.

    Objects in the SQL object cache may need to be purged manually due to changes in the database; this can
    be done with the appropriate REST API call.

    @see @ref devel-sqlcache for more information
 */

/** @page mappers Qorus Mappers

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section mapper-intro Mapper Introduction

    @see @ref mapper-devel for more information

    Qorus Mappers are high-level integration objects that providing a framework for runtime data transformations in Qorus interfaces.

    Mapper configurations are loaded into the database with @ref oload "oload" and also must be explicitly associated with workflows, services, and jobs to be used in interface code.  This way, the system knows (and can display in the system UI) which mappers are associated with which interfaces.

    When mappers are used at runtime, every mapper configuration generates a class descended from @ref Mapper::Mapper "Mapper", and the basic configuration of Qorus mapper objects is based on the implementation of this base class (it's also possible to get an @ref Qore::AbstractIterator "AbstractIterator" object based on a mapper, but this is also based on the @ref Mapper::Mapper "Mapper" object generated by the mapper).

    Mappers have the following high-level attributes:
    - \c mapperid: a unique ID for the mapper
    - \c name: the name of the mapper
    - \c version: the version of the mapper; multiple versions of a mapper can be present at any one time in the system, and interfaces must specify the mapper version that they use
    - \c patch: a patchlevel attribute that does not affect version compatibility
    - \c desc: a description of the mapper
    - \c author: the author of the mapper
    - \c parse_options: local parse options for the mapper
    - \c type: the @ref mapper-types "type of mapper"
    - \c options: a hash of mapper options, some mappers could require certain options
    - \c fields: a hash of mappings where the keys are output fields and the values describe how the output should be generated
    - \c library objects: a list of objects (functions, classes, and constants) that are imported into the mapper container @ref Qore::Program "Program"

    Mappers are exposed through the REST API at the following URI path: @/api/mappers@.

    @note Mappers are also members of @ref rbacgroups "interface groups" for access control purposes (mappers cannot be enabled or disabled).

    @subsection mapper-types Mapper Types

    @see @ref dep_mapper-devel-modules

    The following mapper types are delivered with Qorus (see @ref mapper-modules-ref for information on adding new mapper types):
    - \c "InboundTableMapper": provides a @ref OMQ::QorusInboundTableMapper object at runtime
    - \c "Mapper": provides a @ref Mapper::Mapper object at runtime

    @subsection mapper-modules-ref Mapper Modules

    New mapper types can be added at runtime by implementing a mapper module and placing it in <tt>$OMQ_DIR/user/modules/</tt> and adding the module's name to the @ref mapper-modules system option.

    Such a module will be loaded both in the client library and in the server to provide for custom mapper support; such modules then will create objects of new mapper types or of existing mapper types with default mappings, etc.

    @see @ref dep_mapper-devel-modules for more information

    @section mapperapi Mapper API

    The main mapper API is defined in the following classes:
    - \b Python / \b Java / \b %Qore: @ref OMQ::MapperApi::MapperApi "MapperApi"

    The following APIs are imported into mapper program logic containers for backwards compatibility as well (%Qore code only):

    |!%Qore Function|!Domain|!Availability|!Description
    |get_global_config_item_value()|@ref mapperapi "Mapper API"|\c M|returns the value of the given global config item
    |get_global_config_item_value_with_default()|@ref mapperapi "Mapper API"|\c M|returns the value of the given global config item or a default value
    |get_user_context_info()|@ref systeminfoapi "System Info"|\c W, \c S, \c J, \c M|returns information about a user context
    |get_system_info()|@ref systeminfoapi "System Info"|\c W, \c S, \c J, \c M|returns information about the system
    |get_value_map()|@ref systemvmapapi "Value Maps"|\c W, \c S, \c J, \c M|retrieves a value mapping from a value map
    |prop_get()|@ref systempropapi "System Props"|\c W, \c S, \c J, \c M|returns the value of the given @ref sysprops "system property key" in the given domain or @ref nothing if the system property does not exist
*/

/** @page value-maps Qorus Value Maps

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section value-map-intro Value Map Introduction

    @see @ref valuemap-devel for information on value map development

    Qorus Value Maps (also known as "Lists of Values") are key-value
    lookup tables to access various data. With appropriate processes in place,
    this data can be maintained by non-technical users, and changes can be
    captured and included when releases are packaged and managed.

    Value maps are unique in the system (their ID and name are unique) and also
    keys within a value map are unique.

    By default, values are cached on demand (during the first access by
    name/key combination).  Automatic caching of all the values in a value map
    is possible changing the Qorus system option
    @ref vmap-size-threshold to any number. It's set to 100 by default.

    Each value map has following characteristics:

    - \c id: internal numeric ID of the value map
    - \c name: an unique string name for the value map
    - \c description: string description of the set
    - \c author: a string identifying the author of the value map
    - \c throws_exception: a flag if the API function throws an exception of the key does not exist in the value map (see @ref value-map-exceptions)
    - \c valuetype: an expected data type of the value (see @ref value-map-datatypes)
    - \c created: timestamp the value map was created
    - \c modified: timestamp the value map was last modified

    Value maps are exposed through the REST API at the following URI path: @/api/valuemaps@.

    @note Value maps are also members of @ref rbacgroups "interface groups" for access control purposes (value maps cannot be enabled or disabled).

    @section value-map-datatypes Value Map Data Types

    Each value map has a pre-defined type of the values stored.  The allowed types are as follows:
    - \c "string": values are stored as strings. Even if the number is provided.
    - \c "int": values are stored as int. Strings or anything else is converted using Qore::int() function
    - \c "float": values are stored as float. Strings or anything else is converted using Qore::float() function
    - \c "date": values are stored as date.
    - \c "raw": values are stored as-is. This option allows complex structures (such as lists or hashes) to be stored as values, however no validation is performed in this case.

    @section value-map-enabled Enabled and Disabled Values

    Key-value mappings in the value map can be hidden by setting the \c enabled flag to @ref False "False";
    if a value mapping is disabled, @ref OMQ::UserApi::UserApi::getValueMap() "UserApi::getValueMap()" either returns
    @ref nothing or it throws an exception when a disabled mapping is referenced (see @ref value-map-exceptions).
 */

/** @page alerts System Alerting

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section alertoverview Overview of Alerting

    Qorus alerts are situations that require attention from operators.  There are two types of alerts:
    - @ref ongoingalerts
    - @ref transientalerts

    The following system options pertain to alerts:
    - @ref alert-fs-full "alert-fs-full": the percentage above which an alert will be raised due to a full filesystem
    - @ref alert-smtp-connection "alert-smtp-connection": the name of the @ref userconn "user connection" for the SMTP server for delivering alert emails
    - @ref alert-smtp-enable "alert-smtp-enable": flag allowing alert emails to be enabled or disabled at runtime
    - @ref alert-smtp-from "alert-smtp-from": source (from) email address for alert emails
    - @ref alert-smtp-interval "alert-smtp-interval": interval in seconds for grouping and delivering alert emails
    - @ref alert-smtp-to "alert-smtp-to": list of email addresses for delivering alert emails
    - @ref dsp-warning-timeout "dsp-warning-timeout": the amount of time in milliseconds for a @ref transientalerts "transient alert" to be raised if a connection cannot be allocated from a system datasource pool
    - @ref transient-alert-max "transient-alert-max": maximum number of @ref transientalerts "transient alerts" to cache

    @see @ref rest_api_latest_system_alerts for information about the REST APIs related to Qorus system alerts

    @section ongoingalerts Ongoing Alerts

    Ongoing alerts represent ongoing problems with the operation of the Qorus server or its interfaces that can be cleared if
    the underlying problem is resolved.

    @section transientalerts Transient Alerts

    Transient alerts are one-time events that represent problems or potential problems with the operation of the Qorus server or its interfaces.
*/

/** @page services Qorus Services

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section serviceoverview Overview

    Services are sets of logic defined in methods that are loaded from the database.  A service consists of a set of
    one or more methods that can be called from the Qorus system itself, from Qorus workflows, from other Qorus
    services, from other applications through the system API exported through @ref YAMLRPC "YAML-RPC", XML-RPC,
    JSON-RPC, SOAP or other protocol handlers, or even from the command-line using the @ref qrest "qrest" or
    @ref ocmd "ocmd" programs.

    There are 2 types of services: system services and user services.  Both kinds of services have their metadata and
    actual method logic stored in the database.

    @ref systemservices "System services" are written by %Qore Technologies, delivered with the system.  User services
    are defined and written by Qorus programmers.

    Because system services provide Qorus system functionality, and because services can be deleted and reloaded from
    the database at any time, this means that these parts of the Qorus system itself can be upgraded without taking
    the system down and restarting it.

    Passive services without running threads that just export methods to be called either internally or externally (or
    both) are like named and versioned API sets.  Services that implement actions in service threads can do anything
    that the available system APIs allows them to do.

    @note System services cannot be @ref service_remote "remote" and also cannot be @ref service_stateless "stateless"

    @section servicemeth Services and Service Methods

    There are three service methods that have a special meaning to the Qorus system as listed in the following table.
    If any of these methods are defined, they will be called by the system itself when the service is loaded or
    unloaded.

    <b>Special Service Methods</b>
    |!Method|!Description
    |@ref serviceinit "init()"|If an \c init() method exists, it is called automatically when the service is loaded. \
        If this method is explicitly called, no action is taken by the system, therefore this method can be called \
        to ensure that the service is loaded.  If this method returns a value, it will be ignored by the system.  \
        Any @ref service_method_lock "lock attribute" defined on this method will be ignored.
    |@ref serviceinit "start()"|If a \c start() method exists, it is launched in the background in a separate thread \
        automatically when the service is loaded, after the init() method is called.  Like the \c init() method, if \
        this method is explicitly called, no action is taken by the system, therefore this method can be called to \
        ensure that the service is loaded and running in the background.  If this method returns a value, it will be \
        ignored by the system.  Any @ref service_method_lock "lock attribute" defined on this method will be ignored.
    |@ref serviceinit "stop()"|If a \c start() method exists, then a \c stop() method must also be defined.  The \
        \c stop() method is only called by the system when the service is deleted.  If an external call to a \
        service's \c stop() method is attempted, it results in an error.  Any
        @ref service_method_lock "lock attribute" defined on this method will be ignored.

    Important service attributes are depicted in the following graphic.

    @image html service-diagram.png Service Diagram

    Services have attributes as listed in the following table (for all attributes, see @ref servicedesc).

    <b>Service Attributes (table: \c SERVICES)</b>
    |!Attribute|!Description
    |\c serviceid|The internal identifier for a service (primary key for the \c SERVICES table)
    |@ref service_name "name"|The service's name
    |@ref service_version "version"|The version identifier for the service.  The type, name and version together \
        uniquely identify a service in the database and are associated with one service ID.
    |@ref service_type "type"|Either \c "SYSTEM" or \c "USER".  System services are delivered with the system by \
        %Qore Technologies, while user services are developed by Qorus programmers.
    |@ref service_description "description"|The description of the service
    |@ref service_autostart "autostart"|If this boolean flag is set to @ref True, then the service will be \
        automatically started when the system is started.
    |@ref service_remote "remote"|If this boolean flag is set to @ref True, then the service will run in a remote \
        @ref qsvc "qsvc" process
    |@ref service_stateless "stateless"|If this boolean flag is set to @ref True, then the service must be started \
        externally (when run under Kubernetes, Qorus will create the \
        <a href="https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/">stateful sets</a> \
        automatically), and multiple instances of the service can run for load sharing and fault tolerance
    |\em RWLock|This is an internal attribute of each service (not stored in the database); it is a read-write lock \
        that belongs to every service and is automatically applied to method calls depending on the method's lock \
        type attribute
    |\em Tags|A list of user-defined tags for the service, stored in the \c SERVICE_TAGS table

    Additionally, the \c SERVICE_STATE_DATA table is used to store persistent data for service data to aid in
    recovering service actions in case of errors.  This table has one row for each service.  Service state can be
    stored using:
    - \b %Python: @ref OMQ::UserApi::Service::ServiceApi::saveStateData() "svcapi.saveStateData()"
    - \b Java: @ref OMQ::UserApi::Service::ServiceApi::saveStateData() "ServiceApi.saveStateData"
    - \b %Qore: @ref OMQ::UserApi::Service::ServiceApi::saveStateData() "ServiceApi::saveStateData()"
    and retrieved with:
    - \b %Python: @ref OMQ::UserApi::Service::ServiceApi::getStateData() "svcapi.getStateData()"
    - \b Java: @ref OMQ::UserApi::Service::ServiceApi::getStateData() "ServiceApi.getStateData"
    - \b %Qore: @ref OMQ::UserApi::Service::ServiceApi::getStateData() "ServiceApi::getStateData()"

    Services then have one or more methods, which provide the logic for the service.

    Service methods can be depicted as in the following graphic.

    @image html service-method.png Service Method

    Service methods have the attributes listed in the following table.  Note that service methods do not have
    versions; their name must be unique within the scope of the parent service object.  For all method attributes,
    see @ref service_methods.

    <b>Service Method Attributes (table: SERVICE_METHODS)</b>
    |!Attribute|!Description
    |\c service_methodid|The unique ID of the method (primary key for the table)
    |\c serviceid|The service the method belongs to
    |@ref service_method_name "name"|The method's name, which must be unique within the service.
    |@ref service_method_description "description"|An optional description for the service
    |@ref service_method_lock "locktype"|This can be @ref OMQ::SLRead, @ref OMQ::SLWrite, or @ref OMQ::SLNone.  \
        Depending on this value the system will wrap calls to the method with the appropriate call to the parent \
        service object's read-write lock object.
    |@ref service_method_internal "internal"|A Boolean flag that restricts calling the method to internal calls \
        only.  Any method with this flag set will not be exported through the @ref httpserver "HTTP server's" web \
        service protocol handlers.
    |@ref service_method_write "writeflag"|This flag is ignored in the Community Edition
    |@ref service_method_source "code"|This is the code that is loaded when the method is loaded along with the \
        parent service object.  This logic must contain a function with the same name as the service method.

    @section serviceload Loading and Unloading Services

    When services are loaded, all methods belonging to the service are loaded at the same time.  Additionally, the
    Qorus system will automatically load the latest version of the service from the database.

    As described above, if the service has @ref serviceinit "init() or start() methods" defined, they will be
    automatically called by the system when the service is loaded, before any other methods can be called.  This
    allows the service to perform initialization before other methods are called and therefore ensure consistent
    results.  Additionally, when a service is loaded, the @ref systemevents "system event"
    @ref SERVICE_START "SERVICE_START" is raised.

    When a service is deleted, if it has @ref serviceinit "start() and stop()" methods, or if any service threads
    were started manually using service APIs, the \c stop() method is called and the system waits for all service
    threads to terminate.  After all service threads terminate, the service is unloaded from the system immediately.
    When a service is unloaded, the @ref systemevents "system event" @ref SERVICE_STOP "SERVICE_STOP is raised.

    If any system errors occur related to loading or running a service (such as a service's thread terminating
    prematurely, for example), the @ref systemevents "system event" @ref SERVICE_ERROR "SERVICE_ERROR" is raised.

    @section servicecalls Service Calls

    If a service call is made and the service referenced is not already loaded, the latest version of the service will
    be loaded from the Oracle database and initialized and started (if \c init() and/or \c start() methods exist,
    respectively).

    The call will block until the service is loaded (and initialized and/or started if
    @ref serviceinit "init() and/or start() methods" exist).

    In general, any calls to services while they are in transition states (being initialized/started or deleted) will
    block until the service exits the transition state.  In the case of a service call to a service being deleted, the
    call will block until the service has been deleted, after which the latest version of the service will be reloaded
    (and initialized, etc if necessary) and then the call will be made.

    @note The fact that service calls are guaranteed to be completed even when services are being initialized or
    deleted (assuming that the service is valid can be loaded, initialized, and/or started) means that live service
    upgrades will not cause any lack of availability of the service being upgraded.  Calls during these transition
    states may take longer to fulfill, but will still be completed after the service exits the transition state (i.e.
    the initialization or deletion has completed).
*/

/** @page workflowmodel Qorus Workflows

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section workflowoverview Workflow Overview

    Managing workflows represents the primary functionality of the Qorus system.  All information pertaining to
    workflows is stored in the Qorus database, from workflow metadata, to workflow logic, to the actual workflow data
    and states.

    @section workflows Workflow Metadata

    Qorus workflows are made up of several objects.  Workflow metadata is stored in the \c WORKFLOWS table, and the
    parent table for workflow order data instance information is the \c WORKFLOW_INSTANCE table.

    Important workflow attributes are depicted in the following graphic.

    @image html workflow-diagram.png Workflow Metadata Diagram

    Workflow attributes are described in more detailed in the following table (for all workflow attributes, see
    @ref wfdeffile).

    <b>Workflow Attributes (table: \c WORKFLOWS)</b>
    |!Attribute|!Mand?|!Description
    |\c workflowid|Y|The unique ID of the workflow; no two workflows can have the same ID (primary key for the table)
    |@ref wf_name "name"|Y|The workflow's name
    |@ref wf_version "version"|Y|The workflow's version
    |\c patch|N|A string giving the patchlevel of the workflow's configuration.  Note that the patch string is not \
        used to differentiate different versions of this object.  Objects have unique names and versions, but the \
        patch string is used to track updated configurations of an object where updating the version number is not \
        desirable.
    |@ref wf_description "description"|Y|The description of the workflow
    |@ref wf_autostart "autostart"|Y|The number of workflow execution instances to be started automatically
    |@ref wf_max_instances "max_instances"|Y|The maximum number of workflow execution instances that can be started \
        concurrently (must be >= \c autostart)
    |@ref attach "attach logic"|N|This logic will be executed each time Qorus starts to work on (i.e. "attaches to") \
        a workflow order data instance
    |@ref detach "detach logic"|N|This logic that will be executed each time Qorus stops working on (i.e. \
        "detaches from" or "releases") a workflow order data instance
    |@ref onetimeinit "onetimeinit logic"|N|This code will be executed once each time a workflow execution instance
        starts
    |\c deprecated|N|This flag indicates whether or not the workflow will be displayed in the web UI and can be started
    |@ref stepdefs "Steps"|Y|A list of steps and step dependencies; found in the table: \c WORKFLOW_STEPS
    |\em Segments|Y|A list of segments and segment dependencies, found in tables: \c SEGMENT_DEPENDENCIES, \
        \c SEGMENT_STEPS
    |\em Tags|N|A list of user-defined tags for the workflow, stored in the \c WORKFLOW_TAGS table
    |@ref library_objects "Library Objects"|N|A set of functions, classes, and constants that will be loaded into \
        the workflow's program space; defined in table: \c WORKFLOW_LIB
    |@ref wf_keylist "Keys"|N|A set of keys for searching workflow order data instances.  Only key names in this \
        list can be used to tag workflow order data instances for searching.  Found in table: \c WORKFLOW_KEYS
    |\em Options|N|A set of valid options and option values for a workflow; defined in table: \c WORKFLOW_OPTIONS

    @see @ref workflow_instance_desc "Workflow Instance Data Description" for information about workflow order data
    instances, which are instantiations of the metadata described above

    @section steps Step Metadata
    Each workflow is made up of one or more steps and the step dependencies.

    Step metadata can be graphically depicted as follows.

    @image html step.png Step Metadata Diagram

    Steps have attributes as defined in the following table (see @ref stepdefs for all attributes).

    <b>Step Attributes (Table: \c STEPS)</b>
    |!Attribute|!Mand?|!Description
    |\c stepid|Y|The unique ID of the step; no two steps can have the same ID (also this is the primary key for the \
        table)
    |\c steptype|Y|see @ref StepTypes for valid step types
    |@ref step_name "name"|Y|The step's name
    |@ref step_version "version"|Y|The step's version; the name and version uniquely identify the step and \
        correspond to one step ID
    |@ref step_patch "patch"|N|A string giving the patchlevel of the step's configuration.  Note that the patch \
        string is not used to differentiate different versions of this object.  Objects have unique names and \
        versions, but the patch string is used to track updated configurations of an object where updating the \
        version number is not desirable.
    |@ref arraysteps "arraytype"|Y|Defines the step as an array step or not; see @ref StepArrayTypes for valid values
    |@ref step_source "source"|N|The source code to the step
    |@ref step_queue "queueid"|Y/N*|* Mandatory for steps of type @ref OMQ::ExecAsync (asynchronous steps); must not \
        be present for other step types; foreign key to \c QUEUES
    |@ref step_event_type "workflow_event_typeid"|Y/N*|* Mandatory for steps of type @ref OMQ::ExecEvent (workflow \
        synchronization event steps), must not be present for any other step type; foreign key to \
        \c WORKFLOW_EVENT_TYPES
    |\em Tags|N|A list of user-defined tags for the step, stored in the \c STEP_TAGS table

    @see @ref step_instance_desc "Step Instance Data Description" for information about step instances, which are
    instantiations of the metadata described above

    @section segments Segment Metadata

    Segments are a groups of steps separated by an asynchronous (type @ref OMQ::ExecAsync), a workflow synchronization
    event step (type @ref OMQ::ExecEvent), or a subworkflow step (type @ref OMQ::ExecSubWorkflow).  If a workflow has
    no asynchronous steps, no synchronization event steps, and no subworkflow steps, then the workflow will have only
    one segment (with segment ID 0).

    Segments are executed semi-independently of one another; each segment has it's own resources and threads dedicated
    to processing only that segment.  In this way, the Qorus Integration Engine&reg; can pipeline data processing in
    the most efficient way possible while providing a very easy-to-use system construct to the programmer.

    Segments have attributes as defined in the following table.

    <b>Segment Attributes</b>
    |!Attribute|!Mand?|!Description
    |\c workflowid|Y|The ID of the workflow the segment belongs to; foreign key to \c WORKFLOWS
    |\c segmentid|Y|The ID of the segment, unique within the workflow only.  Segment IDs in each workflow start with 0.
    |\em Steps|Y|List of steps in the segment with their dependencies, defined in \c SEGMENT_STEPS

    @see @ref segment_instance_desc "Segment Instance Data Description" for information about segment instances, which
    are instantiations of the metadata described above

    @section wfmetadatacache Workflow Metadata Cache

    Workflow metadata (workflow configuration information) is loaded on demand into Qorus' workflow cache.  If a
    workflow is updated, or dependent functions, etc are updated in the database, then, in order for the changes to
    take effect, the cached version of the workflow must be deleted so that the new version will be automatically
    loaded into Qorus' workflow cache.

    The cached version of a workflow can be deleted with system REST APIs like
    @ref rest_api_PUT_latest_workflows__id_or_name__reset or the omq.system.reset-workflow() RPC API method.

    When a cached workflow configuration is deleted, the @ref systemevents "system event"
    @ref WORKFLOW_CACHE_RESET "WORKFLOW_CACHE_RESET" is raised.

    @note Instances of workflows running in \c NORMAL (@ref OMQ::WM_Normal) or \c RECOVERY (@ref OMQ::WM_Recovery)
    mode will be automatically updated with the newer configuration when the cached version is deleted (for example,
    by calling @ref rest_api_PUT_latest_workflows_resetAll or omq.system.reset-all-workflows()).  When this happens,
    the workflow execution instance does a partial stop, refreshes the configuration, and then restarts.  It is not
    necessary to stop and start a workflow execution instance manually when workflow configurations are updated.

    @section orderdata Workflow Order Data Instances

    @subsection workflow_instance_desc Workflow Primary Order Instance Data

    Workflow order data instances represent order data to be processed by workflows; they are instantiations of
    @ref workflows, and they have attributes as defined in the following table.

    <b>Workflow Order Data Instance Attributes (tables: \c WORKFLOW_INSTANCE and \c ORDER_INSTANCE)</b>
    |!Attribute|!Description
    |\c workflow_instance.workflow_instanceid|The unique ID of the workflow order data instance; no two workflow \
        order data instances can have the same ID (this is the primary key for both these tables)
    |\c workflow_instance.workflowid|Identifies the workflow the order data belongs to or is processed by.
    |\c workflow_instance.workflowstatus|Indicates the status of the workflow order data instance.  See \
        @ref StatusDescriptions for more information
    |\c workflow_instance.custom_status|This is an optional user status code that can provide more information about \
        the status to operations personnel
    |\c workflow_instance.status_sessionid|When the workflow order data instance is being processed, this value will \
        be set to the session ID of the @ref appsessionmodel "Qorus application instance session" processing it.
    |\c workflow_instance.scheduled|The earliest date and time the order can start processing; this date/time value is \
        only used when the order's status is @ref OMQ::StatReady
    |\c workflow_instance.priority|The priority for the order; lower numbers equal higher priorities; priority \
        numbers may be from 0 (the highest priority) to 999 (the lowest priority)
    |\c workflow_instance.started|The time and date the workflow order data instance was initially processed.
    |\c workflow_instance.completed|The time and date processing was completed for the workflow order data instance.
    |\c workflow_instance.parent_workflow_instanceid|For subworkflows, this points to the parent workflow order data \
        instance ID.
    |\c workflow_instance.synchronous|For order data being processed synchronously, this flag will be set to 1 \
        (= true).
    |\c workflow_instance.business_error|Flag indicating if the workflow order data instance has an \
        @ref OMQ::StatError status due to a business error (if not set, the error status is due to a technical \
        error).  The interpretation of this flag depends on the order being processed, however normally the business \
        error flag is set when the input data are inconsistent with the order to be processed (for example, the \
        input data fail business validation rules)
    |\c order_instance.external_order_instanceid|An optional external identifier for the workflow order data instance
    |\c order_instance.staticdata|The initial order data – this cannot be changed by workflow execution instances that \
        process it
    |\c order_instance.dynamicdata|This is persistent data associated with the workflow order data instance.  Any \
        data stored here will remain until deleted from the DB.
    |<i>User Keys</i>|Optional key-value pairs attached to a workflow order data instanstaticce to be used in \
        searching for the data

    @subsection sensitive_data Sensitive Data

    Qorus has been designed to handle workflow order sensitive data with special APIs, encrypted storage, and
    carefully audited processing to avoid logging such data by the system itself and to ensure the security of such
    data from unauthorized access or inadvertent disclosure.

    Workflow sensitive data can only be submitted with a new workflow order over a secure network interface (i.e.
    using an HTTPS listener); it's not possible to submit sensitive data over an unencrypted listener using system
    APIs.

    Workflow order sensitive data is stored separately for each data subject against the workflow order using two
    identifiers (in addition to the \c workflow_instanceid designating the workflow order); within the order, each
    data subject's sensitive data is identified with the following keys:
    - \c skey: the sensitive data key type (not treated as sensitive itself; ex: \c "social_insurance_nr")
    - \c svalue: the sensitive data key value, which is also treated as sensitive itself

    The value of \c skey must be decided in advance when designing an interface that will process sensitive data.
    This value is meant to describe the type of value stored in \c svalue.  For example, if the sensitive data
    identifier is a social insurance number, then \c skey might be \c "social_insurance_nr" and \c svalue will be the
    social insurance number for the data subject (the natural person whose data are being processed).

    The following image gives an overview of how sensitive data is stored against a workflow order:

    @image html "workflow_order.png" "Qorus Integration Engine&reg; Workflow Order Sensitive Data"

    In another example, an interface might identify data subjects with their tax number, so \c skey might be
    \c "tax_id", and \c svalue will be the tax number of the data subject.

    The following image provides an overview of a concrete example of sensitive data stored against a workflow order
    storing sensitive data for at least two data subjects with tax_ids \c "984.302192.AF" and \c "739.323.714.BR":

    @image html "workflow_order_example.png" "Qorus Integration Engine&reg; Workflow Order Sensitive Data Example"

    In the above example, the sensitive key values (\c "984.302192.AF" and \c "739.323.714.BR") are encrypted when
    stored, additionally the sensitive data and metadata hashes for each data subject are also stored encrypted in the
    system database.

    For each set of personal data stored in a workflow order, the two values \c skey and \c svalue identify sensitive
    data for a data subject and must be used for external queries or manipulation of sensitive data.

    This data can be queried, updated, and deleted separately for each workflow order or for each data subject.

    If another identifier for the customer is used, such as an internal account number (which might be used to ensure
    a common identifier for all sensitive data stored by an organization), then the \c skey value might be
    \c "account_nr", and \c svalue will be the organization's account number.  In any case, \c svalue values will be
    treated as sensitive themselves, therefore they will not be logged in decoded form and also can only be sent or
    received over encrypted network links (at least when the system is aware that sensitive data is being sent or
    received as a part of system APIs designed to support this implementation).

    Sensitive data APIs for workflows also support the possibility of creating internal aliases for sensitive data
    key/value pairs to allow sensitive data to be matched to cleartext workflow order data (such as @ref staticdata
    or @ref dynamicdata); sensitive data aliases are not considered sensitive themselves and therefore should not be
    created using sensitive identifiers that can be used to determine the identity of the data subject.

    @subsubsection sensitive_data_rest_apis Sensitive Data REST APIs

    The following REST APIs support sensitive data processing:
    - @ref rest_api_DELETE_latest_orders_purgeSensitiveData
      This API can be used to delete sensitive data for a particular data subject across all workflows in the system,
      or for a particular workflow order, or based on the age of the data in the system (among other possible criteria)
    - @ref rest_api_GET_latest_orders_searchSensitiveData
      This API can be used to search for sensitive data with flexible search criteria
    - @ref rest_api_GET_latest_orders__id_
      This API has been updated to retrieve sensitive data
    - @ref rest_api_PUT_latest_orders__id__sensitiveData
      This API can be used to create or update sentive data
    - @ref rest_api_POST_latest_workflows__id_or_name__createOrder
      This API has been extended to allow sensitive data to be created when a new workflow order is created
    - @ref rest_api_POST_latest_workflows__id_or_name__execSynchronous
      This API has been extended to allow sensitive data to be created when a new workflow order is created

    @note
    - sensitive data can only be created, retrieved, updated, and deleted over an encrypted (i.e. HTTPS) listener.
    - external sensitive data APIs work across the system schema and any archiving schema transparently

    @warning use of the following REST APIs can log raw data and therefore can result in sensitive data being logged
    in the HTTP log file:
    - @ref rest_api_PUT_system_listeners__id_or_name__logVerboseAll
    - @ref rest_api_PUT_system_listeners__id_or_name__setLogOptions
    .
    Use those REST APIs with care.

    @subsubsection sensitive_data_options Sensitive Data Options

    The following system options support sensitive data processing:
    - @ref sensitive-data-key : indicates the encryption key for sensitive data (created when Qorus is installed /
      upgraded)
    - @ref sensitive-value-key : indicates the encryption key for sensitive key values (created when Qorus is
      installed / upgraded)
    - @ref purge-sensitive-data-complete : if @ref True "True" (the default), then sensitive data will be deleted
      automatically when a workflow order goes to @ref OMQ::StatComplete "COMPLETE"
    - @ref purge-sensitive-data-canceled : if @ref True "True" (the default), then sensitive data will be deleted
      automatically when a workflow order goes to @ref OMQ::StatCanceled "CANCELED"

    If either of the sensitive data purge options is @ref False "False", then sensitive data should be purged
    periodically from the system and archiving schemas using the \c qorus-sensitive-data job.

    @note Once workflow order sensitive data is made available in raw form for internal processing in Qorus,
    programmers must ensure that this data is not processed over insecure network connections or logged in insecure
    log files.  For this reason Qore Technologies recommends that any interfaces handling sensitive data be subjected
    to security audits in the design and test phases at least.

    @see
    - @ref order_sensitive_data in the Developer's Guide
    - @ref ops_sensitive_data in the Operations Manual

    @subsection workflow_order_notes Workflow Order Notes

    Notes can be added to a workflow order through internal and external APIs.  These notes are stored in the
    \c ORDER_INSTANCE_NOTES table.

    Notes are meant to be records of operational information about the processing or troubleshooting of an order.
    Notes can also be created in the web UI and are displayed there with the order instance data.

    The following external APIs are related to notes:
    - REST: @ref rest_api_GET_latest_orders__id__notes : retrieves notes saved against the workflow order
    - REST: @ref rest_api_POST_latest_orders__id__notes : adds a note to a workflow order
    - RPC: omq.system.order-notes(): retrieves notes saved against the workflow order
    - RPC: omq.system.set-order-note(): adds a note to a workflow order

    The following internal APIs are related to notes:
    - \b %Python: @ref OMQ::UserApi::Workflow::WorkflowApi::addOrderNote() "wfapi.addOrderNote()"
    - \b Java: @ref OMQ::UserApi::Workflow::WorkflowApi::addOrderNote() "WorkflowApi.addOrderNote()"
    - \b %Qore: @ref OMQ::UserApi::Workflow::WorkflowApi::addOrderNote() "WorkflowApi::addOrderNote()"
    - \b %Python: @ref OMQ::UserApi::Workflow::WorkflowApi::getOrderNotes() "wfapi.getOrderNotes()"
    - \b Java: @ref OMQ::UserApi::Workflow::WorkflowApi::getOrderNotes() "WorkflowApi.getOrderNotes()"
    - \b %Qore: @ref OMQ::UserApi::Workflow::WorkflowApi::getOrderNotes() "WorkflowApi::getOrderNotes()"

    @subsection segment_instance_desc Workflow Order Segment Instances

    As an order is being processed, it will have one or more segment rows created for it.  This information is stored
    in the \c SEGMENT_INSTANCE table, which is an instantiation of @ref segments.

    <b>Segment Instance Attributes (table: \c SEGMENT_INSTANCE)</b>
    |!Attribute|!Description
    |\c workflow_instanceid|The workflow order data instance that the segment instance belongs to
    |\c segmentid|The metadata ID of the segment, unique in the workflow order data instance; the first segment has \
        segmentid 0
    |\c segmentstatus|Segments can have any of the statuses in @ref StatusDescriptions except \
        @ref OMQ::StatIncomplete, @ref OMQ::StatCanceled, and @ref OMQ::StatBlocked
    |\c custom_status|Segments can have an optional user status code that can provide more information about the \
        status to operations personnel
    |\c retry_trigger|When a segment has status @ref OMQ::StatRetry or @ref OMQ::StatAsyncWaiting, it can have a \
        specific retry time set so that the retry occurs at this certain time, overriding system options \
        @ref recover_delay or @ref async_delay

    @subsection retry_trigger Workflow Order Data Retry Trigger

    Note that the \c retry_trigger value is set for a segment instance when a step requests a specific retry time; a
    specific retry time can be set by a step any time the step gets an @ref OMQ::StatRetry or
    @ref OMQ::StatAsyncWaiting status.  In this case, the earliest retry time will take effect for the segment
    instance.

    @subsection step_instance_desc Workflow Order Step Instances

    Each step that is executed for an order has a row in the \c STEP_INSTANCE table associated with it, which is an
    instantiation of @ref steps.

    <b>Step Instance Attributes (table: \c STEP_INSTANCE)</b>
    |!Attribute|!Description
    |\c workflow_instanceid|The workflow order data instance that the step instance belongs to (see \
        @ref workflow_instance_desc)
    |\c stepid|The metadata step ID for the step (see @ref steps)
    |\c ind|The array step index; the first element is always 0.  Non-array steps will only have one \
        \c STEP_INSTANCE entry for their stepid and this attribute will always set to 0
    |\c stepstatus|Steps can have any of the statuses in @ref StatusDescriptions except @ref OMQ::StatReady, \
        @ref OMQ::StatIncomplete, @ref OMQ::StatCanceled, and @ref OMQ::StatBlocked
    |\c custom_status|Steps can have an optional user status code that can provide more information about the status \
        to operations personnel
    |\c skip|This flag is set on steps that were skipped

    Additional tables of interest are:
    - \c QUEUE_DATA: where asynchronous messages are stored to be delivered to @ref asyncbackendcode "back-end code"
      for @ref asyncsteps "asynchronous steps"
    - \c STEP_INSTANCE_EVENTS: where the event type and event key information is stored for steps pending on a
      workflow synchronization event
    - \c SUBWORKFLOW_INSTANCE: where the information is stored linking a step in a parent workflow to a child or sub
      workflow
    - \c WORKFLOW_EVENTS: where workflow events are stored, holding the key value and posted status

    @section workflowexecution Workflow Execution

    This section describes workflow execution instance processing.

    @subsection workflowstartup Startup and Execution

    The workflow startup procedures (SQL select statements) are split into batches due the performance reasons.
    It means that all steps described below are performend 1..N times depending on amount of data in the system
    database schema.

    Size of these batches can be set by options:
    - @ref sql-default-blocksize
    - @ref sql-init-blocksize

    <hr>
    <b>Step 1: Open Log Files</b>

    When the first execution instance of a workflow starts, the workflow's shared log files are opened (and created if
    necessary) in append mode.  Note that all workflow execution instances of the same type will normally share the
    same log file (depending on the file name mask).  See @ref logging for more information about logging.

    <hr>
    <b>Step 2: Execute One-Time Initialization</b>

    When a workflow execution instance is started, if any one-time initialization function has been defined, then this
    function will be executed.  If any errors occur when running this function, then the workflow execution instance
    will fail to start.

    <hr>
    <b>Step 3: Start Segment Threads</b>

    Segments are groups of steps in a workflow separated by asynchronous or subworkflow steps.  Two threads are
    started for each segment, one in @ref OMQ::WM_Normal mode, and one in @ref OMQ::WM_Recovery mode.  Each segment
    thread is capable of processing a different workflow order data instance; in this sense segments run independently
    within the workflow execution instance.
    <hr>

    @ref OMQ::WM_Normal segments process workflow order data instances that are running without errors.  Initial
    segments have segment ID 0 within a workflow and are always the first segments to be run.

    When a workflow is started, the @ref systemevents "system event" @ref WORKFLOW_START "WORKFLOW_START" is raised.

    Note that in addition to the logic documented above, if the workflow execution instance is the first one of its
    workflow type to start executing, then background threads begin reading in workflow event data from the database
    as well.

    @subsection initialsegment Initial Segment Execution

    In @ref OMQ::WM_Normal mode the initial segment waits for new workflow order data instances to be submitted
    through the system API.

    When this data is found, the workflow order data instance row is marked @ref OMQ::StatInProgress and the segment
    instance row for segment ID 0 is created.

    @subsection normalsegmentexec Normal (Non-Recovery) Asynchronous Segment Execution

    Asynchronous segments are segments that are separated from the previous segment by an
    @ref asyncsteps "asynchronous step".

    Non-recovery (@ref OMQ::WM_Normal) asynchronous segment threads wait for data to become available for the back end
    of the asynchronous step that separates the segment from its predecessor.  The segment thread will be notified
    when a row in the \c QUEUE_DATA table with the asynchronous step's ID is updated with status
    @ref OMQ::QS_Received.  At this point, the data will be extracted from the row, the row is deleted, and the
    asynchronous back end is executed, with the queue data passed as an argument to the
    @ref asyncbackendcode "back-end code".

    If the @ref asyncbackendcode "back-end code" completes without an error, then the previous segment status is set
    to @ref OMQ::StatComplete and the new segment is started (a row is inserted in the \c SEGMENT_INSTANCE table with
    status @ref OMQ::StatInProgress).

    Otherwise, if the @ref asyncbackendcode "back-end code" throws an error, the new segment will not be started (and
    no \c SEGMENT_INSTANCE row will be created for it), and the asynchronous step's and front-end segment status will
    be set to reflect the error's status (either @ref OMQ::StatError or @ref OMQ::StatRetry).

    @note If the step is an asynchronous array step, the dependent back-end segment will only be started once all
    elements of the array step have completed.

    @subsection subworkflowsegments Normal (Non-Recovery) Subworkflow Segments

    Subworkflow segments are separated from the previous segment by a @ref subworkflowsteps "subworkflow step".

    Non-recovery (@ref OMQ::WM_Normal) subworkflow segments wait for a subworkflow order data instance (a normal
    workflow order data instance linked to a subworkflow step through the \c SUBWORKFLOW_INSTANCE table) linked to the
    subworkflow step to reach a @ref OMQ::StatComplete status.  When this happens, the new segment is started
    immediately.  The parent step's status is also updated if a subworkflow bound to the step receives an
    @ref OMQ::StatError status.  @ref OMQ::StatError statuses are propagated up through all parent workflow order data
    instances in case the workflow order data instance is a subworkflow itself.

    @note If the subworkflow step is also an @ref arraysteps "array step", the dependent back-end segment will only be
    started once all workflow order data instances bound to all elements of the array step have completed.

    @subsection eventsegments Normal (Non-Recovery) Workflow Synchronization Event Segments

    Workflow synchronization event segments are separated from the previous segment by a
    @ref eventsteps "workflow synchronization event step".

    Non-recovery (@ref OMQ::WM_Normal) workflow synchronization event segments wait for the dependent workflow
    event(s) (the segment can depend on more than one event if it is also an array step) to post and therefore the
    associated steps will receive a @ref OMQ::StatComplete status.  When this happens, the new segment is started
    immediately.

    @note If the workflow synchronization event step is also an array step, the dependent back-end segment will only
    be started once all events for all elements of the array step have posted and the steps receive a
    @ref OMQ::StatComplete status.

    @subsection segmentrecovery Segment Recovery Processing

    Recovery (@ref OMQ::WM_Recovery) segments process segments with a @ref OMQ::StatRetry or
    @ref OMQ::StatAsyncWaiting status.

    Recovery segments wait for a \c SEGMENT_INSTANCE row to become available meeting at least one of the following
    criteria:
    - segment status is @ref OMQ::StatRetry and the last modified timestamp shows that it has not been modified within
      the time period defined by the system option @ref recover_delay (can be overridden as described below) or it's
      @ref retry_trigger time (if any has been set) has arrived.
    - segment status is @ref OMQ::StatAsyncWaiting and the last modified timestamp shows that it has not been modified
      within the time period defined by the system option @ref async_delay (can be overridden as described below) or
      it's @ref retry_trigger time (if any has been set) has arrived.

    Please note that system options for retry processing can be overridden at several levels listed here in order of
    priority (listed first equals highest priority):
    - by setting a @ref retry_trigger for the segment within the workflow logic itself
    - by setting workflow parameters set on the segment level
    - by setting workflow parameters set on the workflow execution instance level
    - by setting workflow parameters set on the workflow level
    - by setting global system options (@ref recover_delay and @ref async_delay).

    When at least one of these criteria is true for a segment, the segment status is set to @ref OMQ::StatInProgress
    "IN-PROGRESS", and steps without a status of @ref OMQ::StatComplete are executed in their dependency order.

    Steps that have already been executed at least once are subject to special processing.  Before the step is
    executed, if @ref validationcode "validation code" exists, the @ref validationcode "validation code" is executed.

    If the @ref validationcode "validation code" raises an error, the step's status is set to the error's status.

    If the @ref validationcode "validation code" returns a status code, the status code is taken for the step's status
    (for example, @ref OMQ::StatComplete "COMPLETE" will set the step immediately to @ref OMQ::StatComplete "COMPLETE"
    without executing the @ref primarystepcode "primary step logic", @ref OMQ::StatRetry "RETRY" will run the step's
    primary logic again, etc).

    @subsection arraystep_execution Array Step Execution

    @ref arraysteps "Array steps" are executed like normal steps with the following exceptions: before an array step
    is executed, the @ref arraycode "array code" is executed.  The @ref arraycode "array code" must return a list (an
    array), which will define how many times the @ref primarystepcode "primary step logic" is executed.

    @note It is imperative to the correct execution of the system that the @ref arraycode "array code" always return
    the same list with elements in the same order.  If necessary, the array can be stored in
    @ref dynamicdata "dynamic data" (if, for example, the list cannot be directly derived from
    @ref staticdata "static order data").

    If the @ref arraycode "array code" returns \c NOTHING or a list with no elements, a single \c STEP_INSTANCE row
    will be created and the step will be marked as @ref OMQ::StatComplete and processing will continue normally.

    The array step will continue executing even if some elements return @ref OMQ::StatError "ERROR" or
    @ref OMQ::StatRetry "RETRY" statuses until all elements of the array have been iterated.

    For array steps that are subworkflow or asynchronous steps, the segment linked to the back end (for asynchronous
    steps) or the subworkflow completion will only be started once all elements of the array step are
    @ref OMQ::StatComplete.

    @subsection steperrorhandling Error Handling

    When a step raises an error, the handling depends on how the error was defined by the workflow's error function
    (if any).

    If the error has a severity less than @ref OMQ::ES_Major, then the error is treated as a warning.  See below for
    valid error statuses.  Otherwise, the status of the error is taken as the status of the step (must be either
    @ref OMQ::StatError "ERROR", the default, or @ref OMQ::StatRetry "RETRY").

    If an error was not defined by the workflow's error function, then the severity is by default
    @ref OMQ::ES_Major "MAJOR" and the status @ref OMQ::StatError "ERROR".

<b>Error Severity Levels</b>
|!Level|!Description
|@ref OMQ::ES_Fatal|Indicates that the workflow execution instance should shutdown.
|@ref OMQ::ES_Major|Indicates that the workflow order data instance will be set to the error status of the error.
|@ref OMQ::ES_Minor|Indicates that the error will be logged but no other action will take place.

    When a workflow execution instance raises an error, the @ref systemevents "system event"
    @ref WORKFLOW_DATA_ERROR "WORKFLOW_DATA_ERROR" is raised.

    @subsection execinstanceshutdown Workflow Execution Instance Shutdown

    When a workflow execution instance shuts down, all running segments must terminate first.  In order for a running
    segment to terminate, it must complete processing of any steps that may be in progress.  Therefore a long-running
    step can delay the workflow execution instance's shutdown.

    After all running segments have terminated, the log file descriptor is closed, and the internal workflow execution
    instance object is deleted.

    When a workflow is stopped, the @ref systemevents "system event" @ref WORKFLOW_STOP "WORKFLOW_STOP" is raised.

    @section workflowdatacache Workflow Order Data Instance Cache

    Workflow order data instances are cached (remain in main system memory) for the number of seconds defined by the
    value of the @ref detach-delay system option, if processing is halted with any status other that
    @ref OMQ::StatComplete "COMPLETE", @ref OMQ::StatError "ERROR", @ref OMQ::StatCanceled "CAMCELED", or
    @ref OMQ::StatBlocked "BLOCKED" (and the cache is not full as determined by the @ref cache-max system option).

    This is designed to reduce database overhead for recoveries, asynchronous, workflow synchronization event, and
    subworkflow event processing.  Without this option, the workflow order data instance would be purged immediately,
    and then when an asynchronous step's back end completes, or a subworkflow completes, the system would always have
    to read back in and parse the workflow's data form the database, incurring additional I/O that can be spared if
    the data is cached.

    As mentioned above, the two system options that control Qorus' use of the workflow data cache are as follows:
    - @ref detach-delay
    - @ref cache-max

    @see @ref systemoptions of this manual for detailed information on all system options.

    When workflow metadata is reset by a call to the system API
    @ref rest_api_PUT_latest_workflows__id_or_name__reset (or omq.system.reset-workflow()) or
    @ref rest_api_PUT_latest_workflows_resetAll (or omq.system.reset-all-workflows()), the
    @ref systemevents "system event" @ref WORKFLOW_CACHE_RESET "WORKFLOW_CACHE_RESET" is raised.
*/

/** @page jobs Qorus Jobs

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section joboverview Job Overview

    Jobs are simple tasks that have a schedule, similar to a cron job.  Each time a job executes, a record is created
    in the database storing its status.  The system supports a @ref jobmethods "set of system APIs" for controlling
    jobs as well as providing job configuration and status information.

    Jobs are also members of @ref rbacgroups "interface groups"; if a job is a member of a disabled group, then then
    job will not run when scheduled, even if it is active.

    When jobs are scheduled and executed, log file entries are created; see @ref logging for more information about
    log file locations and file formats.

    @section jobmetadata Job Configuration

    Jobs have the following attributes:

    <b>Job Attributes (table: \c JOBS)</b>
    |!Name|!Description
    |\c name|The name of the job
    |\c version|Version string for the job object; this version is informative; only one version of a job is stored \
        in the database at a time
    |\c description|Description of the job object
    |\c sessionid|If the job is currently running on a Qorus instance, then this attribute will have a value, \
        otherwise it will not be set
    |\c active|A boolean value giving the active status of the job; inactive jobs will not be scheduled and run
    |\c run_skipped|A boolean value telling the system if the job should be run immediately if the last scheduled \
        run was missed due to system downtime
    |\c code|The code for the job; the job's Program object will be created out of this code and any library objects \
        associated with the job; the resultant program will have its \c run() function executed when the job is \
        executed
    |\c last_executed|The last execution date/time of the job; will not have a value if the job has never been run
    |\c last_executed_job_instanceid|The last executed instance id of the job
    |\c expiry_date|The optional expiration date of the job
    |\c recurring|a schedule duration in seconds; if present the job will be scheduled to run every \c n seconds \
        where \c n is the value assigned to this attribute; either this or the <i>Cron Schedule Fields</i> \
        attributes will be set, but not both
    |<i>Cron Schedule Fields</i>|the cron schedule fields are as follows: <tt>minute, hour,day,month,wday</tt>, see \
        @ref job_schedule for more information on the meanings of these fields; either these attributes or the \
        \c recurring attribute will be set, but not both
    |<i>Library Objects</i>|A set of functions, classes, and constants that will be loaded into the workflow's \
        program space; defined in table: \c JOB_LIB
    |\em Tags|A list of user-defined tags for the job, stored in the \c JOB_TAGS table

    @section jobdata Job Data

    When jobs are executed, an entry in the \c JOB_INSTANCE table is created to track the status of processing the job.

    Job instance rows have the following attributes:
    <b>Job Instance Attributes</b>
    |!Name|!Description
    |\c job_instanceid|The job instance ID
    |\c jobid|The ID of the type of job that was executed
    |\c sessionid|The @ref appsessionmodel "Qorus application session" ID of the controlling session when the job \
        was executed
    |\c jobstatus|The status of executing the job; see @ref JobStatusDescriptions for possible values
    |\c info|An optional YAML-encoded field of information related to job processing; data will only be present in \
        this field if the job calls @ref OMQ::UserApi::Job::JobApi::saveInfo() "JobApi::saveInfo()"
    |\c started|The date/time the job was scheduled and started
    |\c completed|The date/time the scheduled job compelted processing

    Additionally, the \c JOB_STATE_DATA table is used to store persistent data related to job processing to aid in
    recovering jobs in case of errors.  This table has one row for each job; the row for the job is cleared if the job
    has a @ref OMQ::StatComplete status.  Job state can be stored using
    @ref OMQ::UserApi::Job::JobApi::saveStateData() "JobApi::saveStateData()" and retrieved with
    @ref OMQ::UserApi::Job::JobApi::getStateData() "JobApi::getStateData()".

    Additionally, the \c JOB_PERSISTENT_STATE_DATA table is used to store persistent data related to job processing
    independently of error recovery.  This table has one row for each job; unlike job state data, the row for the job
    is not cleared when the job gets a @ref OMQ::StatComplete status.  Job state can be stored using
    @ref OMQ::UserApi::Job::JobApi::savePersistentStateData() "JobApi::savePersistentStateData()" and retrieved with
    @ref OMQ::UserApi::Job::JobApi::getPersistentStateData() "JobApi::getPersistentStateData()".
*/

/** @page sysprops System Properties

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    This section will outline Qorus system properties, which serve as a configuration store.

    @section sysprops_intro System Properties Introduction

    System properties are a domain-based key-value store that can be used to store persistent configuration information for Qorus interfaces.
    In the context of Qorus system properties, a "domain" is simply a name that groups together key-value pairs.
    Keys are strings, and values are any %Qore value that can be serialized to @ref qore_to_yaml_type_mappings "YAML".

    <b>System Properties Overview</b>
    |!Component|!Description
    |\c domain|a string of up to 240 bytes used to group key-value pairs; domain names are unique and case-sensitive
    |\c key|a string of up to 240 bytes that uniquely identifies a value within a domain; key names are case-sensitive
    |\c value|Any %Qore value that can be serialized to @ref qore_to_yaml_type_mappings "YAML" in less or equal to than 4000 bytes

    @note
    - System properties are stored in the \c SYSTEM_PROPERTIES table in the Qorus system schema; the data size limitations listed in the table
      above are due to column constraints in this table.
    - @ref qore_to_yaml_type_mappings "YAML serialization" incurs a small overhead of at least 4 bytes; trying to store a larger value will cause a \c PROP-ERROR exception to be thrown
    - All system property operations are protected by a read-write lock and are therefore atomic in respect to simultaneous actions in multiple threads

    @note The <b><tt>"omq"</tt></b> domain is protected; it contains system reference information and cannot be updated.

    @section sysprops_apis System Properties APIs

    System properties can be created, updated, read, and deleted using REST APIs, internal function calls, and from the command line.

    @note To delete a system property; call the function or network API to set the value, and omit the value; this will cause the system property key to be deleted; when the last key is deleted, the system property domain is deleted as well.

    <b>System Properties REST APIs</b>
    |!Action|!REST URI Request
    |read|<tt>GET /api/system/props</tt>\n <tt>GET /api/system/props/<i>name</i></tt>
    |create, update, delete|<tt>PUT /api/system/props/<i>domain</i>?action=updateMany;...</tt>\n <tt>PUT /api/system/props/<i>domain</i>/<i>name</i>?action=update;...</tt>

    <b>System Properties Functions</b>
    |!Function|!Availability
    |@ref prop_get()|All user server code (@ref workflowapi "workflows", @ref serviceapi "services", @ref jobapi "jobs", and mappers) and the @ref client "Qorus client library"
    |@ref prop_update()|@ref workflowapi "workflows", @ref serviceapi "services", @ref jobapi "jobs"

    <b>System Properties Command-Line Programs</b>
    |!Program|!Description
    |@ref oprop "oprop"|The primary command-line interface to system properties; uses the REST API
    |@ref qrest "qrest"|The raw REST client; can be used to query and set system properties directly with the REST API

    @section sysprops_examples System Properties Examples

    @par REST Examples
    @verbatim
qrest get system/props
qrest get system/props/omq
qrest get system/props/omq/value
    @endverbatim

    @par Function Example
    @verbatim
string ds = prop_get("mydomain", "myds") ?? "default_value";
    @endverbatim

    @par Command-line Example
    @verbatim
oprop get mydomain myds
oprop set mydomain hash key1=value,key2=value
    @endverbatim
*/

/** @page logging System, Service, Workflow, and Job Logging

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    This section will outline Qorus system, service, and workflow logging.

    @section logfilelocations Log File Names and Locations

    Log file names are created based on template strings that undergo variable substitution. The following is a list
    of the allowable variables in the template strings:

    <b>Log File Name Substitution Variables</b>
    |!Variable|!Valid For|!Description
    |\c $instance|All|Gives the instance name of the Qorus server
    |\c $pid|All|Gives the PID of the Qorus server process
    |\c $host|All|Gives the hostname where the Qorus server is running
    |\c $id|Workflows, Services, Jobs|Gives the ID number of the workflow, service, or job
    |\c $name|Workflows, Services, Jobs|Gives the name of the workflow, service, or job
    |\c $version|Workflows, Services, Jobs|Gives the version of the workflow, service, or job
    |\c $type|Services|Gives the type of service ("user" or "system")

    If Qorus logger contains @ref Logger::LoggerAppenderFile "appenders" then Qorus will use a system log directory to
    store log files (defined by the system option @ref logdir) in append mode (and the file is created if necessary)
    with a filename based on the filename template saved in appender params as filename.

    Each Qorus interface (workflow execution instance, service or job) has its own logger.  System loggers are
    furthermore divided to audit, alert, monitoring, http, qorus-core, qorus-master and qdsp loggers.

    If there is no specific logger for a system logger, the default system parameters will be used.  All logger
    parameters can be modified through the REST API or the Qorus UI.

    @section defaultlogparams Default logger params

    Default logger and appender params:
    - \c name: "DefaultSystemLogger" | "DefaultWorkflowLogger" | "DefaultServiceLogger" | "DefaultJobLogger"
    - \c level: 20000
    - \c additivity: false
        - name: "DefaultSystemAppender" | "DefaultWorkflowAppender" | "DefaultServiceAppender" | "DefaultJobAppender"
        - layoutPattern: "%m%n"
        - rotationCount: 10
        - appenderType: "LoggerAppenderFileRotate"
        - filename: "$pathOMQ-$instance-$name.log"
        - encoding: "UTF-8"
        - archivePattern: "%p%f.%i"

    To know more about logger @see @ref Logger

    @section logmessageformat Log File Message Format

    Messages in the log file are prefixed by default as follows:

    - \c YYYY.MM.DD \c HH:mm:SS \c T<i>tid</i>:

    The timestamp at the beginning shows the date and time the message was generated.  The number after the \c "T"
    gives the thread ID of the thread generating the message.  This helps in identifying consecutive messages produced
    by one thread.

    The default log message format can be customized for each appender; the information provided here about the
    prefix is the default log message prefix.

    Additionally, any fatal errors generated by workflow processing will also be logged in the system log file as well
    as the workflow's log file.

    Workflow execution instance log messages have the same format as system log messages, however the following fields
    are appended.  Fields surrounded by square brackets are only output when data is available:

    - ID <i>id</i>: [WI <i>wid</i>: [<i>sname</i>(<i>sid</i>)]]:

    The fields have the following meanings.

    <b>Workflow Execution Instance Log Fields</b>
    |!Field|!Description
    |\em id|The workflow execution instance ID.
    |\em wid|The workflow order data instance ID identifying the \c WORKFLOW_INSTANCE row in the Qorus database.
    |\em sname|The name of the step being executed.
    |\em sid|The step ID of the step being executed.

    Job log messages have the same format as system log messages with the following fields added:

    - [JI <i>jiid</i>]

    Where \em jiid is the job instance ID.

    @section logrotation Log File Rotation

    Log files can be rotated by calling the REST API method @ref rest_api_PUT_latest_system_rotateLogFiles or the RPC
    API method omq.system.rotate-log-files().  Log file rotation is only supported by log appenders that support file
    rotation; the default file appenders do support rotation.

    When log files are rotated, the current log file is closed and given a prefix of ".1".  Any older backup files
    will be renamed with a digit one higher than the current one up to the system option @ref max-log-files.

    Log files whose suffixes would exceed the value of the system option @ref max-log-files will be deleted.
*/

/** @page datamodel Data Model

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    The following table gives an overview of the Qorus table structure.

    <b>Workflow Metadata</b>
    |!Name|!Description
    |\c ERROR_SEVERITY|Gives valid severity levels for errors
    |\c FUNCTIONS|Gives the type of functions that can be in the database
    |\c GLOBAL_WORKFLOW_ERRORS|Holds global workflow error definition information
    |\c QUEUES|Queue description table
    |\c QUEUE_DATA_STATUS|Reference table for queue data dataus
    |\c QUEUE_TAGS|Holds key-value pair information associated to queues
    |\c SEGMENT_ASYNC_LINK|Defines the links between asynchronous segments
    |\c SEGMENT_DEPENDENCIES|Defines dependencies between segments
    |\c SEGMENT_STEPS|Defines the relationship between steps and segments
    |\c STEP_ARRAYTYPE|Gives valid array types for array steps
    |\c STEP_CONFIG_ITEMS|Defines step configuration items
    |\c STEP_STATUS|Gives valid statues for step instances
    |\c STEP_TAGS|Holds key-value pair information associated to steps
    |\c STEP_TYPE|Reference table for step types
    |\c STEPS|Top-level step definition (id, name, version, etc)
    |\c WORKFLOW_DEPENDENCIES|Defines inter-workflow dependencies
    |\c WORKFLOW_ERRORS|Holds workflow-specific error definition information
    |\c WORKFLOW_EVENT_TYPE_TAGS|Holds key-value pair information associated to workflow event types
    |\c WORKFLOW_EVENT_TYPES|Defines the possible workflow event types
    |\c WORKFLOW_GLOBAL_CONFIG_ITEMS|Defines global configuration items with workflow-specific values
    |\c WORKFLOW_LIB|Links workflows to code objects (classes, constants, and functions)
    |\c WORKFLOW_MAPPERS|Links workflows to data mapper objects
    |\c WORKFLOW_OPTIONS|Defines valid options per workflow and stores persistent workflow option values
    |\c WORKFLOW_STATUS|Gives valid statuses for workflow order data instances
    |\c WORKFLOW_STEPS|Defines the m:n relationship between workflows and steps
    |\c WORKFLOW_TAGS|Holds key-value pair information associated to workflows
    |\c WORKFLOW_VMAPS|Links workflows to value map objects
    |\c WORKFLOWS|Top-level workflow definition (id, name, version, etc)

    <b>Workflow Order Data</b>
    |!Name|!Description
    |\c ERROR_INSTANCE|Stores errors raised
    |\c ORDER_INSTANCE|Stores the static and dynamic data for workflow order data instances, 1:1 relationship with \c WORKFLOW_INSTANCE as joined by the workflow_instanceid primary key
    |\c ORDER_INSTANCE_KEYS|Stores user-defined keys for workflow order data instances
    |\c ORDER_INSTANCE_NOTES|Stores user or system generated notes
    |\c QUEUE_DATA|Stores asynchronous messages
    |\c SEGMENT_INSTANCE|Per workflow instance, tracks state of segments
    |\c SENSITIVE_ORDER_DATA|Encrypted sensitive order data
    |\c SENSITIVE_ORDER_DATA_KEYS|Encrypted sensitive order data aliases
    |\c STEP_INSTANCE|Per workflow and per segment instance, tracks the state of each step executed
    |\c STEP_INSTANCE_EVENTS|Connects a step in a given workflow order data instance to a workflow event
    |\c SUBWORKFLOW_INSTANCE|Matches subworkflow steps with their subworkflows
    |\c WORKFLOW_EVENTS|Stores workflow synchronization event information, including the event type ID, the key name, and the posted status.  @note Data in this table is not necessarily associated to only one workflow order, but may be shared across any number of workflow orders of different workflow types
    |\c WORKFLOW_FEEDBACK|Used to store feedback from child workflows
    |\c WORKFLOW_INSTANCE|Top-level workflow order data instance state table

    <b>Library Object Tables</b>
    |!Name|!Description
    |\c FSM|Contains @ref finite_state_machines "Finite State Machine" definitions
    |\c FUNCTION_INSTANCE|Contains the definition of a function (id, name, version, logic, etc)
    |\c FUNCTION_INSTANCE_TAGS|Holds key-value pair information associated to function instances
    |\c CLASSES|Contains versioned user class definitions
    |\c CLASS_DEPENDENCIES|Lists dependencies for classes that depend on other classes
    |\c CLASS_TAGS|Holds key-value pair information associated to classes
    |\c CLASS_API_MANAGERS|Holds the list of API managers associated with a class
    |\c CONSTANT_TAGS|Holds key-value pair information associated to constants
    |\c CONSTANTS|Contains versioned constant definitions
    |\c LIBRARY_TYPE|Valid types of library objects
    |\c PIPELINES|Contains @ref data_pipelines "data pipeline" definitions

    <b>Service Tables</b>
    |!Name|!Description
    |\c SERVICE_AUTH_LABELS|Defines authorization labels for HTTP handlers in services
    |\c SERVICE_CONFIG_ITEMS|Defines service configuration items
    |\c SERVICE_GLOBAL_CONFIG_ITEMS|Defines global configuration items with per-service values
    |\c SERVICE_LIB|Links services to code objects (classes, constants, and functions)
    |\c SERVICE_MAPPERS|Links services to data mapper objects
    |\c SERVICE_METHOD_TAGS|Holds key-value pair information associated to service methods
    |\c SERVICE_METHODS|Service method definitions (name, description, code, etc)
    |\c SERVICE_STATE_DATA|Stores service state data for service recovery logic
    |\c SERVICE_TAGS|Holds key-value pair information associated to services
    |\c SERVICE_TYPE|Type of services possible (currently only system and user)
    |\c SERVICE_VMAPS|Links services to value map objects
    |\c SERVICES|Top-level service definition (type, name, description)L

    <b>Job Tables</b>
    |!Name|!Description
    |\c JOB_CONFIG_ITEMS|Defines job configuration items
    |\c JOB_ERRORS|Holds information about errors raised when jobs are executed
    |\c JOB_GLOBAL_CONFIG_ITEMS|Defines global configuration items with per-job values
    |\c JOB_INSTANCE|Tracks the status of processing jobs
    |\c JOB_LIB|Lists code objects (classes, constants, and functions) that will be included in each job's Program object
    |\c JOB_MAPPERS|Links jobs to data mapper objects
    |\c JOB_PERSISTENT_STATE_DATA|Stores persistent job state data
    |\c JOB_STATE_DATA|Stores job state data for job recovery logic
    |\c JOB_STATUS|Static reference table giving valid statuses for job instance records
    |\c JOB_TAGS|Holds key-value pair information associated to jobs
    |\c JOB_VMAPS|Links jobs to value map objects
    |\c JOBS|Job definition

    <b>Mapper Tables</b>
    |!Name|!Description
    |\c MAPPERS|Defines data mapper objects
    |\c MAPPER_TAGS|Holds key-value pair tag information associated to data mappers objects

    <b>Value Map Tables</b>
    |!Name|!Description
    |\c VALUE_MAPS|Defines value map objects
    |\c VALUE_MAP_VALUES|Holds key-value information associated to value map objects

    <b>SLA Tracking Tables</b>
    |!Name|!Description
    |\c SLA|Defines SLAs
    |\c SLA_EVENTS|Stores SLA events

    <b>User Connection Table</b>
    |!Name|!Description
    |\c CONNECTIONS|Holds information about @ref userconn "user connections"

    <b>Cluster Table</b>
    |!Name|!Description
    |\c CLUSTER_PROCESSES|Holds information about cluster processes

    @anchor RBACTables

    <b>RBAC Tables</b>
    |!Name|!Description
    |\c GROUP_JOBS|Defines the job members of @ref rbacgroups "interface groups"
    |\c GROUP_MAPPERS|Defines the mapper members of @ref rbacgroups "interface groups"
    |\c GROUP_SERVICES|Defines the service members of @ref rbacgroups "interface groups"
    |\c GROUP_VMAPS|Defines the value set members of @ref rbacgroups "interface groups"
    |\c GROUP_WORKFLOWS|Defines the workflow members of @ref rbacgroups "interface groups"
    |\c GROUP_FSMS|Defines the @ref finite_state_machines "Finite State Machine" members of @ref rbacgroups "interface groups"
    |\c GROUP_PIPELINES|Defines the @ref data_pipelines "data pipeline" members of @ref rbacgroups "interface groups"
    |\c GROUPS|Defines @ref rbacgroups

    <b>Data Type Table</b>
    |!Name|!Description
    |\c DATA_TYPES|Stores data type information

    <b>System Tables</b>
    |!Name|!Description
    |\c SESSIONS|Stores session information
    |\c SYSTEM_PROPERTIES|Stores @ref sysprops "system property" information

    <b>Audit Tables</b>
    |!Name|!Description
    |\c AUDIT_EVENT_CODES|Lists possible audit event codes (see @ref AuditEventCodes for the list of values in this reference table)
    |\c AUDIT_EVENTS|Contains auditing events (see also @ref auditevents)
*/

/** @page systemoptions System Options

    @tableofcontents

    @ref systemref "Back to the System Reference Manual Table of Contents"

    @section optionoverview Overview of All System Options

    @subsection qorusoptionoverview Qorus Domain Options

    The following options are all in the \c qorus option domain and can be set in the @ref options "options"
    file as well as overridden on the command line when starting qorus.

    <b>Qorus System Options</b>
    |!Option|!Type|!Default|!Description
    |@ref alert-fs-full|int|\c 85|The percentage above which an alert will be raised due to a full filesystem
    |@ref alert-smtp-connection|string|- none -|The name of the @ref userconn "user connection" for the SMTP server for delivering alert emails
    |@ref alert-smtp-enable|bool|@ref False "False"|A flag allowing alert emails to be enabled or disabled at runtime
    |@ref alert-smtp-from|string|<tt>alert_noreply@@$instance</tt>|Source/from email address for alert emails
    |@ref alert-smtp-interval|int|\c 60|The interval in seconds for grouping and delivering alert emails
    |@ref alert-smtp-to|list of strings|- none -|List of email addresses for delivering alert emails
    |@ref allow-node-overcommit-percent|int|\c 0|Percent of physical memory that @ref qorus "qorus-master" will tolerate on a node when launching new processes
    |@ref async_delay|int|\c 600|Value in seconds: the amount of time a workflow in @ref OMQ::WM_Recovery mode will wait before trying to recover a step with @ref OMQ::StatAsyncWaiting status
    |@ref audit|list of strings|- none -|List of string auditing options, for possible values, see @ref AuditOptions
    |@ref auto-error-update|bool|@ref True "True"|If True, then adding new error definitions for workflows will automatically create or update workflow-specific or global error defintions (the default behavior); if False, then only new global error definitions will be created automatically and updates are never made automatically; updates can only be made manually when this option is False
    |@ref autostart-interfaces|bool|@ref True "True"|If True, then workflows, services, and jobs are started automatically when the system is started according to their configuration; if False, then no interfaces are started automatically when the system is started regardless of their configuration
    |@ref cache-max|int|\c 100000|Maximum number of workflow order data instances to cache after a detach.
    |@ref connection-modules|list of strings|- none -|List of user modules defining user-specific @ref userconn "connection types"
    |@ref cors-allow-credentials|bool|@ref True "True"|Set this option to @ref True to allow CORS requests using \
        credentials; only used if @ref cors-enable is @ref True
    |@ref cors-allow-headers|list of strings|<tt>Content-Type, content-type, Content-Language, content-language, \
        Accept, Accept-Language, Authorization, Qorus-Token</tt>|This option provides a list of headers allowed in \
        CORS requests; only used if @ref cors-enable is @ref True
    |@ref cors-allow-methods|list of strings|<tt>GET, POST, PUT, PATCH, DELETE, OPTIONS</tt>|This option provides a \
        list of HTTP methods in all upper case giving \
        the allowed methods in CORS preflight requests for accessing HTTP resources; only used if \
        @ref cors-enable is @ref True
    |@ref cors-allow-origin|list of strings|<tt>*</tt>|This option provides a list of allowed origins for the \
        <tt>Access-Control-Allow-Origin</tt> header; if an origin is in this list, then CORS responses will be \
        enabled for the given origin if the @ref cors-enable option is @ref True; use <tt>*</tt> to enable CORS for \
        all origins
    |@ref cors-enable|bool|@ref False "False"|If @ref True "True" then all Qorus system HTTP handlers will return \
        <a href="https://en.wikipedia.org/wiki/Cross-origin_resource_sharing">CORS</a> headers in responses to \
        enable Qorus functionality to be accessible from external web applications
    |@ref cors-max-age|int|\c 9999999|This option tells HTTP clients how long the results of a preflight request \
        (the info contained in the <tt>Access-Control-Allow-Methods</tt> and <tt>Access-Control-Allow-Headers</tt> \
        headers) can be cached; only used if @ref cors-enable is @ref True
    |@ref daemon-mode|bool|@ref True "True"|If True, will fork into the background after the process has started
    |@ref dataprovider-modules|list of strings|- none -|List of user modules defining data provider definitions and support
    |@ref db-max-threads|int|\c 30|Maximum number of parallel tasks to execute when running special database tasks in parallel; should not be larger than @ref system-pool-maximum
    |@ref dbparams-file|string|see desc.|the option is ignored from Qorus 4.0
    |@ref default-datasource-coordinated|bool|@ref False "False"|Sets the default mode for @ref qdsp "qdsp" processes without a \c "coord-mode" option in the datasource connection
    |@ref defines|hash|- none -|Set of parse defines for all user code (workflows, services, and jobs) and also for @ref connectionfiles
    |@ref disable-https-redirect|bool|@ref False "False"|if @ref True then automatic redirects from HTTP to HTTPS \
        requests for the web UI will be disabled, allowing the UI to be accessible from both HTTP and HTTPS \
        listeners at the same time
    |@ref detach-delay|int|\c 3600|Value in seconds: the amount of time workflow order data instances will be cached before being purged from the cache
    |@ref dsp-error-timeout|int|\c 120000|The amount of time in milliseconds for a runtime exception to be raised if a connection cannot be allocated from a system @ref dsconn "datasource pool"
    |@ref dsp-warning-timeout|int|\c 5000|The amount of time in milliseconds for a @ref transientalerts "transient alert" to be raised if a connection cannot be allocated from a system @ref dsconn "datasource pool"
    |@ref http-secure-certificate|string|- none -|The certificate file in PEM format for HTTPS listeners
    |@ref http-secure-private-key|string|- none -|The private key file in PEM format for HTTPS listeners
    |@ref http-secure-private-key-password|string|- none -|The password for the private key for HTTPS listeners
    |@ref http-secure-server|list of strings|- none -|The optional interface and required port number for HTTPS listeners and other options
    |@ref http-server|list of strings|\c 8001|The optional interface and required port number for HTTP listeners (list of URLs or hostname:port strings)
    |@ref instance-key|string|\c "qorus-test-instance"|The unique identifier for an instance of Qorus
    |@ref job-logfile-template|string|\c OMQ-$instance-JOB-$name.log|gives the default logfile template for new job log appenders
    |@ref job-modules-option|list of strings|- none -|List of user modules defining functionality to extend job APIs
    |@ref kubernetes-namespace|string|\c default|The namespace to use in Kubernetes REST API calls for autoscaling control
    |@ref logdir|string|- none -|The log directory for Qorus
    |@ref logfile-template|string|\c OMQ-$instance-$name.log|Gives the default logfile template for new system log appenders
    |@ref manage-interfaces|bool|@ref True "True"|Determines whether or not the system will automatically start and stop workflows, services, and jobs depending on their @ref connmon "connection status"
    |@ref mapper-modules|list of strings|- none -|List of user modules defining user-specific data mapper types
    |@ref max-events|int|\c 100000|Maximum number of @ref systemevents "system events" to cache
    |@ref max-log-files|int|\c 10|The default value to use for the \c rotationCount option for new log appenders supporting file rotation
    |@ref max-process-memory-percent|int|\c 99|Maximum private (heap + stack etc) memory as a percentage of RAM on the node for a process before the @ref qorus "master process" will terminate it due to excess memory usage
    |@ref max-retries|int|\c 5|Number of retries before getting status @ref OMQ::StatError
    |@ref max-service-threads|int|\c 200|Maximum number of threads a Qorus service can start
    |@ref minimum-tls-13|bool|@ref False "False"|If True the TLS v1.3 protocol will be the minimum supported version \
        with secure connections
    |@ref network-key|string|- none -|The file name of an encryption key for private cluster network data encryption and decryption; the file must contain a 32-byte binary encryption key
    |@ref node|hash|- none -|a hash of node names to IP addresses for cluster communication
    |@ref option-file|string|see desc.|The path to the file containing these system options; the default value depends on the Qorus installation location
    |@ref oracle-datasource-pool|bool|@ref True "True"|Enables automatic Oracle instrumentation as described in \
        @ref OMQ::QorusOracleDatasourcePool "QorusOracleDatasourcePool"
    |@ref password-policy-min-length|int|\c 0|Minimum password length when changing passwords
    |@ref password-policy-mixed-case|bool|@ref False "False"|If new passwords require at least one upper and lower-case letter
    |@ref password-policy-numbers|bool|@ref False "False"|If new passwords require at least one number
    |@ref password-policy-symbols|bool|@ref False "False"|If new passwords require at least one symbol
    |@ref purge-sensitive-data-canceled|bool|@ref True "True"|if @ref sensitive_data should be purged from the system when an order goes to @ref OMQ::StatCanceled
    |@ref purge-sensitive-data-complete|bool|@ref True "True"|if @ref sensitive_data should be purged from the system when an order goes to @ref OMQ::StatComplete
    |@ref recover_delay|int|\c 60|Value in seconds: the amount of time a workflow in @ref OMQ::WM_Recovery mode will wait before trying to recover a step with @ref OMQ::StatRetry status
    |@ref recovery-amount|int|\c 750|Monetary amount for a single recovered workflow order to estimate the cost savings of automatic technical error recovery in Qorus
    |@ref recovery-currency|string|\c USD|Currency for @ref recovery-amount
    |@ref remoteconnections-file|string|see desc.|This option is ignored since Qorus 4.0 (deprecated)
    |@ref scaling-min-replicas|int|\c 1|The minimum number of replicas that will be started when Qorus is running \
        under <a href="https://kubernetes.io/">Kubernetes</a>
    |@ref scaling-max-replicas|int|\c 3|The maximum number of replicas that will be started when Qorus is running \
        under <a href="https://kubernetes.io/">Kubernetes</a>
    |@ref scaling-cpu|int|\c 50|The percentage CPU usage goal for <a href="https://kubernetes.io/">Kubernetes</a> \
        for all pods
    |@ref scaling-memory|string|\c "200M"|The memory usage target for <a href="https://kubernetes.io/">Kubernetes</a>
    |@ref sensitive-data-key|string|- none -|The file name of an encryption key for sensitive order data encryption and decryption defining a 32-byte encryption key
    |@ref sensitive-value-key|string|- none -|The file name of an encryption key for sensitive key value data encryption and decryption defining a 4 - 56 byte encryption key
    |@ref service-modules-option|list of strings|- none -|List of user modules defining functionality to extend service APIs
    |@ref service-perf-events|bool|False|enables @ref SERVICE_METHOD_PERFORMANCE "SERVICE_METHOD_PERFORMANCE" event emission on all service calls; note that enabling this option can cause service method call performance degredation
    |@ref sla-max-events|int|\c 100|Maximum SLA events to hold before flushing to DB
    |@ref sla-max-sync-secs|int|\c 30|Maximum number of seconds to hold SLA events before flushing to DB
    |@ref socket-min-throughput|int|20480|The minimum socket throughput in bytes/second below which a warning will be raised for socket-based connection objects
    |@ref socket-min-throughput-ms|int|1000|The minimum time in milliseconds a socket transfer must take for it to be eligible for throughput warnings; transfers that take less time than this are ignored
    |@ref socket-warning-timeout|int|10000|The socket operation timeout threshold in milliseconds for raising transient alerts against socket-based connection objects
    |@ref sql-default-blocksize|int|5000|Size of the regular @ref appsessionrecovery and workflow @ref workflowstartup SQL batches
    |@ref sql-init-blocksize|int|200|Size of the first workflow @ref workflowstartup SQL batch for instant workflow instance processing as soon as possible
    |@ref stack-size|int|- none -|The stack size for new threads in bytes; must be &gt;= \c 524288
    |@ref svc-logfile-template|string|\c OMQ-$instance-SVC-$name.log|Gives the default logfile template for new service log appenders
    |@ref sync-delay|int|\c 3600|Value in seconds: the amount of time workflow synchronization events will be cached since their last access before being purged from the cache
    |@ref system-pool-maximum|int|\c 40|Maximum number of connections for the system schema @ref Qore::SQL::DatasourcePool "DatasourcePool"
    |@ref system-pool-minimum|int|\c 5|Minimum number of connections for the system schema @ref Qore::SQL::DatasourcePool "DatasourcePool"
    |@ref systemdb|string|<tt>pgsql:omq/omq\@omq</tt>|A database connection string for the system schema @ref Qore::SQL::DatasourcePool "DatasourcePool"
    |@ref transient-alert-max|int|\c 1000|Maximum number of @ref transientalerts "transient alert" to cache
    |@ref verbose|int|5|Deprecated; only used for migrating an indication of the log level to new logger configurations
    |@ref vmap-size-threshold|int|100|The maximum size of a value map for it to be cached entirely on its first reference
    |@ref warning-process-memory-percent|int|\c 50|Maximum private (heap + stack etc) memory as a percentage of RAM on the node for a process before a \c "PROCESS-MEMORY-USAGE" @ref ongoingalerts "ongoing alert" is raised about excessive memory usage for the process
    |@ref wf-logfile-template|string|\c OMQ-$instance-WF-$name.log|Gives the default logfile template for new \
        workflow log appenders
    |@ref workflow-modules-option|list of strings|- none -|List of user modules defining functionality to extend \
        workflow APIs
    |@ref workflow-params|hash|- none -|This option is ignored since Qorus 4.0 (deprecated)
    |@ref workflow-perf-events|bool|@ref False|enables @ref WORKFLOW_PERFORMANCE "WORKFLOW_PERFORMANCE" event \
        emission for all workflows
    |@ref workflow-step-perf-events|bool|@ref False|enables \
        @ref WORKFLOW_STEP_PERFORMANCE "WORKFLOW_STEP_PERFORMANCE" event emission for all workflow steps; note that \
        enabling this option can cause workflow step performance degredation

    @subsubsection readonlyoptions Runtime Read-Only Qorus System Options

    The following options can only be set in the @ref options or on the qorus command-line (they cannot be changed after the system starts); listed in alphabetical order:

    - @ref alert-fs-full (@ref qorus-core "qorus-core")
    - @ref alert-smtp-connection (@ref qorus-core "qorus-core")
    - @ref alert-smtp-from (@ref qorus-core "qorus-core")
    - @ref alert-smtp-interval (@ref qorus-core "qorus-core")
    - @ref alert-smtp-to (@ref qorus-core "qorus-core")
    - @ref allow-node-overcommit-percent (@ref qorus "qorus-master")
    - @ref audit (@ref qorus-core "qorus-core")
    - @ref auto-error-update (@ref qorus-core "qorus-core")
    - @ref autostart-interfaces (@ref qorus-core "qorus-core")
    - @ref connection-modules (@ref qorus-core "qorus-core")
    - @ref dataprovider-modules (@ref qorus-core "qorus-core", @ref qwf "qwf", @ref qsvc "qsvc", @ref qjob "qjob")
    - @ref db-max-threads (@ref qorus-core "qorus-core")
    - @ref daemon-mode (@ref qorus-core "qorus-core")
    - @ref default-datasource-coordinated (@ref qdsp "qdsp")
    - @ref defines (@ref qorus-core "qorus-core" @ref qwf "qwf", @ref qsvc "qsvc", @ref qjob "qjob")
    - @ref disable-https-redirect (@ref qorus-core "qorus-core")
    - @ref http-server (@ref qorus-core "qorus-core")
    - @ref http-secure-server (@ref qorus-core "qorus-core")
    - @ref http-secure-certificate (@ref qorus-core "qorus-core")
    - @ref http-secure-private-key (@ref qorus-core "qorus-core")
    - @ref http-secure-private-key-password (@ref qorus-core "qorus-core")
    - @ref instance-key (@ref qorus-core "qorus-core")
    - @ref job-modules-option (@ref qorus-core "qorus-core", @ref qjob "qjob")
    - @ref logdir (all)
    - @ref manage-interfaces (@ref qorus-core "qorus-core")
    - @ref mapper-modules (@ref qorus-core "qorus-core" @ref qwf "qwf", @ref qsvc "qsvc", @ref qjob "qjob")
    - @ref max-events (@ref qorus-core "qorus-core")
    - @ref max-log-files (@ref qorus-core "qorus-core")
    - @ref max-process-memory-percent (@ref qorus "qorus")
    - @ref max-service-threads (@ref qorus-core "qorus-core")
    - @ref minimum-tls-13 (@ref qorus-core "qorus-core")
    - @ref network-key (all)
    - @ref node (all)
    - @ref oracle-datasource-pool (@ref qdsp "qdsp")
    - @ref sensitive-data-key (@ref qorus-core "qorus-core")
    - @ref sensitive-value-key (@ref qorus-core "qorus-core")
    - @ref service-modules-option (@ref qorus-core "qorus-core", @ref qsvc "qsvc")
    - @ref sla-max-events (@ref qorus-core "qorus-core")
    - @ref stack-size (@ref qorus-core "qorus-core", @ref qwf "qwf", @ref qsvc "qsvc", @ref qjob "qjob")
    - @ref systemdb
    - @ref system-pool-minimum (@ref qdsp "qdsp")
    - @ref system-pool-maximum (@ref qdsp "qdsp")
    - @ref transient-alert-max (@ref qorus-core "qorus-core")
    - @ref warning-process-memory-percent (@ref qorus-core "qorus-core")
    - @ref workflow-modules-option (@ref qorus-core "qorus-core", @ref qwf "qwf")

    @subsubsection perfoptions Qorus System Options Related to Performance and Scalability

    See details of the following options for how they affect the system's performance and scalability:
    - @ref cache-max
    - @ref detach-delay
    - @ref oracle-datasource-pool
    - @ref service-perf-events
    - @ref sql-default-blocksize
    - @ref sql-init-blocksize
    - @ref workflow-step-perf-events

    @subsection qorusclientoptionoverview Qorus Client Domain Options

    The following options are all in the \c qorus-client option domain and can be set in the @ref options "options"
    file.

    <b>Qorus System Options</b>
    |!Option|!Type|!Default|!Description
    |@ref allow-test-execution|bool|@ref False|allows execution of @ref QorusInterfaceTest
    |@ref applications|list of strings|- none -|The list of user applications present in this instance of Qorus for \
        verification with @ref oload "oload"
    |@ref client-pool-maximum|int|\c 10|The Maximum number of connections in datasource connection pools when \
        created from the client (ex: \
        @ref OMQ::QorusClientAPI::getDatasourcePool() "QorusClientAPI::getDatasourcePool()")
    |@ref client-pool-minimum|int|\c 3|The minimum number of connections in datasource connection pools when created \
        from the client (ex: @ref OMQ::QorusClientAPI::getDatasourcePool() "QorusClientAPI::getDatasourcePool()")
    |@ref client-url|string|depends on @ref http-secure-server and @ref http-server|The URL used to communicate with \
        Qorus from client programs
    |@ref data-tablespace|string|- none -|The data tablespace name for the datasource given as the prefix of the \
        option name
    |@ref index-tablespace|string|- none -|The index tablespace name for the datasource given as the prefix of the \
        option name
    |@ref missing-tag-warning|bool|@ref True|Show missing tag warnings in @ref oload "oload"
    |@ref override-job-params|bool|@ref False|Always override job schedule and runtime parameters when loading jobs \
        with @ref oload "oload", even if they have been changed with the API
    |@ref proxy-url|string|- none -|The URL of the HTTP proxy for the Qorus server, optionally including any proxy \
        authentication
    |@ref remote|bool|@ref True|The default value of the \c "remote" option for @ref oload "oload" for interfaces \
        that do not specify this option
    |@ref warn-deprecated-api|bool|@ref False|If @ref True, @ref oload "oload" will warn when loading interface code \
        using deprecated APIs

    @section optiondetails Option Details

    <hr>
    @subsection alert-fs-full qorus.alert-fs-full

    The percentage above which an alert will be raised due to a full filesystem.

    <i>Data Type and Default Value</i>
    - int: \c 85

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus alert-fs-full=75 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 3.0.0

    <hr>
    @subsection alert-smtp-connection qorus.alert-smtp-connection

    The name of the @ref userconn "user connection" for the SMTP server for delivering alert emails.

    <i>Data Type and Default Value</i>
    - string: no default value

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus alert-smtp-connection=alert-smtp @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 3.0.0

    <hr>
    @subsection alert-smtp-enable qorus.alert-smtp-enable

    A flag allowing alert emails to be enabled or disabled at runtime.

    <i>Data Type and Default Value</i>
    - bool: @ref False

    @since Qorus 3.0.0

    <hr>
    @subsection alert-smtp-from qorus.alert-smtp-from

    Source/from email address for alert emails.

    <i>Data Type and Default Value</i>
    - string: <tt>alert_noreply@@$instance</tt>

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus alert-smtp-from=my_instance@example.com @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 3.0.0

    <hr>
    @subsection alert-smtp-interval qorus.alert-smtp-interval

    The interval in seconds for grouping and delivering alert emails.

    <i>Data Type and Default Value</i>
    - int: \c 60

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus alert-smtp-interval=120 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 3.0.0

    <hr>
    @subsection alert-smtp-to qorus.alert-smtp-to

    List of email addresses for delivering alert emails.

    <i>Data Type and Default Value</i>
    - list of strings: no default value

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus alert-smtp-to=ops@example.com,monitoring@example.com @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 3.0.0

    <hr>
    @subsection allow-node-overcommit-percent qorus.allow-node-overcommit-percent

    Sets the percent of physical memory that the qorus master process will tolerate on a node when launching new
    processes.

    <i>Data Type and Default Value</i>
    - int: 0 (no overcommit tolerance = processes that would cause main memory to be exhausted are not launched)

    @note
    - This option may also be overridden at the workflow execution instance level by setting a workflow option with this name.

    @since Qorus 4.1.4.p3

    <hr>
    @subsection async_delay qorus.async_delay

    Sets the amount of time in seconds a workflow (or workflow thread) running in @ref OMQ::WM_Recovery mode will wait before trying to recover a step with @ref OMQ::StatAsyncWaiting status.

    <i>Data Type and Default Value</i>
    - int: 600 (600 seconds = 10 minutes)

    @note
    - This option may also be overridden at the workflow execution instance level by setting a workflow option with this name.
    - This option (along with @ref recover_delay) does not follow the option name standard of using dashes to separate words in the option identifier

    <hr>
    @subsection audit qorus.audit

    Controls @ref auditing by setting the list of events to audit in the \c AUDIT_EVENTS table; see @ref auditing for a description of the possible options (corresponding to @ref AuditOptions giving a list of possible values).  The default when this option is not present is that nothing will be audited.

    System auditing impacts database space used and can also impact performance; only enable auditing for events that need tracking to save space in the database and ensure that performance is maximized.

    <i>Data Type and Default Value</i>
    - list of strings: no default value

    @note \c "*" can also be given as the only value to this option, meaning audit all events

    @since Qorus 2.6.2

    <hr>
    @subsection auto-error-update qorus.auto-error-update

    If @ref True, then adding new error definitions for workflows will automatically create or update workflow-specific or global error defintions (the default behavior); if @ref False, then only new global error definitions will be created automatically and updates are never made automatically; updates can only be made manually when this option is @ref False.

    <i>Data Type and Default Value</i>
    - bool: @ref True

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus auto-error-update=False @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 2.8.1.p7

    <hr>
    @subsection autostart-interfaces qorus.autostart-interfaces

    If @ref True, then workflows, services, and jobs are started automatically when the system is started according to their configuration; if @ref False, then no interfaces are started automatically when the system is started regardless of their configuration.

    <i>Data Type and Default Value</i>
    - bool: @ref True

    @note
    - This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus autostart-interfaces=False @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.
    - To ensure that no interfaces are started in a Qorus instance, set this option and @ref manage-interfaces to @ref False "False" when Qorus is started

    @since Qorus 3.0.2

    <hr>
    @subsection cache-max qorus.cache-max

    - Sets the maximum number of workflow order data instances to cache after a detach with status @ref OMQ::StatReady, @ref OMQ::StatRetry, @ref OMQ::StatAsyncWaiting, @ref OMQ::StatWaiting, @ref OMQ::StatEventWaiting, or @ref OMQ::StatIncomplete.

    This option has a direct impact on performance as setting a large number here increases the size of the cache and therefore keeps more data in memory, reducing SQL I/O by reducing the need for the server to query the database for workflow data.

    <i>Data Type and Default Value</i>
    - int: 100000

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus cache-max=10000000@endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection connection-modules qorus.connection-modules

    This option sets the set of user modules that provide support for custom @ref userconn "user connection types".
    Each module must define the following public function:
    - <tt>public AbstractIterator sub get_schemes() {}</tt>: this must return an
      @ref Qore::AbstractIterator "AbstractIterator" object that iterates a list of @ref OMQ::ConnectionScheme objects
      that enumerate the connection types handled by the module

    Furthermore, the following optional functions are supported:
    - <tt>public softlist sub required_resources() {}</tt>: this optional function can return a list of resources
      required by the module; currently-supported resources:
      - "omqservice": the @ref OMQ::omqservice "$omqservice" service object
    - <tt>public sub set_resources(hash $h) {}</tt>: (this must be declared if \c required_resources() is declared)
      accepts a hash of the resources required by \c required_resources()

    <i>Data Type and Default Value</i>
    - @ref list_type "list": no default value

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example: @verbatim qorus connection-modules=RabbitMQConnection @endverbatim In order to effect
    a change in the value of this option, it is necessary to restart the server.

    @note Full path to the module can be specified too; for example:
    @verbatim qorus.connection-modules: RabbitMQConnection,/opt/qorus/modules/Foo.qm @endverbatim

    @par an example of the module
    @code
%requires qore >= 0.9

module TestUserConnectionProvider {
    version = "1.0";
    desc = "just test the connection provider module";
    author = "Qore Technologies, s.r.o.";
    url = "http://qoretechnologies.com";
}

%requires QorusClientCore
%requires ConnectionProvider

%new-style
%require-types
%strict-args
%enable-all-warnings

public namespace TestUserConnectionProvider {
    public AbstractIterator sub get_schemes() {
        softlist<auto> l = (
            new ConnectionScheme("qtest", "TestUserConnectionProvider::TestUserConnection"),
        );
        return l.iterator();
    }

    public softlist sub required_resources() {
    }

    public sub set_resources(hash h) {
    }

    public class TestUserConnection inherits HttpConnection {
        constructor(string name, string desc, string url, hash attrs, hash opts)
           : HttpConnection(name, desc, url, attrs, opts) {
               # some custom things can go here... or into inherited methods
        }

        string getType() {
            return "testuserconnection";
        }
    }
}
@endcode

    @since Qorus 3.0.0

    <hr>
    @subsection cors-allow-credentials qorus.cors-allow-credentials

    Set this option to @ref True to allow CORS requests using credentials; only used if @ref cors-enable is @ref True.

    <i>Data Type and Default Value</i>
    - bool: @ref True

    @since Qorus 5.0.6

    <hr>
    @subsection cors-allow-headers qorus.cors-allow-headers

    This option provides a list of headers allowed in CORS requests; only used if @ref cors-enable is @ref True.

    <i>Data Type and Default Value</i>
    - list<string>: <tt>("Content-Type", "content-type", "Content-Language", "content-language", "Accept",
        "Accept-Language", "Authorization")</tt>

    @since Qorus 5.0.6

    <hr>
    @subsection cors-allow-methods qorus.cors-allow-methods

    This option provides a list of HTTP methods in all upper case giving the allowed methods in CORS preflight
    requests for accessing HTTP resources; only used if @ref cors-enable is @ref True.

    <i>Data Type and Default Value</i>
    - list<string>: <tt>("GET", "POST", "PUT", "PATCH", "DELETE", "OPTIONS")</tt>

    @since Qorus 5.0.6

    <hr>
    @subsection cors-allow-origin qorus.cors-allow-origin

    This option provides a list of allowed origins for the <tt>Access-Control-Allow-Origin</tt> header; if an origin
    is in this list, then CORS responses will be enabled for the given origin if the @ref cors-enable option is
    @ref True; use <tt>*</tt> to enable CORS for all origins.

    <i>Data Type and Default Value</i>
    - list<string>: <tt>("*",)</tt>

    @since Qorus 5.0.6

    <hr>
    @subsection cors-enable qorus.cors-enable

    If @ref True "True then all Qorus system HTTP handlers will return
    <a href="https://en.wikipedia.org/wiki/Cross-origin_resource_sharing">CORS</a> headers in responses from the Qorus
    system file, REST, and WebSocket handlers to enable Qorus functionality to be accessible from external web
    applications.

    <i>Data Type and Default Value</i>
    - bool: @ref False

    @since Qorus 5.0.6

    <hr>
    @subsection cors-max-age qorus.cors-max-age

    This option tells HTTP clients how long the results of a preflight request (the info contained in the
    <tt>Access-Control-Allow-Methods</tt> and <tt>Access-Control-Allow-Headers</tt> headers) can be cached in seconds;
    only used if @ref cors-enable is @ref True.

    A value of -1 means to disable caching and require preflight \c OPTIONS checks for all calls.

    Most browsers have limits on the maximum value for this option that is respected, which could vary from a few
    minutes up to a day (ex: \c 86400 seconds for Firefox); the Qorus default value is meant to indicate to the
    browser that the maximum validity period should be used to reduce I/O by eliminating unnecessary preflight
    \c OPTIONS calls.

    <i>Data Type and Default Value</i>
    - int: \c 9999999

    <hr>
    @subsection dataprovider-modules qorus.dataprovider-modules

    This option provides a list of user modules defining @ref dataproviderintro "data provider" definitions and
    support.

    <i>Data Type and Default Value</i>
    - list of strings: @ref nothing

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus dataprovider-modules=my-module @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 4.1

    <hr>
    @subsection daemon-mode qorus.daemon-mode

    If this option is set to @ref True "True" then the system will fork into the background after starting.

    <i>Data Type and Default Value</i>
    - bool: @ref True

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus daemon-mode=false @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection db-max-threads qorus.db-max-threads

    This option sets the count of simultaneously running parallel tasks in Qorus system database.

    This option is used when running database tasks in parallel in special cases like session recoveries and
    populating workflow event queues to get better performance.

    The optimal value of this option is dependent of your Qorus system database configuration hardware; in general the
    recommended value is "# DB server CPUs + 2".

    This value may be tuned according to user requirements.

    <i>Data Type and Default Value</i>
    - int: \c 30

    @note This option should not be greater than the maximum number of sessions in the system
    @ref Qore::SQL::DatasourcePool "DatasourcePool".

    @since Qorus 2.0.3

    <hr>
    @subsection dbparams-file qorus.dbparams-file

    The option is ignored and considered empty from Qorus 4.0; all system datasources are handled as
    @ref dsconn "datasource connections"; the \c dbparams is no longer used by Qorus as of Qorus 4.0.

    @see @ref dsconn

    @since Qorus 4.0 the option is ignored

    <hr>
    @subsection default-datasource-coordinated qorus.default-datasource-coordinated

    Sets the default mode for @ref qdsp "qdsp" processes without a \c "coord-mode" option in the datasource
    connection; see @ref qdsp_mode for more information.

    <i>Data Type and Default Value</i>
    - bool: @ref False

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-
    line; for example: @verbatim qorus default-datasource-coordinated=true @endverbatim  In order to effect a change
    in the value of this option, it is necessary to restart the server.

    @since Qorus 4.0

    <hr>
    @subsection defines qorus.defines

    This option sets the parse defines for all user code (workflows, services, and jobs) and also for @ref connectionfiles for conditional parsing.

    <i>Data Type and Default Value</i>
    - @ref hash_type "hash": no default value

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus defines=Production=1 @endverbatim  In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 2.8.1

    <hr>
    @subsection disable-https-redirect qorus.disable-https-redirect

    if @ref True then automatic redirects from HTTP to HTTPS requests for the web UI will be disabled, allowing the UI
    to be accessible from both HTTP and HTTPS listeners at the same time.

    <i>Data Type and Default Value</i>
    - bool: @ref False

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example:
    @verbatim qorus disable-https-redirect=true @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qprus 5.1

    <hr>
    @subsection detach-delay qorus.detach-delay

    This option gives the amount of time in seconds that workflow order data instances will be cached before deleted (see the @ref cache-max option as well).

    This option has a direct impact on performance as setting a large number here keeps more data in memory, for a longer time period reducing SQL I/O by reducing the need for the server to query the database for workflow data.  This option should be set according to the requirements of the environment and workflows running on Qorus; the default is one hour (3600 seconds) which may not be appropriate for workflows with long-running asynchronous steps.

    It is generally safe to use longer values, however a detach-delay value that is too short will reduce the effectiveness of the cache as the data will be automatically purged before it's needed, therefore it's recommended to set this option to a value a little higher than the longest possible execution time for the longest-running workflow.

    <i>Data Type and Default Value</i>
    - int: 3600 (3600 seconds = 1 hour)

    <hr>
    @subsection dsp-error-timeout qorus.dsp-error-timeout

    The amount of time in milliseconds for a runtime exception to be raised if a connection cannot be allocated from a system @ref dsconn "datasource pool".

    <i>Data Type and Default Value</i>
    - int: \c 120000 (2 minutes)

    @since Qorus 3.0.0

    <hr>
    @subsection dsp-warning-timeout qorus.dsp-warning-timeout

    The amount of time in milliseconds for a @ref transientalerts "transient alert" to be raised if a connection cannot be allocated from a system @ref dsconn "datasource pool"

    <i>Data Type and Default Value</i>
    - int: \c 5000 (5 seconds)

    @since Qorus 3.0.0

    <hr>
    @subsection http-secure-certificate qorus.http-secure-certificate

    This option sets the global certificate path (for X.509 certificates in PEM format) for HTTPS listeners; environment variables
    are legal and are expanded in this option value.
    To set the global private key, see @ref http-secure-private-key.

    @see @ref http-secure-server

    <i>Data Type and Default Value</i>
    - string: no default value

    @note
    - This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus http-secure-certificate=/etc/pki/cert.pem @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.
    - Certificates and private keys may be also defined for specific HTTPS listeners; see @ref http-secure-server for more information

    <hr>
    @subsection http-secure-private-key qorus.http-secure-private-key

    This option sets the global private key path (for private key files for X.509 certificated in PEM format) for HTTPS listeners;
    environment variables are legal and are expanded in this option value.
    To set the global certificate, see @ref http-secure-certificate; to set the private key password; see @ref http-secure-private-key-password

    @see
    - @ref http-secure-server
    - @ref http-secure-certificate
    - @ref http-secure-private-key-password

    <i>Data Type and Default Value</i>
    - string: no default value

    @note
    - This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus http-secure-private-key=/etc/pki/key.pem @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.
    - Certificates and private keys may be also defined for specific HTTPS listeners; see @ref http-secure-server for more information

    <hr>
    @subsection http-secure-private-key-password qorus.http-secure-private-key-password

    This option sets the global password for the the global private key for HTTPS listeners.
     To set the private key, see @ref http-secure-private-key; to set the certificate, see @ref http-secure-certificate.

    @see @ref http-secure-server
    - @ref http-secure-certificate
    - @ref http-secure-private-key

    @since Qorus 3.0.4.p2

    <i>Data Type and Default Value</i>
    - string: no default value
    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-
    line; for example: @verbatim qorus http-secure-private-key=/etc/pki/key.pem @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection http-secure-server qorus.http-secure-server

    This option sets the listener addresses for HTTPS listeners (for encrypted connections).
    To set the global X.509 certificate see @ref http-secure-certificate, and to set the global private key, see
    @ref http-secure-private-key.

    This option takes multiple values separated by commas (whereas parameters for each listener are separated
    by semicolons).  If a single port number is given, then the HTTPS listener
    will listen on all available interfaces on the given port number.  Otherwise, to specify a certain network device
    and IP address, give the IP address and port in the following format:

    - <tt>[</tt><i>ip-address</i><tt>:]</tt><i>port</i><tt>[{cert=</tt><i>file</i><tt>;key=</tt><i>file</i><tt>;password=</tt><i>string</i><tt>}]</tt>[,...]

    ex:
    - <tt>8009</tt>
    - <tt>192.168.20.15:8009{cert=$OMQ_DIR/etc/cert1.pem;key=$OMQ_DIR/etc/key1.pem;password=my_password}</tt>
    - <tt>192.168.20.77:8085{cert=$OMQ_DIR/etc/cert2.pem;key=$OMQ_DIR/etc/key2.pem},8086{cert=$OMQ_DIR/etc/cert3.pem;key=$OMQ_DIR/etc/key3.pem}</tt>

    If any of the \a cert, \a key, or \a password parameters are given for a listener, they must be separated by
    semicolons in the curly bracket parameters expression after the listener specifiction, and in this case they
    override global options for the X.509 certificate (@ref http-secure-certificate), the HTTPS private key
    (@ref http-secure-private-key), and the private key password (@ref http-secure-private-key-password).  Environment
    variables are expanded in the \a cert and \a key parameters of this option value.

    This option may be repeated multiple times to define each listener on a separate line.

    <i>Data Type and Default Value</i>
    - list of strings: no default value

    @see
    - @ref http-secure-certificate
    - @ref http-secure-private-key
    - @ref http-secure-private-key-password

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example:
    @verbatim qorus http-secure-server=8009 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection http-server qorus.http-server

    This option sets the listener addresses for HTTP listeners (for unencrypted connections).

    This option takes multiple values separated by commas.  If a single port number is given, then the HTTP listener
    will listen on all available interfaces on the given port number.  Otherwise, to specify a certain network device
    and IP address, give the IP address and port in the following format:

    - <em>ip-address:port</em> (i.e. <tt>192.168.20.15:8009</tt>)

    <i>Data Type and Default Value</i>
    - list of strings: no default value

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example:
    @verbatim qorus.http-server: localhost:8081,192.168.20.4:9010 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection instance-key qorus.instance-key

    This option sets the name of the application instance.  Each Qorus server should have a unique instance name.  The instance name will be saved against each application session and will determine if the Qorus instance can connect to the database or not, or if an open application session in the \c SESSIONS table needs to be recovered.

    If two Qorus server instances are given the same instance key name and are started against the same database at the same time, one of the instances might recover the other instance's session while it is still in progress, leading to data corruption.

    <i>Data Type and Default Value</i>
    - string: \c "qorus-test-instance"

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus instance-key=dev-1 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection job-logfile-template qorus.job-logfile-template

    Gives the default logfile template for new job log appenders when created from the system UI.

    <i>Data Type and Default Value</i>
    - string: \c "OMQ-$instance-JOB-$name.log"

    @since Qorus 2.6.1

    <hr>
    @subsection job-modules-option qorus.job-modules

    This option provides a list of user modules defining APIs for Qorus jobs; see @ref job_modules for more
    information.

    <i>Data Type and Default Value</i>
    - list of strings: @ref nothing

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus job-modules=my-module @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 4.0

    <hr>
    @subsection kubernetes-namespace qorus.kubernetes-namespace

    The namespace to use in Kubernetes REST API calls for autoscaling control.

    <i>Data Type and Default Value</i>
    - string: \c "default"

    @since Qorus 5.1

    <hr>
    @subsection logdir qorus.logdir

    This option sets the path to the system log directory.

    <i>Data Type and Default Value</i>
    - string: \c "$OMQ_DIR/log" (@ref tar installs) \c "/var/log/qorus" (LSB installs)

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus logdir=/var/log/qorus/dev-1 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection logfile-template qorus.logfile-template

    Gives the default logfile template for new system log appenders when created from the system UI.

    <i>Data Type and Default Value</i>
    - string: \c "OMQ-$instance-$name.log"

    @since Qorus 1.8.0

    <hr>
    @subsection manage-interfaces qorus.manage-interfaces

    The value of this option determines whether Qorus will start and stop workflows, services, and jobs automatically based on their @ref connmon "connection status".

    <i>Data Type and Default Value</i>
    - bool: @ref True

    @note To ensure that no interfaces are started in a Qorus instance, set this option and @ref autostart-interfaces to @ref False "False" when Qorus is started

    @since Qorus 3.0.0

    <hr>
    @subsection mapper-modules qorus.mapper-modules

    This option sets the set of user modules that provide support for custom data mapper types.

    <i>Data Type and Default Value</i>
    - @ref list_type "list": no default value

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example: @verbatim qorus connection-modules=RabbitMQConnection @endverbatim In order to effect a
    change in the value of this option, it is necessary to restart the server.

    @see dep_mapper-devel-modules

    @since Qorus 3.1.0

    <hr>
    @subsection max-async-retries qorus.max-async-retries

    This option specifies the retry limit for asynchronous steps until the step will automatically receive an @ref OMQ::StatError status.

    If an asynchronous step undergoes this many asynchronous retries without getting a @ref OMQ::StatComplete status, then an appropriate error will be logged and the step's status will be updated to @ref OMQ::StatError.

    @see @ref max-retries.

    <i>Data Type and Default Value</i>
    - int: 20

    @note This option may also be overridden at the workflow execution instance level by setting a workflow option with this name.

    <hr>
    @subsection max-events qorus.max-events

    Sets the maximum number of @ref systemevents "system events" to be held in the system event cache.

    <i>Data Type and Default Value</i>
    - int: 100000

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus max-events=10000000 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 2.0.2

    <hr>
    @subsection max-log-files qorus.max-log-files

    Sets the default value to use for the \c rotationCount option for new log appenders supporting file rotation
    (as triggered by @ref rest_api_PUT_latest_system_rotateLogFiles or omq.system.rotate-log-files()).

    <i>Data Type and Default Value</i>
    - int: 10

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example: @verbatim qorus max-log-files=20 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection max-process-memory-percent qorus.max-process-memory-percent

    Sets the maximum private (heap + stack etc) memory as a percentage of RAM on the node for any single non-critical
    process before the @ref qorus "qorus master process" will terminate it due to excess memory usage.  This value
    must be larger than @ref warning-process-memory-percent "warning-process-memory-percent".

    Critical processes must always be running and therefore are never killed; there are two critical processes as
    follows:
    - @ref qorus-core "qorus-core": the core Qorus process handling global integration services such as the HTTP
      server and global metadata cache
    - @ref qdsp "qdsp-omq": the database pool process for the Qorus system schema

    <i>Data Type and Default Value</i>
    - int: 99

    @see @ref warning-process-memory-percent

    @note
    - This option is read-only after system startup; it can only be set in the @ref options.
    - Qorus will refuse to start processes in low memory conditions

    @since
    - Qorus 4.0: first implementation
    - Qorus 4.1.4.p3: default value changed to 99

    <hr>
    @subsection max-retries qorus.max-retries

    This option specifies the retry limit for workflow steps until the step will automatically receive an @ref OMQ::StatError status.

    If a step undergoes this many retries (after a @ref OMQ::StatRetry status) without getting a @ref OMQ::StatComplete status, then an appropriate error will be logged and the step's status will be updated to @ref OMQ::StatError.

    @see @ref max-async-retries.

    <i>Data Type and Default Value</i>
    - int: 20

    @note This option may also be overridden at the workflow execution instance level by setting a workflow option with this name.

    <hr>
    @subsection max-service-threads qorus.max-service-threads

    This option sets the maximum number of threads that can be started by a service and running simultaneously.

    This value may be tuned according to user requirements.
    <i>Data Type and Default Value</i>
    - int: 200

    @since Qorus 2.7.0.p2

    <hr>
    @subsection minimum-tls-13 qorus.minimum-tls-13

    If True the TLS v1.3 protocol will be the minimum supported version with secure connections

    <i>Data Type and Default Value</i>
    - bool: @ref False

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example:
    @verbatim qorus minimum-tls-13=true @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 5.1.36

    <hr>
    @subsection network-key qorus.network-key

    This option gives the file name for the encryption key for private cluster network data encryption and decryption;
    the file must contain a 32-byte binary encryption key.

    If this option is set and the file is not readable or has too permissive permissions, the system cannot be started.

    <i>Data Type and Default Value</i>
    - string: no default value

    @note
    - To create this file, call @ref user-tool "user-tool -K"
    - Do not change this file while the system is running; all cluster network processes must have the same shared key in
      order to be able to communicate.  The network encryption key can be safely changed when the cluster is shut down.

    @since Qorus 4.0

    <hr>
    @subsection node qorus.node

    This option provdes a mapping from node names to IP addresses for cluster communication; the format is a hash
    where keys are node names and values are IP address values; for example:

    @verbatim
node-a=192.168.90.15,node-b=192.168.90.90,node-c=192.168.90.110
    @endverbatim

    If Qorus is started on a machine with an IP address that matches an IP address value set in this option, then that
    machine will have the node name given for that IP address.

    If this option is not set and no addresses match the current machine, the system cannot be started.

    <i>Data Type and Default Value</i>
    - string: no default value

    @since Qorus 4.0

    @note Qorus 5.1+ will autodetect this option if not set

    <hr>
    @subsection option-file qorus.option-file

    This option gives the path to the @ref options.  It is read-only and can only be set on the command-line when starting the Qorus server, otherwise the system will look in the default location for this file.

    <i>Data Type and Default Value</i>
    - string: \c "$OMQ_DIR/etc/options" (@ref tar installs) or \c "/etc/qorus/options" (LSB installs)

    @note This option is read-only after system startup; it can only be set on the command-line; for example: @verbatim qorus option-file=/tmp/options-dev-1 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 1.8.0

    <hr>
    @subsection oracle-datasource-pool qorus.oracle-datasource-pool

    Enables automatic Oracle instrumentation as described in @ref OMQ::QorusOracleDatasourcePool "QorusOracleDatasourcePool"
    This option has an effect only for Oracle datasources.
    In this case the user code won't receive a @ref Qore::SQL::DatasourcePool "DatasourcePool" object but rather a
    @ref OMQ::QorusOracleDatasourcePool "QorusOracleDatasourcePool" object which is compatible with
    @ref Qore::SQL::DatasourcePool "DatasourcePool" by inheritance.

    <i>Data Type and Default Value</i>
    - bool: @ref True "True"

    @since Qorus 3.1.0

    <hr>
    @subsection password-policy-min-length qorus.password-policy-min-length

    Minimum password length when changing passwords

    <i>Data Type and Default Value</i>
    - int: \c 0

    @since Qorus 6.0

    <hr>
    @subsection password-policy-mixed-case qorus.password-policy-mixed-case

    If new passwords require at least one upper and lower-case letter

    <i>Data Type and Default Value</i>
    - bool: @ref False "False"

    @since Qorus 6.0

    <hr>
    @subsection password-policy-numbers qorus.password-policy-numbers

    If new passwords require at least one number

    <i>Data Type and Default Value</i>
    - bool: @ref False "False"

    @since Qorus 6.0

    <hr>
    @subsection password-policy-symbols qorus.password-policy-symbols

    If new passwords require at least one symbol

    <i>Data Type and Default Value</i>
    - bool: @ref False "False"

    @since Qorus 6.0

    <hr>
    @subsection purge-sensitive-data-canceled qorus.purge-sensitive-data-canceled

    This option determines if @ref sensitive_data should be purged from the system when an order goes to @ref OMQ::StatCanceled

    <i>Data Type and Default Value</i>
    - bool: @ref True "True"

    @since Qorus 3.1.1

    <hr>
    @subsection purge-sensitive-data-complete qorus.purge-sensitive-data-complete

    This option determines if @ref sensitive_data should be purged from the system when an order goes to @ref OMQ::StatComplete

    <i>Data Type and Default Value</i>
    - bool: @ref True "True"

    @since Qorus 3.1.1

    <hr>
    @subsection recovery-amount qorus.recovery-amount

    Monetary amount for a single recovered workflow order to estimate the cost savings of automatic technical error recovery in Qorus.

    <i>Data Type and Default Value</i>
    - int: 750

    @since Qorus 4.0

    <hr>
    @subsection recovery-currency qorus.recovery-currency

    Set the currency for @ref recovery-amount "recovery-amount".

    <i>Data Type and Default Value</i>
    - string: USD

    @since Qorus 4.0

    <hr>
    @subsection remoteconnections-file qorus.remoteconnections-file

    The option is ignored and considered empty from Qorus 4.0; all Qorus remote connections are handled as
    @ref remoteconn "remote Qorus connection objects"; the \c remoteconnections file is no longer used as of Qorus
    4.0.

    @see @ref remoteconn

    @since Qorus 4.0 the option is ignored

    <hr>
    @subsection scaling-min-replicas qorus.scaling-min-replicas

    The minimum number of replicas that will be started when Qorus is running under
    <a href="https://kubernetes.io/">Kubernetes</a>.

    <i>Data Type and Default Value</i>
    - int: 1

    @since Qorus 5.1

    <hr>
    @subsection scaling-max-replicas qorus.scaling-max-replicas

    The maximum number of replicas that will be started when Qorus is running under
    <a href="https://kubernetes.io/">Kubernetes</a>.

    <i>Data Type and Default Value</i>
    - int: 3

    @since Qorus 5.1

    <hr>
    @subsection scaling-cpu qorus.scaling-cpu

    The percentage CPU usage goal for <a href="https://kubernetes.io/">Kubernetes</a> for all pods.

    <i>Data Type and Default Value</i>
    - int: 50

    @since Qorus 5.1

    <hr>
    @subsection scaling-memory qorus.scaling-memory

    The memory usage target for <a href="https://kubernetes.io/">Kubernetes</a>

    <i>Data Type and Default Value</i>
    - string: 200M

    @since Qorus 5.1

    <hr>
    @subsection sensitive-data-key qorus.sensitive-data-key

    This option give the file name of an encryption key for @ref sensitive_data "sensitive order data" encryption and decryption.  This file must contain a 32-byte encryption key and must be readable only by the application user, or the system cannot be started.

    If this option is set and the file is not readable or has too permissive permissions, the system cannot be started.

    If this option is not set, then @ref sensitive_data "sensitive order data" APIs cannot be used.

    If this option is set, then the @ref sensitive-value-key option must also be set.

    <i>Data Type and Default Value</i>
    - string: no default value

    @note
    - To create this file, call @ref user-tool "user-tool -K"
    - Do not change or lose this file; if the encyrption key is lost or changed, sensitive data stored in the system schema cannot be retrieved or processed.

    @since Qorus 3.1.1

    <hr>
    @subsection sensitive-value-key qorus.sensitive-value-key

    This option give the file name of an encryption key for @ref sensitive_data "sensitive order" key value encryption and decryption.  This file must contain a 4 - 56 byte encryption key and must be readable only by the application user, or the system cannot be started.

    If this option is set and the file is not readable or has too permissive permissions, the system cannot be started.

    If this option is not set, then @ref sensitive_data "sensitive order data" APIs cannot be used.

    If this option is set, then the @ref sensitive-data-key option must also be set.

    <i>Data Type and Default Value</i>
    - string: no default value

    @note
    - To create this file, call @ref user-tool "user-tool -K"
    - Do not change or lose this file; if the encyrption key is lost or changed, sensitive data stored in the system schema cannot be retrieved or processed.

    @since Qorus 3.1.1

    <hr>
    @subsection service-modules-option qorus.service-modules

    This option provides a list of user modules defining APIs for Qorus services; see
    @ref service_modules "service-modules" for more information.

    <i>Data Type and Default Value</i>
    - list of strings: @ref nothing

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus service-modules=my-module @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 4.0

    <hr>
    @subsection service-perf-events qorus.service-perf-events

    Enables @ref SERVICE_METHOD_PERFORMANCE "SERVICE_METHOD_PERFORMANCE" event emission on all service calls; note that enabling this option can cause service method call performance degredation.

    <i>Data Type and Default Value</i>
    - bool: @ref False "False"

    @since Qorus 3.0.3

    <hr>
    @subsection sla-max-events qorus.sla-max-events

    The maximum number of SLA events to hold before flushing to DB

    <i>Data Type and Default Value</i>
    - integer: \c 100

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line, for example: @verbatim qorus sla-max-events=50 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 3.1.1

    <hr>
    @subsection sla-max-sync-secs qorus.sla-max-sync-secs

    The maximum number of seconds to hold SLA events before flushing to DB.

    <i>Data Type and Default Value</i>
    - integer: \c 30

    @since Qorus 3.1.1

    <hr>
    @subsection socket-min-throughput qorus.socket-min-throughput

    The minimum socket throughput in bytes/second below which a warning will be raised for socket-based connection objects.

    <i>Data Type and Default Value</i>
    - integer: \c 20480

    @since Qorus 3.0.0

    @note This option takes effect only for new connections created after the value is changed.

    <hr>
    @subsection socket-min-throughput-ms qorus.socket-min-throughput-ms

    The minimum time in milliseconds a socket transfer must take for it to be eligible for throughput warnings; transfers that take less time than this are ignored.

    <i>Data Type and Default Value</i>
    - integer: \c 1000

    @since Qorus 3.0.0

    @note This option takes effect only for new connections created after the value is changed.

    <hr>
    @subsection socket-warning-timeout qorus.socket-warning-timeout

    The socket operation timeout threshold in milliseconds for raising transient alerts against socket-based connection objects.

    <i>Data Type and Default Value</i>
    - integer: \c 10000

    @since
    - Qorus 3.0.0 introduced this option
    - Qorus 3.1.0 changed the default value from 5000 (5 seconds) to 10000 (10 seconds)

    @note This option takes effect only for new connections created after the value is changed.

    <hr>
    @subsection sql-default-blocksize qorus.sql-default-blocksize

    Size of the regular @ref appsessionrecovery and workflow @ref workflowstartup SQL batches

    <i>Data Type and Default Value</i>
    - integer: \c 5000

    @since Qorus 2.9.1.p1

    <hr>
    @subsection sql-init-blocksize qorus.sql-init-blocksize

    Size of the first workflow @ref workflowstartup SQL batch for instant workflow instance processing as soon as possible.
    This batch goes before any other @ref sql-default-blocksize

    @note It's logical to have \c sql-init-blocksize value smaller than @ref sql-default-blocksize.
          But there is no technical limitation of the values used in this option.

    <i>Data Type and Default Value</i>
    - integer: \c 200

    @since Qorus 2.9.1.p1

    <hr>
    @subsection stack-size qorus.stack-size

    The stack size for new threads in bytes; must be greater than or equal to \c 524288, which is the minimum stack
    size.

    <i>Data Type and Default Value</i>
    - integer: n/a

    Because setting a high default stack size value will cause far higher memory usage of the system as a whole, its
    recommended to set higher stack sizes by setting the appropriate value of the \c stack-size option on each
    interface directly while also setting the \c remote flag to \c True on the interface, ensuring that it will be run
    in a dedicated process.  That way the higher stack size will be enforced only for the program that needs it.

    @note
    - For processes running in @ref qorus-core "qorus-core" (i.e. where the \c remote flag is \c False), any
      locally-set \c stack-size option value is ignored; in @ref qorus-core "qorus-core", only the global
      \c stack-size option is used.
    - This option is read-only after system startup; it can only be set in the @ref options or on the
      command-line; for example: @verbatim qorus stack-size=1048576 @endverbatim
      In order to effect a change in the value of this option, it is necessary to restart the server.

    @see
    - @ref python_development_thread_stacks
    - @ref wf_remote
    - @ref service_remote
    - @ref job_remote

    @since Qorus 5.0

    <hr>
    @subsection svc-logfile-template qorus.svc-logfile-template

    Gives the default logfile template for new service log appenders when created from the system UI.

    <i>Data Type and Default Value</i>
    - string: \c "OMQ-$instance-SVC-$name.log"

    @since Qorus 1.8.0

    <hr>
    @subsection sync-delay qorus.sync-delay

    This option gives the amount of time in seconds that workflow synchronization event keys will be cached before being purged from the cache

    <i>Data Type and Default Value</i>
    - int: 3600 (3600 seconds = 1 hour)

    @since Qorus 3.1.0

    <hr>
    @subsection system-pool-maximum qorus.system-pool-maximum

	Sets the maximum number of connections in the system @ref Qore::SQL::DatasourcePool "DatasourcePool".  The system
    datasource pool (with special @ref dsconn "datasource" name \c "omq") is used internally to communicate with the
    system schema.  Larger installations may consider increasing the number when monitoring the system schema reveals
    that all of the system connections are active at the same time, meaning that no more connections are available and
    some threads are waiting on a connection to become free.

    <i>Data Type and Default Value</i>
    - int: 40

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example: @verbatim qorus system-pool-maximum=60 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection system-pool-minimum qorus.system-pool-minimum

    Sets the minimum number of connections in the system @ref Qore::SQL::DatasourcePool "DatasourcePool".   This
    number of database connection will be opened automatically when the system is started.

    Normally it's not necessary to change this option as database connections are opened automatically when needed.

    <i>Data Type and Default Value</i>
    - int: 5

    @note This option is read-only after system startup; it can only be set in the @ref options or on the
    command-line; for example: @verbatim qorus system-pool-minimum=2 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    <hr>
    @subsection systemdb qorus.systemdb

    Sets the database connection string for the system
    @ref Qore::SQL::DatasourcePool "DatasourcePool".
    This database connection will be opened automatically when the system is started.

    It is mandatory to set this option.

    <i>Data Type and Default Value</i>
    - string: no default value

    @note This option is read-only after system startup; it can only be set in the @ref options.
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 4.0

    <hr>
    @subsection transient-alert-max qorus.transient-alert-max

    Maximum number of @ref transientalerts "transient alert" to cache.

    <i>Data Type and Default Value</i>
    - int: \c 1000

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus transient-alert-max=2000 @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 3.0.0

    <hr>
    @subsection verbose qorus.verbose

    This value is only used to migrate an indication of the log level to new logger configurations.

    Use the REST API for a particular logger to change how information is logged.

    @deprecated since Qorus 4.0

    <hr>
    @subsection vmap-size-threshold qorus.vmap-size-threshold

    The maximum size of a value map (in number of entries) for it to be cached entirely on its first reference.  If the value map exceeds ths given size, its mappings are cached on demand as they are used.

    <i>Data Type and Default Value</i>
    - int: 100

    @see value-maps

    @since Qorus 3.1.0

    <hr>
    @subsection warning-process-memory-percent qorus.warning-process-memory-percent

    Sets the maximum private (heap + stack etc) memory as a percentage of RAM on the node for a process before a
    \c "PROCESS-MEMORY-USAGE" @ref ongoingalerts "ongoing alert" is raised about excessive memory usage for the
    process.  This value must be smaller than @ref max-process-memory-percent

    <i>Data Type and Default Value</i>
    - int: 50

    @see @ref max-process-memory-percent qorus.max-process-memory-percent

    @note This option is read-only after system startup; it can only be set in the @ref options.

    @since
    - Qorus 4.0: first implementation
    - Qorus 4.1.4.p3: default value changed to 50

    <hr>
    @subsection wf-logfile-template qorus.wf-logfile-template

    Gives the default logfile template for new workflow log appenders when created from the system UI.

    <i>Data Type and Default Value</i>
    - string: \c "OMQ-$instance-WF-$name.log"

    @since Qorus 1.8.0

    <hr>
    @subsection workflow-modules-option qorus.workflow-modules

    This option provides a list of user modules defining APIs for Qorus workflow; see @ref wf_modules for more
    information.

    <i>Data Type and Default Value</i>
    - list of strings: @ref nothing

    @note This option is read-only after system startup; it can only be set in the @ref options or on the command-line; for example: @verbatim qorus workflow-modules=my-module @endverbatim
    In order to effect a change in the value of this option, it is necessary to restart the server.

    @since Qorus 4.0

    <hr>
    @subsection workflow-params qorus.workflow-params

    This option is ignored since Qorus 4.0.

    <i>Data Type and Default Value</i>
    - hash (empty hash)

    @since Introduced in Qorus 2.0.2, made non-functional and deprecated in Qorus 4.0

    @deprecated This option will be removed in a future version of Qorus.

    <hr>
    @subsection workflow-perf-events qorus.workflow-perf-events

    Enables @ref WORKFLOW_PERFORMANCE "WORKFLOW_PERFORMANCE" event emission for all workflows.

    <i>Data Type and Default Value</i>
    - bool: @ref True "True"

    @since Qorus 4.0

    <hr>
    @subsection workflow-step-perf-events qorus.workflow-step-perf-events

    Enables @ref WORKFLOW_STEP_PERFORMANCE "WORKFLOW_STEP_PERFORMANCE" event emission for all workflow steps; note that enabling this option can cause workflow step performance degredation.

    <i>Data Type and Default Value</i>
    - bool: @ref False "False"

    @since Qorus 3.0.3

    <hr>
    @subsection applications qorus-client.applications

    The list of user applications present in this instance of Qorus for verification with @ref oload "oload"

    <i>Example</i>
    @verbatim qorus-client.applications: BssCrm @endverbatim

    <i>Data Type and Default Value</i>
    - list of strings: no default value

    @since Qorus 2.8.0.p7

    <hr>
    @subsection allow-test-execution qorus-client.allow-test-execution

    Allows execution of @ref QorusInterfaceTest

    <i>Example</i>
    @verbatim qorus-client.allow-test-execution: true @endverbatim

    <i>Data Type and Default Value</i>
    - bool: @ref False

    @since Qorus 4.0.1

    <hr>
    @subsection client-pool-maximum qorus-client.client-pool-maximum

    The maximum number of connections in connection pools when created from the client, for example when created from
    a call to @ref OMQ::QorusClientAPI::getDatasourcePool() "QorusClientAPI::getDatasourcePool()".

    <i>Example</i>
    @verbatim qorus-client.client-pool-maximum: 3 @endverbatim

    <i>Data Type and Default Value</i>
    - int: \c 10

    <hr>
    @subsection client-pool-minimum qorus-client.client-pool-minimum

    The minimum number of connections in connection pools when created from the client, for example when created from
    a call to @ref OMQ::QorusClientAPI::getDatasourcePool() "QorusClientAPI::getDatasourcePool()".

    <i>Example</i>
    @verbatim qorus-client.client-pool-minimum: 1 @endverbatim

    <i>Data Type and Default Value</i>
    - int: \c 3

    <hr>
    @subsection client-url qorus-client.client-url

    The URL used to communicate with Qorus from client programs.  In most cases it is not necessary to set this option
    explicitly, as it will be set automatically based on the @ref http-secure-server and @ref http-server options.

    <i>Example</i>
    @verbatim qorus-client.client-url: https://[::1]:8009 @endverbatim

    <i>Data Type and Default Value</i>
    - string: depends on @ref http-secure-server and @ref http-server

    @note
    - If this option is not set explicitly in the @ref options, then the value will be detected and set automatically
    - It is not recommended to set a username and password in this URL for local use, as local client programs
    will automatically acquire an internal token using a ZeroMQ call to @ref qorus-core "qorus-core" so that they will
    run with internal system privileges in any case.

    <hr>
    @subsection data-tablespace qorus-client.data-tablespace

    The data tablespace name for the datasource in the wildcard portion of the option name.  The actual option name
    must be prefixed by the datasource name followed by a hyphen as in the following example:
    @verbatim qorus-client.omq-data-tablespace: omq_data @endverbatim

    <i>Data Type and Default Value</i>
    - string: no default value

    @see index-tablespace

    <hr>
    @subsection index-tablespace qorus-client.index-tablespace

    The index tablespace name for the datasource given as a prefix of the option name.  The actual option name
    must be prefixed by the datasource name followed by a hyphen as in the following example:
    @verbatim qorus-client.omq-index-tablespace: omq_index @endverbatim

    <i>Data Type and Default Value</i>
    - string: no default value

    @see data-tablespace

    <hr>
    @subsection missing-tag-warning qorus-client.missing-tag-warning

    Show missing tag warnings when loading interfaces with @ref oload "oload".

    <i>Example</i>
    @verbatim qorus-client.missing-tag-warning: false @endverbatim

    <i>Data Type and Default Value</i>
    - bool: @ref True

    <hr>
    @subsection override-job-params qorus-client.override-job-params

    Always override job schedule and runtime parameters when loading jobs with @ref oload "oload", even if they have
    been changed with the API.

    <i>Example</i>
    @verbatim qorus-client.override-job-params: true @endverbatim

    <i>Data Type and Default Value</i>
    - bool: @ref False

    <hr>
    @subsection proxy-url qorus-client.proxy-url

    The URL of the HTTP proxy for the Qorus server, optionally including any proxy authentication

    <i>Example</i>
    @verbatim qorus-client.proxy-url: https://my-user:my-pass@my-proxy.local:12413 @endverbatim

    <i>Data Type and Default Value</i>
    - string: no default value

    <hr>
    @subsection remote qorus-client.remote

    The default value of the \c "remote" option for @ref oload "oload" for interfaces that do not specify this option.
    Set this value to \c false to ensure that @ref oload "oload" will not enable the remote flag when loading
    interfaces with no remote option (for example, when working with older interfaces after a Qorus upgrade).

    <i>Example</i>
    @verbatim qorus-client.remote: false @endverbatim

    <i>Data Type and Default Value</i>
    - bool: @ref True

    @since Qorus 4.0

    <hr>
    @subsection warn-deprecated-api qorus-client.warn-deprecated-api

    If @ref True, @ref oload "oload" will warn when loading interface code using deprecated APIs.

    <i>Example</i>
    @verbatim qorus-client.warn-deprecated-api: false @endverbatim

    <i>Data Type and Default Value</i>
    - bool: @ref True

    @since Qorus 3.0.2
*/
